# YOLOv8 프루닝 및 재학습 성능 분석 보고서

## 📊 핵심 결과 요약

### 모델별 성능 비교

| 모델 | 파라미터 수 | 크기(MB) | mAP50 | FPS | 효율성¹ | 특징 |
|------|-------------|----------|-------|-----|---------|------|
| **모델 0** | 2,752,255 | 5.3 | 0.852 | **24.8** | **3.95** | 프루닝 기준 모델 |
| 모델 1 | 3,012,213 | 5.9 | 0.833 | 16.5 | 2.32 | Model_seg_ver3 1차 재학습 |
| 모델 2 | 3,012,213 | 5.9 | 0.853 | 15.5 | 2.23 | Model_seg_ver3 2차 재학습 |
| **모델 3** | 3,007,013 | 5.8 | **0.860** | 20.1 | 2.96 | train_code 1차 재학습 |
| 모델 4 | 3,007,013 | 5.8 | 0.864 | 15.7 | 2.33 | train_code 2차 재학습 |

¹ 효율성 = (mAP50 × FPS) / 모델크기

### 주요 발견사항

- **최고 효율성**: 모델 0 (프루닝만 적용)
- **최고 정확도**: 모델 4 (0.864 mAP50)
- **최고 속도**: 모델 0 (24.8 FPS)
- **최적 균형**: 모델 3 (정확도↑, 실시간 처리 가능)

---

## 🔬 실험 설정

### 모델 정의
- **모델 0**: 원본 모델에서 프루닝만 적용 (기준 모델)
- **모델 1**: 프루닝 후 Model_seg_ver3 코드로 1차 재학습
- **모델 2**: 모델 1에서 Model_seg_ver3 코드로 추가 학습
- **모델 3**: 프루닝 모델에서 train_code.py로 1차 재학습  
- **모델 4**: 모델 3에서 train_code.py로 추가 학습

### 평가 환경
- **해상도**: 320×180 (패딩 후 320×192)
- **평가 데이터**: 100장 샘플
- **환경**: CPU 추론
- **배치 크기**: 1

---

## 📈 상세 성능 분석

### 1. 실용성 관점 - 배포 적합성

#### 실시간 처리 기준 분석 (>20 FPS)
| 모델 | FPS | 실시간 처리 | 배포 적합성 |
|------|-----|-------------|-------------|
| 모델 0 | 24.8 | ✅ 여유있음 | **최적** |
| 모델 1 | 16.5 | ❌ 부족 | 부적합 |
| 모델 2 | 15.5 | ❌ 부족 | 부적합 |
| 모델 3 | 20.1 | ✅ 한계선 | 적합 |
| 모델 4 | 15.7 | ❌ 부족 | 부적합 |

#### 메모리 효율성
- **모델 0**: 5.3MB (기준)
- **재학습 모델들**: 5.8-5.9MB (+9.4-11.3% 증가)
- **파라미터 증가**: +254,758 ~ +259,958개

### 2. 기술적 관점 - 재학습 방법론 비교

#### Model_seg_ver3 vs train_code.py 성능 차이

| 지표 | Model_seg_ver3 (모델1) | train_code.py (모델3) | 차이 |
|------|------------------------|----------------------|------|
| 파라미터 증가율 | +9.4% | +9.2% | train_code 0.2%p 우수 |
| 정확도 변화 | -2.2% (0.852→0.833) | +0.9% (0.852→0.860) | train_code 3.1%p 우수 |
| 속도 보존율 | 66.5% | 81.0% | train_code 14.5%p 우수 |
| 효율성 | 2.32 | 2.96 | train_code 27.6% 우수 |

#### 코드별 핵심 차이점

**Model_seg_ver3 특징:**
- 일반적인 YOLO 학습 설정
- 프루닝 구조 보존 고려 부족
- 결과: 성능 하락, 속도 크게 저하

**train_code.py 특징:**
```python
# 구조 보존 특화 설정
'freeze': 0,           # 레이어 동결 없음
'dropout': 0.0,        # 드롭아웃 비활성화  
'lr0': 0.001,          # 낮은 학습률
'warmup_epochs': 3,    # 짧은 워밍업
'close_mosaic': 10,    # 모자이크 증강 조기 종료
```

### 3. 파라미터 증가 원인 분석

#### 프루닝 후 파라미터 수 변화
```
원본 모델 (추정): ~3,012,213개
↓ 프루닝 적용
모델 0: 2,752,255개 (-8.6%)
↓ 재학습
모델 1,2: 3,012,213개 (원본 수준 복원)
모델 3,4: 3,007,013개 (부분 복원)
```

#### 원인 분석
1. **Ultralytics 자동 구조 복원**
   - 프루닝된 구조를 "손상된" 것으로 인식
   - 학습 중 자동으로 구조 보완
   
2. **학습 방법론 차이**
   - Model_seg_ver3: 완전 복원 (원본과 동일)
   - train_code: 부분 복원 (보수적 접근)

3. **성능 역설**
   - 파라미터 증가 ≠ 성능 향상
   - 모델 3 (3,007,013개) > 모델 1 (3,012,213개)

### 4. 추가 학습의 효과 분석

#### 1차 vs 2차 재학습 비교

| 비교 | 정확도 개선 | 속도 변화 | 효율성 변화 |
|------|-------------|-----------|-------------|
| 모델 1→2 | +2.4% | -6.1% | -3.9% |
| 모델 3→4 | +0.5% | -21.9% | -21.3% |

**결론**: 2차 재학습은 비효율적
- 정확도 개선 미미 (0.5-2.4%p)
- 속도 저하 심각 (6-22%)
- 효율성 크게 감소

---

## 🎯 최적화 전략 분석

### Pareto 효율성 순위

| 순위 | 모델 | 정확도/속도 비율 | 최적화 상태 | 권장 용도 |
|------|------|------------------|-------------|-----------|
| 1위 | 모델 0 | 0.034 | 최적 | 실시간 처리 우선 |
| 2위 | 모델 3 | 0.043 | 차선 | 균형 추구 |
| 3위 | 모델 1 | 0.050 | 비효율 | 사용 비권장 |
| 4위 | 모델 4 | 0.055 | 비효율 | 정확도 최우선시만 |
| 5위 | 모델 2 | 0.055 | 최악 | 사용 비권장 |

### 용도별 모델 선택 가이드

#### 실시간 처리 우선 환경
**권장**: 모델 0
- 근거: 24.8 FPS, 5.3MB, 85.2% mAP50
- 장점: 최고 속도, 최경량, 충분한 정확도
- 단점: 재학습 불가

#### 정확도와 속도 균형
**권장**: 모델 3  
- 근거: 86.0% mAP50, 20.1 FPS, 5.8MB
- 장점: 최고 정확도, 실시간 처리 가능
- 단점: 모델 0 대비 속도 19% 저하

#### 정확도 최우선 환경
**권장**: 모델 4
- 근거: 86.4% mAP50 (최고 정확도)
- 단점: 15.7 FPS (실시간 처리 불가)

---

## 📋 결론 및 권장사항

### 핵심 발견사항

1. **프루닝 단독 사용이 최고 효율**
   - 모델 0: 효율성 3.95 (1위)
   - 재학습은 속도 저하 대비 정확도 개선 미미

2. **train_code.py 방법론 우수성 입증**
   - Model_seg_ver3 대비 모든 지표에서 우수
   - 프루닝 효과 보존력 14.5%p 높음

3. **2차 재학습의 비효율성**
   - 정확도 개선 대비 속도 저하 과다
   - 효율성 크게 감소

4. **파라미터 증가 역설**
   - 파라미터 수와 성능이 반비례
   - Ultralytics 자동 구조 복원의 부작용

### 기술적 권장사항

#### 즉시 적용 가능한 권장사항
1. **프루닝 단독 사용**: 재학습 없이 프루닝만 적용 (모델 0)
2. **train_code.py 채택**: 재학습 필요시 Model_seg_ver3 대신 사용
3. **1차 재학습만 수행**: 2차 재학습 지양
4. **실시간 기준 준수**: 20 FPS 이상 모델만 배포

#### 장기적 개선 방향
1. **프루닝 구조 보존 강화**: Ultralytics 자동 복원 방지
2. **전용 재학습 파이프라인**: 프루닝 특화 학습 방법론 개발
3. **효율성 기반 조기 종료**: 속도 저하 임계점 설정

### 최종 모델 선택 기준

```
실시간 처리 + 효율성 → 모델 0
정확도 + 실시간 처리 → 모델 3  
최고 정확도 → 모델 4 (비실시간 허용시만)
```

**결론**: 대부분의 실용적 환경에서는 **모델 0** 또는 **모델 3** 선택 권장