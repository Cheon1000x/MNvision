"""
í™•ì¥ëœ ì¼ê´„ í”„ë£¨ë‹ ì‹œìŠ¤í…œ
ê¸°ì¡´ ì„±ê³µí•œ ì‹œìŠ¤í…œì— ë” ë§ì€ í›„ë³´ ë ˆì´ì–´ë“¤ì„ ì¶”ê°€í•˜ì—¬ ìë™ íƒìƒ‰
"""

import torch
import torch.nn as nn
from ultralytics import YOLO
import copy
import time
import numpy as np

class ExpandedBatchPruner:
    def __init__(self, model_path):
        self.yolo = YOLO(model_path)
        self.model = self.yolo.model
        
        # í™•ì¥ëœ í›„ë³´ ë ˆì´ì–´ë“¤ (ê¸°ì¡´ ì„±ê³µ + ìƒˆë¡œìš´ í›„ë³´ë“¤)
        self.target_candidates = [
            # ê¸°ì¡´ ì„±ê³µí•œ cv1 ë ˆì´ì–´ë“¤ (ê²€ì¦ë¨)
            "model.2.m.0.cv1.conv",   # 16 ì±„ë„
            "model.4.m.0.cv1.conv",   # 32 ì±„ë„  
            "model.4.m.1.cv1.conv",   # 32 ì±„ë„
            "model.6.m.0.cv1.conv",   # 64 ì±„ë„
            "model.6.m.1.cv1.conv",   # 64 ì±„ë„
            "model.8.m.0.cv1.conv",   # 128 ì±„ë„
            "model.12.m.0.cv1.conv",  # 64 ì±„ë„
            "model.15.m.0.cv1.conv",  # 32 ì±„ë„
            "model.18.m.0.cv1.conv",  # 64 ì±„ë„
            "model.21.m.0.cv1.conv",  # 128 ì±„ë„
            
            # ìƒˆë¡œìš´ í›„ë³´: cv2 ë ˆì´ì–´ë“¤ (ë†’ì€ ì„±ê³µ í™•ë¥ )
            "model.2.m.0.cv2.conv",   # 16 ì±„ë„
            "model.4.m.0.cv2.conv",   # 32 ì±„ë„
            "model.4.m.1.cv2.conv",   # 32 ì±„ë„
            "model.6.m.0.cv2.conv",   # 64 ì±„ë„
            "model.6.m.1.cv2.conv",   # 64 ì±„ë„
            "model.8.m.0.cv2.conv",   # 128 ì±„ë„
            "model.12.m.0.cv2.conv",  # 64 ì±„ë„
            "model.15.m.0.cv2.conv",  # 32 ì±„ë„
            "model.18.m.0.cv2.conv",  # 64 ì±„ë„
            "model.21.m.0.cv2.conv",  # 128 ì±„ë„
            
            # ìƒˆë¡œìš´ í›„ë³´: Backbone Conv ë ˆì´ì–´ë“¤ (ì¤‘ê°„ í™•ë¥ )
            "model.1.conv",           # 32 ì±„ë„
            "model.3.conv",           # 64 ì±„ë„
            "model.5.conv",           # 128 ì±„ë„
            "model.7.conv",           # 256 ì±„ë„
            
            # ìƒˆë¡œìš´ í›„ë³´: ê¸°íƒ€ ë ˆì´ì–´ë“¤ (ë‚®ì€ í™•ë¥ )
            "model.16.conv",          # 64 ì±„ë„
            "model.19.conv",          # 128 ì±„ë„
            "model.9.cv1.conv",       # SPPF 128 ì±„ë„
            "model.9.cv2.conv",       # SPPF 256 ì±„ë„
        ]
        
        self.original_model = None
        
    def print_model_info(self, label="ëª¨ë¸"):
        """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
        total_params = sum(p.numel() for p in self.model.parameters())
        param_size = sum(param.nelement() * param.element_size() for param in self.model.parameters())
        buffer_size = sum(buffer.nelement() * buffer.element_size() for buffer in self.model.buffers())
        size_mb = (param_size + buffer_size) / 1024 / 1024
        
        print(f"ğŸ“Š {label} ì •ë³´:")
        print(f"   íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}ê°œ")
        print(f"   ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
    
    def scan_available_candidates(self):
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í›„ë³´ ë ˆì´ì–´ë“¤ ìŠ¤ìº” ë° ë¶„ë¥˜"""
        print("ğŸ” í™•ì¥ëœ í›„ë³´ ë ˆì´ì–´ ìŠ¤ìº”:")
        
        available_layers = []
        categories = {
            'cv1_existing': [],
            'cv2_new': [],
            'backbone_new': [],
            'other_new': []
        }
        
        for target in self.target_candidates:
            layer = None
            
            # ë ˆì´ì–´ ì¡´ì¬ í™•ì¸
            for name, module in self.model.named_modules():
                if name == target and isinstance(module, nn.Conv2d):
                    layer = module
                    break
            
            if layer:
                available_layers.append((target, layer))
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                if 'cv1.conv' in target:
                    categories['cv1_existing'].append((target, layer))
                elif 'cv2.conv' in target:
                    categories['cv2_new'].append((target, layer))
                elif target in ['model.1.conv', 'model.3.conv', 'model.5.conv', 'model.7.conv']:
                    categories['backbone_new'].append((target, layer))
                else:
                    categories['other_new'].append((target, layer))
                
                print(f"   âœ… {target} ({layer.out_channels} ì±„ë„)")
            else:
                print(f"   âŒ {target} (ì—†ìŒ)")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½
        print(f"\nğŸ“‹ í›„ë³´ ë¶„ë¥˜:")
        print(f"   ê¸°ì¡´ cv1 (ê²€ì¦ë¨): {len(categories['cv1_existing'])}ê°œ")
        print(f"   ìƒˆë¡œìš´ cv2: {len(categories['cv2_new'])}ê°œ")
        print(f"   ìƒˆë¡œìš´ backbone: {len(categories['backbone_new'])}ê°œ")
        print(f"   ê¸°íƒ€ ìƒˆë¡œìš´: {len(categories['other_new'])}ê°œ")
        print(f"   ì´ í›„ë³´: {len(available_layers)}ê°œ")
        
        return available_layers, categories
    
    def find_connected_conv_pair(self, layer_name):
        """ì—°ê²°ëœ Conv ìŒ ì°¾ê¸°"""
        if 'cv1.conv' in layer_name:
            cv2_name = layer_name.replace('cv1.conv', 'cv2.conv')
        elif 'cv2.conv' in layer_name:
            cv1_name = layer_name.replace('cv2.conv', 'cv1.conv')
            return self.find_connected_conv_pair(cv1_name)
        else:
            return None, None, None
        
        cv1_layer = None
        cv2_layer = None
        
        for name, module in self.model.named_modules():
            if name == layer_name and isinstance(module, nn.Conv2d):
                cv1_layer = module
            elif name == cv2_name and isinstance(module, nn.Conv2d):
                cv2_layer = module
        
        if cv1_layer and cv2_layer:
            return cv1_layer, cv2_layer, cv2_name
        
        return None, None, None
    
    def find_conv_bn_pair(self, conv_name):
        """Convì™€ BatchNorm ìŒ ì°¾ê¸°"""
        bn_name = conv_name.replace('.conv', '.bn')
        
        conv_layer = None
        bn_layer = None
        
        for name, module in self.model.named_modules():
            if name == conv_name and isinstance(module, nn.Conv2d):
                conv_layer = module
            elif name == bn_name and isinstance(module, nn.BatchNorm2d):
                bn_layer = module
        
        return conv_layer, bn_layer
    
    def test_single_layer_safety(self, layer_name, prune_ratio=0.1):
        """ë‹¨ì¼ ë ˆì´ì–´ í”„ë£¨ë‹ ì•ˆì „ì„± í…ŒìŠ¤íŠ¸"""
        # ëª¨ë¸ ë°±ì—…
        original_model = copy.deepcopy(self.model)
        
        try:
            # ì—°ê²°ëœ ìŒì´ ìˆëŠ”ì§€ í™•ì¸
            cv1_layer, cv2_layer, cv2_name = self.find_connected_conv_pair(layer_name)
            
            if cv1_layer and cv2_layer:
                # cv1-cv2 ìŒ í”„ë£¨ë‹
                success = self._prune_conv_pair(layer_name, cv1_layer, cv2_name, cv2_layer, prune_ratio)
            else:
                # ë‹¨ë… ë ˆì´ì–´ í”„ë£¨ë‹
                success = self._prune_single_layer(layer_name, prune_ratio)
            
            if success:
                # ëª¨ë¸ ë™ì‘ í…ŒìŠ¤íŠ¸
                dummy_input = torch.randn(1, 3, 192, 320)
                with torch.no_grad():
                    output = self.model(dummy_input)
                return True
            else:
                return False
                
        except Exception as e:
            print(f"      ì˜¤ë¥˜: {e}")
            return False
        
        finally:
            # ì›ë³¸ ëª¨ë¸ ë³µì›
            self.model = original_model
            self.yolo.model = self.model
    
    def _prune_conv_pair(self, cv1_name, cv1_layer, cv2_name, cv2_layer, prune_ratio):
        """CV1-CV2 ì—°ê²° ìŒ í”„ë£¨ë‹"""
        original_channels = cv1_layer.out_channels
        prune_count = int(original_channels * prune_ratio)
        prune_count = min(prune_count, original_channels - 8)
        
        if prune_count <= 0:
            return False
        
        # ì¤‘ìš”ë„ ê³„ì‚°
        weights = cv1_layer.weight.data
        channel_importance = torch.norm(weights.view(weights.size(0), -1), dim=1)
        _, prune_indices = torch.topk(channel_importance, prune_count, largest=False)
        keep_indices = torch.tensor([i for i in range(original_channels) if i not in prune_indices])
        
        # CV1 ì¶œë ¥ ì±„ë„ í”„ë£¨ë‹
        self._prune_conv_output_channels(cv1_layer, cv1_name, keep_indices)
        
        # CV2 ì…ë ¥ ì±„ë„ í”„ë£¨ë‹
        self._prune_conv_input_channels(cv2_layer, keep_indices)
        
        return True
    
    def _prune_single_layer(self, layer_name, prune_ratio):
        """ë‹¨ë… ë ˆì´ì–´ í”„ë£¨ë‹"""
        conv_layer, bn_layer = self.find_conv_bn_pair(layer_name)
        
        if conv_layer is None:
            return False
        
        original_channels = conv_layer.out_channels
        prune_count = int(original_channels * prune_ratio)
        prune_count = min(prune_count, original_channels - 8)
        
        if prune_count <= 0:
            return False
        
        weights = conv_layer.weight.data
        channel_importance = torch.norm(weights.view(weights.size(0), -1), dim=1)
        _, prune_indices = torch.topk(channel_importance, prune_count, largest=False)
        keep_indices = torch.tensor([i for i in range(original_channels) if i not in prune_indices])
        
        self._prune_conv_output_channels(conv_layer, layer_name, keep_indices)
        return True
    
    def _prune_conv_output_channels(self, conv_layer, layer_name, keep_indices):
        """Conv ì¶œë ¥ ì±„ë„ í”„ë£¨ë‹"""
        # Conv í”„ë£¨ë‹
        new_weight = conv_layer.weight.data[keep_indices]
        new_bias = conv_layer.bias.data[keep_indices] if conv_layer.bias is not None else None
        
        conv_layer.out_channels = len(keep_indices)
        conv_layer.weight = nn.Parameter(new_weight)
        if new_bias is not None:
            conv_layer.bias = nn.Parameter(new_bias)
        
        # BatchNorm í”„ë£¨ë‹
        bn_name = layer_name.replace('.conv', '.bn')
        for name, module in self.model.named_modules():
            if name == bn_name and isinstance(module, nn.BatchNorm2d):
                self._prune_batchnorm(module, keep_indices)
                break
    
    def _prune_conv_input_channels(self, conv_layer, keep_indices):
        """Conv ì…ë ¥ ì±„ë„ í”„ë£¨ë‹"""
        new_weight = conv_layer.weight.data[:, keep_indices]
        conv_layer.in_channels = len(keep_indices)
        conv_layer.weight = nn.Parameter(new_weight)
    
    def _prune_batchnorm(self, bn_layer, keep_indices):
        """BatchNorm í”„ë£¨ë‹"""
        bn_layer.num_features = len(keep_indices)
        
        if bn_layer.weight is not None:
            bn_layer.weight = nn.Parameter(bn_layer.weight.data[keep_indices])
        if bn_layer.bias is not None:
            bn_layer.bias = nn.Parameter(bn_layer.bias.data[keep_indices])
        
        bn_layer.running_mean = bn_layer.running_mean.data[keep_indices]
        bn_layer.running_var = bn_layer.running_var.data[keep_indices]
    
    def discover_safe_layers(self, test_ratio=0.1):
        """ì•ˆì „í•œ í”„ë£¨ë‹ ë ˆì´ì–´ ìë™ ë°œê²¬"""
        print(f"\nğŸ” ì•ˆì „í•œ ë ˆì´ì–´ ìë™ íƒìƒ‰ (í…ŒìŠ¤íŠ¸ ë¹„ìœ¨: {test_ratio:.0%})")
        print("=" * 60)
        
        # í›„ë³´ ìŠ¤ìº”
        available_layers, categories = self.scan_available_candidates()
        
        if not available_layers:
            print("âŒ í…ŒìŠ¤íŠ¸í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ê° í›„ë³´ë³„ ì•ˆì „ì„± í…ŒìŠ¤íŠ¸
        safe_layers = []
        
        print(f"\nğŸ§ª í›„ë³´ë³„ ì•ˆì „ì„± í…ŒìŠ¤íŠ¸:")
        for i, (layer_name, layer_module) in enumerate(available_layers, 1):
            print(f"\n--- {i}/{len(available_layers)}: {layer_name} ---")
            print(f"   ì±„ë„ ìˆ˜: {layer_module.out_channels}")
            
            # ì•ˆì „ì„± í…ŒìŠ¤íŠ¸
            if self.test_single_layer_safety(layer_name, test_ratio):
                safe_layers.append((layer_name, layer_module))
                print(f"   âœ… ì•ˆì „ í™•ì¸")
            else:
                print(f"   âŒ ìœ„í—˜ - ì œì™¸")
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š íƒìƒ‰ ê²°ê³¼:")
        print(f"   í…ŒìŠ¤íŠ¸í•œ í›„ë³´: {len(available_layers)}ê°œ")
        print(f"   ì•ˆì „í•œ ë ˆì´ì–´: {len(safe_layers)}ê°œ")
        print(f"   ì„±ê³µë¥ : {len(safe_layers)/len(available_layers)*100:.1f}%")
        
        if safe_layers:
            print(f"\nâœ… ë°œê²¬ëœ ì•ˆì „í•œ ë ˆì´ì–´ë“¤:")
            for layer_name, layer_module in safe_layers:
                print(f"   {layer_name} ({layer_module.out_channels} ì±„ë„)")
        
        return safe_layers
    
    def backup_model(self):
        """ëª¨ë¸ ë°±ì—…"""
        self.original_model = copy.deepcopy(self.model)
        print("ğŸ’¾ ì›ë³¸ ëª¨ë¸ ë°±ì—… ì™„ë£Œ")
    
    def restore_model(self):
        """ëª¨ë¸ ë³µì›"""
        if self.original_model:
            self.model = self.original_model
            self.yolo.model = self.model
            print("ğŸ”„ ì›ë³¸ ëª¨ë¸ ë³µì› ì™„ë£Œ")
    
    def benchmark_speed(self, num_runs=50):
        """ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
        dummy_image = np.random.randint(0, 255, (192, 320, 3), dtype=np.uint8)
        
        # ì›Œë°ì—…
        for _ in range(5):
            _ = self.yolo.predict(dummy_image, verbose=False)
        
        # ë²¤ì¹˜ë§ˆí¬
        start_time = time.perf_counter()
        for _ in range(num_runs):
            _ = self.yolo.predict(dummy_image, verbose=False)
        end_time = time.perf_counter()
        
        avg_time = (end_time - start_time) / num_runs * 1000
        fps = 1000 / avg_time
        
        print(f"   ì¶”ë¡  ì†ë„: {avg_time:.2f}ms ({fps:.1f} FPS)")
        return avg_time, fps
    
    def save_model(self, filename="expanded_pruned_model.pt"):
        """í”„ë£¨ë‹ëœ ëª¨ë¸ ì €ì¥"""
        save_path = f"./{filename}"
        self.yolo.save(save_path)
        print(f"ğŸ’¾ í™•ì¥ í”„ë£¨ë‹ëœ ëª¨ë¸ ì €ì¥: {save_path}")
        return save_path


def main():
    MODEL_PATH = r"C:\Users\KDT34\Desktop\Group6\best.pt"
    TEST_RATIO = 0.1    # 10% í…ŒìŠ¤íŠ¸ í”„ë£¨ë‹
    FINAL_RATIO = 0.15  # 15% ì‹¤ì œ í”„ë£¨ë‹
    
    print("ğŸš€ í™•ì¥ëœ ì¼ê´„ í”„ë£¨ë‹ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    try:
        # í”„ë£¨ë„ˆ ì´ˆê¸°í™”
        pruner = ExpandedBatchPruner(MODEL_PATH)
        
        # ì›ë³¸ ì„±ëŠ¥ ì¸¡ì •
        print("\n1ï¸âƒ£ ì›ë³¸ ëª¨ë¸ ì„±ëŠ¥:")
        pruner.print_model_info("ì›ë³¸")
        original_speed = pruner.benchmark_speed()
        
        # ì•ˆì „í•œ ë ˆì´ì–´ ìë™ ë°œê²¬
        print("\n2ï¸âƒ£ ì•ˆì „í•œ ë ˆì´ì–´ ìë™ ë°œê²¬:")
        safe_layers = pruner.discover_safe_layers(TEST_RATIO)
        
        if not safe_layers:
            print("âŒ ì¶”ê°€ë¡œ ì•ˆì „í•œ ë ˆì´ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # ì‚¬ìš©ì í™•ì¸
        print(f"\në°œê²¬ëœ {len(safe_layers)}ê°œ ë ˆì´ì–´ë¡œ ì‹¤ì œ í”„ë£¨ë‹ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        user_input = input("ê³„ì† ì§„í–‰? (y/n) [y]: ").strip().lower()
        if user_input == 'n':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # ì‹¤ì œ í”„ë£¨ë‹ ì‹¤í–‰ (ê¸°ì¡´ ì¼ê´„ í”„ë£¨ë‹ ì‹œìŠ¤í…œ ì¬ì‚¬ìš©)
        print(f"\n3ï¸âƒ£ í™•ì¥ëœ ì¼ê´„ í”„ë£¨ë‹ ì‹¤í–‰:")
        pruner.backup_model()
        
        # ë°œê²¬ëœ ì•ˆì „í•œ ë ˆì´ì–´ë“¤ë¡œ íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        pruner.target_candidates = [name for name, _ in safe_layers]
        
        # ê¸°ì¡´ ì¼ê´„ í”„ë£¨ë‹ ë¡œì§ ì¬ì‚¬ìš©
        success_count = 0
        total_channels_before = 0
        total_channels_after = 0
        
        for i, (layer_name, layer_module) in enumerate(safe_layers, 1):
            print(f"\n--- {i}/{len(safe_layers)}: {layer_name} ---")
            
            # ì—°ê²°ëœ ìŒ í™•ì¸
            cv1_layer, cv2_layer, cv2_name = pruner.find_connected_conv_pair(layer_name)
            
            original_channels = layer_module.out_channels
            
            if cv1_layer and cv2_layer:
                # ìŒ í”„ë£¨ë‹
                success = pruner._prune_conv_pair(layer_name, cv1_layer, cv2_name, cv2_layer, FINAL_RATIO)
            else:
                # ë‹¨ë… í”„ë£¨ë‹  
                success = pruner._prune_single_layer(layer_name, FINAL_RATIO)
            
            if success:
                after_channels = int(original_channels * (1 - FINAL_RATIO))
                after_channels = max(after_channels, 8)  # ìµœì†Œ 8ì±„ë„
                
                print(f"   ğŸ“Š ì±„ë„ ìˆ˜: {original_channels} â†’ {after_channels} ({original_channels-after_channels}ê°œ ì œê±°)")
                total_channels_before += original_channels
                total_channels_after += after_channels
                
                # ëª¨ë¸ ë™ì‘ í™•ì¸
                try:
                    dummy_input = torch.randn(1, 3, 192, 320)
                    with torch.no_grad():
                        output = pruner.model(dummy_input)
                    success_count += 1
                    print(f"   âœ… í”„ë£¨ë‹ ì„±ê³µ")
                except Exception as e:
                    print(f"   âŒ ëª¨ë¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    pruner.restore_model()
                    break
            else:
                print(f"   âŒ í”„ë£¨ë‹ ì‹¤íŒ¨")
        
        # ê²°ê³¼ í‰ê°€
        print(f"\n4ï¸âƒ£ í™•ì¥ í”„ë£¨ë‹ ê²°ê³¼:")
        if success_count > 0:
            print(f"   ì„±ê³µí•œ ë ˆì´ì–´: {success_count}/{len(safe_layers)}ê°œ")
            print(f"   ì´ ì±„ë„ ê°ì†Œ: {total_channels_before} â†’ {total_channels_after}")
            print(f"   ì±„ë„ ê°ì†Œìœ¨: {(1-total_channels_after/total_channels_before)*100:.1f}%")
            
            # ìµœì¢… ì„±ëŠ¥ ì¸¡ì •
            print(f"\n5ï¸âƒ£ ìµœì¢… ì„±ëŠ¥:")
            pruner.print_model_info("í™•ì¥ í”„ë£¨ë‹")
            final_speed = pruner.benchmark_speed()
            
            # ì„±ëŠ¥ ë¹„êµ
            speed_improvement = original_speed[0] / final_speed[0]
            print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
            print(f"   ì›ë³¸: {original_speed[1]:.1f} FPS")
            print(f"   í™•ì¥ í”„ë£¨ë‹ í›„: {final_speed[1]:.1f} FPS")
            print(f"   ì†ë„ í–¥ìƒ: {speed_improvement:.2f}ë°°")
            
            # ëª¨ë¸ ì €ì¥
            save_choice = input("\ní™•ì¥ í”„ë£¨ë‹ëœ ëª¨ë¸ì„ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n) [y]: ").strip().lower()
            if save_choice != 'n':
                saved_path = pruner.save_model()
                print(f"\nâœ… í™•ì¥ í”„ë£¨ë‹ ì™„ë£Œ!")
                print(f"ìµœì¢… ëª¨ë¸: {saved_path}")
        else:
            print("   âŒ í™•ì¥ í”„ë£¨ë‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()