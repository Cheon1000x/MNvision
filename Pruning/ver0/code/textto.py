"""
í”„ë£¨ë‹ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (í•µì‹¬ ê¸°ëŠ¥ë§Œ)
ì›ë³¸ vs í”„ë£¨ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥, ì†ë„, í¬ê¸° ë¹„êµ + ìë™ ê·¸ë˜í”„ ìƒì„±
"""

import torch
import time
import numpy as np
from ultralytics import YOLO
import psutil
import os
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class PruningBenchmark:
    def __init__(self, original_model_path, pruned_model_path):
        """
        Args:
            original_model_path: ì›ë³¸ ëª¨ë¸ ê²½ë¡œ
            pruned_model_path: í”„ë£¨ë‹ëœ ëª¨ë¸ ê²½ë¡œ
        """
        print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.original_model = YOLO(original_model_path)
        self.pruned_model = YOLO(pruned_model_path)
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
    def get_model_info(self, model, label):
        """ëª¨ë¸ ì •ë³´ ì¶”ì¶œ"""
        # íŒŒë¼ë¯¸í„° ìˆ˜
        total_params = sum(p.numel() for p in model.model.parameters())
        
        # ëª¨ë¸ í¬ê¸° (MB)
        param_size = sum(p.numel() * p.element_size() for p in model.model.parameters())
        buffer_size = sum(b.numel() * b.element_size() for b in model.model.buffers())
        size_mb = (param_size + buffer_size) / (1024 * 1024)
        
        return {
            'label': label,
            'params': total_params,
            'size_mb': size_mb
        }
    
    def benchmark_speed(self, model, num_runs=100, img_size=(192, 320)):
        """ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
        model.model.eval()
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_input = torch.randn(1, 3, img_size[0], img_size[1])
        
        # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.model.to(device)
        dummy_input = dummy_input.to(device)
        
        # ì›Œë°ì—… (5íšŒ)
        with torch.no_grad():
            for _ in range(5):
                _ = model.model(dummy_input)
        
        # ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        start_time = time.perf_counter()
        
        with torch.no_grad():
            for _ in range(num_runs):
                _ = model.model(dummy_input)
        
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        end_time = time.perf_counter()
        
        # ê²°ê³¼ ê³„ì‚°
        total_time = end_time - start_time
        avg_time_ms = (total_time / num_runs) * 1000
        fps = 1000 / avg_time_ms
        
        return {
            'avg_time_ms': avg_time_ms,
            'fps': fps,
            'total_time': total_time
        }
    
    def benchmark_memory(self, model):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()
            
            # ë”ë¯¸ ì¶”ë¡ 
            dummy_input = torch.randn(1, 3, 192, 320).cuda()
            model.model.cuda()
            
            with torch.no_grad():
                _ = model.model(dummy_input)
            
            memory_mb = torch.cuda.max_memory_allocated() / (1024 * 1024)
            torch.cuda.empty_cache()
            
            return {'gpu_memory_mb': memory_mb}
        else:
            # CPU ë©”ëª¨ë¦¬ (ëŒ€ëµì )
            process = psutil.Process()
            memory_mb = process.memory_info().rss / (1024 * 1024)
            return {'cpu_memory_mb': memory_mb}
    
    def create_benchmark_graphs(self, original_info, pruned_info, original_speed, pruned_speed, 
                               original_memory, pruned_memory, accuracy_results=None):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ê·¸ë˜í”„ë¡œ ìƒì„±"""
        
        # ê°œì„ ìœ¨ ê³„ì‚°
        param_reduction = (1 - pruned_info['params'] / original_info['params']) * 100
        size_reduction = (1 - pruned_info['size_mb'] / original_info['size_mb']) * 100
        speed_improvement = pruned_speed['fps'] / original_speed['fps']
        time_reduction = (1 - pruned_speed['avg_time_ms'] / original_speed['avg_time_ms']) * 100
        
        memory_key = 'gpu_memory_mb' if torch.cuda.is_available() else 'cpu_memory_mb'
        memory_reduction = (1 - pruned_memory[memory_key] / original_memory[memory_key]) * 100
        
        # ê·¸ë˜í”„ ìƒì„±
        if accuracy_results:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        else:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
        
        colors = ['#3498db', '#e74c3c']
        models = ['Original', 'Pruned']
        
        # 1. ëª¨ë¸ í¬ê¸° ë° íŒŒë¼ë¯¸í„° ë¹„êµ
        params = [original_info['params']/1000000, pruned_info['params']/1000000]  # ë°±ë§Œ ë‹¨ìœ„
        sizes = [original_info['size_mb'], pruned_info['size_mb']]
        
        x = np.arange(2)
        width = 0.35
        
        bars1 = ax1.bar(x - width/2, params, width, label='Parameters (M)', color=colors[0], alpha=0.8)
        ax1_twin = ax1.twinx()
        bars2 = ax1_twin.bar(x + width/2, sizes, width, label='Size (MB)', color=colors[1], alpha=0.8)
        
        ax1.set_title('Model Size & Parameters', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Parameters (Millions)', fontsize=12)
        ax1_twin.set_ylabel('Size (MB)', fontsize=12)
        ax1.set_xticks(x)
        ax1.set_xticklabels(models)
        ax1.grid(axis='y', alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for i, (param, size) in enumerate(zip(params, sizes)):
            ax1.text(i - width/2, param + 0.05, f'{param:.2f}M', ha='center', va='bottom', fontweight='bold')
            ax1_twin.text(i + width/2, size + 0.1, f'{size:.2f}MB', ha='center', va='bottom', fontweight='bold')
        
        # ê°ì†Œìœ¨ í‘œì‹œ
        ax1.text(0.5, 0.9, f'Params: {param_reduction:.1f}% â†“\nSize: {size_reduction:.1f}% â†“', 
                transform=ax1.transAxes, ha='center', fontsize=11,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        
        ax1.legend(loc='upper left')
        ax1_twin.legend(loc='upper right')
        
        # 2. ì†ë„ ë¹„êµ
        fps_values = [original_speed['fps'], pruned_speed['fps']]
        time_values = [original_speed['avg_time_ms'], pruned_speed['avg_time_ms']]
        
        bars3 = ax2.bar(x - width/2, fps_values, width, label='FPS', color='#2ecc71', alpha=0.8)
        ax2_twin = ax2.twinx()
        bars4 = ax2_twin.bar(x + width/2, time_values, width, label='Time (ms)', color='#f39c12', alpha=0.8)
        
        ax2.set_title('Speed Performance', fontsize=14, fontweight='bold')
        ax2.set_ylabel('FPS', fontsize=12)
        ax2_twin.set_ylabel('Inference Time (ms)', fontsize=12)
        ax2.set_xticks(x)
        ax2.set_xticklabels(models)
        ax2.grid(axis='y', alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for i, (fps, time_val) in enumerate(zip(fps_values, time_values)):
            ax2.text(i - width/2, fps + 1, f'{fps:.1f}', ha='center', va='bottom', fontweight='bold')
            ax2_twin.text(i + width/2, time_val + 0.2, f'{time_val:.2f}ms', ha='center', va='bottom', fontweight='bold')
        
        # í–¥ìƒë¥  í‘œì‹œ
        ax2.text(0.5, 0.9, f'Speed: {speed_improvement:.2f}x â†‘\nTime: {time_reduction:.1f}% â†“', 
                transform=ax2.transAxes, ha='center', fontsize=11,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
        
        ax2.legend(loc='upper left')
        ax2_twin.legend(loc='upper right')
        
        # 3. ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸
        if accuracy_results:
            # ì •í™•ë„ í¬í•¨ëœ ë ˆì´ë” ì°¨íŠ¸
            categories = ['Speed\n(FPS)', 'Efficiency\n(Params)', 'Size\n(MB)', 'Accuracy\n(mAP50)', 'Memory\n(MB)']
            
            # ì •ê·œí™”ëœ ê°’ (0-1 ë²”ìœ„)
            original_values = [
                original_speed['fps'] / 100,  # FPS ì •ê·œí™”
                1.0,  # ì›ë³¸ì„ 1.0ìœ¼ë¡œ ê¸°ì¤€
                1.0,  # ì›ë³¸ì„ 1.0ìœ¼ë¡œ ê¸°ì¤€  
                accuracy_results['original_map50'],
                1.0   # ì›ë³¸ì„ 1.0ìœ¼ë¡œ ê¸°ì¤€
            ]
            
            pruned_values = [
                pruned_speed['fps'] / 100,
                pruned_info['params'] / original_info['params'],
                pruned_info['size_mb'] / original_info['size_mb'],
                accuracy_results['pruned_map50'],
                pruned_memory[memory_key] / original_memory[memory_key]
            ]
        else:
            # ì •í™•ë„ ì—†ëŠ” ë ˆì´ë” ì°¨íŠ¸
            categories = ['Speed\n(FPS)', 'Efficiency\n(Params)', 'Size\n(MB)', 'Memory\n(MB)']
            
            original_values = [
                original_speed['fps'] / 100,
                1.0,
                1.0,
                1.0
            ]
            
            pruned_values = [
                pruned_speed['fps'] / 100,
                pruned_info['params'] / original_info['params'],
                pruned_info['size_mb'] / original_info['size_mb'],
                pruned_memory[memory_key] / original_memory[memory_key]
            ]
        
        # ë ˆì´ë” ì°¨íŠ¸ ìƒì„±
        ax_radar = ax3 if not accuracy_results else ax3
        if accuracy_results:
            ax_radar = plt.subplot(2, 2, 3, projection='polar')
        else:
            ax_radar = plt.subplot(1, 3, 3, projection='polar')
        
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
        angles = np.concatenate((angles, [angles[0]]))  # ë‹«íŒ ë„í˜•ì„ ìœ„í•´
        
        original_values += [original_values[0]]  # ë‹«íŒ ë„í˜•
        pruned_values += [pruned_values[0]]
        
        ax_radar.plot(angles, original_values, 'o-', linewidth=2, label='Original', color='#3498db')
        ax_radar.fill(angles, original_values, alpha=0.25, color='#3498db')
        ax_radar.plot(angles, pruned_values, 'o-', linewidth=2, label='Pruned', color='#e74c3c')
        ax_radar.fill(angles, pruned_values, alpha=0.25, color='#e74c3c')
        
        ax_radar.set_xticks(angles[:-1])
        ax_radar.set_xticklabels(categories)
        ax_radar.set_ylim(0, 1)
        ax_radar.set_title('Performance Radar Chart', fontsize=14, fontweight='bold', pad=20)
        ax_radar.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))
        ax_radar.grid(True)
        
        # 4. ì •í™•ë„ ë¹„êµ (ìˆëŠ” ê²½ìš°)
        if accuracy_results:
            metrics = ['mAP50', 'mAP50-95']
            original_acc = [accuracy_results['original_map50'], accuracy_results['original_map']]
            pruned_acc = [accuracy_results['pruned_map50'], accuracy_results['pruned_map']]
            
            x_acc = np.arange(len(metrics))
            bars5 = ax4.bar(x_acc - width/2, original_acc, width, label='Original', color='#3498db', alpha=0.8)
            bars6 = ax4.bar(x_acc + width/2, pruned_acc, width, label='Pruned', color='#e74c3c', alpha=0.8)
            
            ax4.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')
            ax4.set_ylabel('Accuracy Score', fontsize=12)
            ax4.set_xticks(x_acc)
            ax4.set_xticklabels(metrics)
            ax4.grid(axis='y', alpha=0.3)
            ax4.legend()
            
            # ê°’ í‘œì‹œ
            for i, (orig, prun) in enumerate(zip(original_acc, pruned_acc)):
                ax4.text(i - width/2, orig + 0.01, f'{orig:.3f}', ha='center', va='bottom', fontweight='bold')
                ax4.text(i + width/2, prun + 0.01, f'{prun:.3f}', ha='center', va='bottom', fontweight='bold')
            
            # ë³€í™”ìœ¨ í‘œì‹œ
            map50_change = accuracy_results['pruned_map50'] - accuracy_results['original_map50']
            map_change = accuracy_results['pruned_map'] - accuracy_results['original_map']
            ax4.text(0.5, 0.9, f'mAP50: {map50_change:+.3f}\nmAP: {map_change:+.3f}', 
                    transform=ax4.transAxes, ha='center', fontsize=11,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        
        plt.tight_layout()
        plt.savefig('pruning_benchmark_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ê·¸ë˜í”„ê°€ 'pruning_benchmark_results.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        plt.show()
        
        return fig
    
    def validate_accuracy(self, data_path=None):
        """ì •í™•ë„ ê²€ì¦ (ë°ì´í„°ì…‹ì´ ìˆëŠ” ê²½ìš°)"""
        if not data_path or not os.path.exists(data_path):
            print("âš ï¸  ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ì–´ ì •í™•ë„ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None, None
        
        print("ğŸ“Š ì •í™•ë„ ê²€ì¦ ì¤‘...")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ (YAML íŒŒì¼ vs í´ë”)
        if os.path.isfile(data_path) and data_path.endswith('.yaml'):
            # YAML íŒŒì¼ì¸ ê²½ìš°
            data_source = data_path
            print(f"   ğŸ“ YAML ë°ì´í„°ì…‹ ì‚¬ìš©: {data_path}")
        elif os.path.isdir(data_path):
            # í´ë”ì¸ ê²½ìš°
            data_source = data_path
            print(f"   ğŸ“ í´ë” ë°ì´í„°ì…‹ ì‚¬ìš©: {data_path}")
        else:
            print(f"âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹: {data_path}")
            return None, None
        
        try:
            # ì›ë³¸ ëª¨ë¸ ê²€ì¦
            print("   ğŸ”„ ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì¤‘...")
            original_results = self.original_model.val(data=data_source, verbose=False)
            
            # í”„ë£¨ë‹ ëª¨ë¸ ê²€ì¦  
            print("   ğŸ”„ í”„ë£¨ë‹ ëª¨ë¸ ê²€ì¦ ì¤‘...")
            pruned_results = self.pruned_model.val(data=data_source, verbose=False)
            
            return {
                'original_map50': float(original_results.box.map50),
                'original_map': float(original_results.box.map),
                'pruned_map50': float(pruned_results.box.map50), 
                'pruned_map': float(pruned_results.box.map)
            }, None
            
        except Exception as e:
            print(f"âš ï¸  ì •í™•ë„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None
        """ì •í™•ë„ ê²€ì¦ (ë°ì´í„°ì…‹ì´ ìˆëŠ” ê²½ìš°)"""
        if not data_path or not os.path.exists(data_path):
            print("âš ï¸  ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ì–´ ì •í™•ë„ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None, None
        
        print("ğŸ“Š ì •í™•ë„ ê²€ì¦ ì¤‘...")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ (YAML íŒŒì¼ vs í´ë”)
        if os.path.isfile(data_path) and data_path.endswith('.yaml'):
            # YAML íŒŒì¼ì¸ ê²½ìš°
            data_source = data_path
            print(f"   ğŸ“ YAML ë°ì´í„°ì…‹ ì‚¬ìš©: {data_path}")
        elif os.path.isdir(data_path):
            # í´ë”ì¸ ê²½ìš°
            data_source = data_path
            print(f"   ğŸ“ í´ë” ë°ì´í„°ì…‹ ì‚¬ìš©: {data_path}")
        else:
            print(f"âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹: {data_path}")
            return None, None
        
        try:
            # ì›ë³¸ ëª¨ë¸ ê²€ì¦
            print("   ğŸ”„ ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì¤‘...")
            original_results = self.original_model.val(data=data_source, verbose=False)
            
            # í”„ë£¨ë‹ ëª¨ë¸ ê²€ì¦  
            print("   ğŸ”„ í”„ë£¨ë‹ ëª¨ë¸ ê²€ì¦ ì¤‘...")
            pruned_results = self.pruned_model.val(data=data_source, verbose=False)
            
            return {
                'original_map50': float(original_results.box.map50),
                'original_map': float(original_results.box.map),
                'pruned_map50': float(pruned_results.box.map50), 
                'pruned_map': float(pruned_results.box.map)
            }, None
            
        except Exception as e:
            print(f"âš ï¸  ì •í™•ë„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None
    
    def run_benchmark(self, data_path=None, num_runs=100):
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("\nğŸš€ í”„ë£¨ë‹ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 50)
        
        # 1. ëª¨ë¸ ì •ë³´ ë¹„êµ
        print("\n1ï¸âƒ£ ëª¨ë¸ ì •ë³´:")
        original_info = self.get_model_info(self.original_model, "ì›ë³¸")
        pruned_info = self.get_model_info(self.pruned_model, "í”„ë£¨ë‹")
        
        print(f"ğŸ“Š {original_info['label']} ëª¨ë¸:")
        print(f"   íŒŒë¼ë¯¸í„°: {original_info['params']:,}ê°œ")
        print(f"   í¬ê¸°: {original_info['size_mb']:.2f} MB")
        
        print(f"ğŸ“Š {pruned_info['label']} ëª¨ë¸:")
        print(f"   íŒŒë¼ë¯¸í„°: {pruned_info['params']:,}ê°œ")
        print(f"   í¬ê¸°: {pruned_info['size_mb']:.2f} MB")
        
        # ê°œì„ ìœ¨ ê³„ì‚°
        param_reduction = (1 - pruned_info['params'] / original_info['params']) * 100
        size_reduction = (1 - pruned_info['size_mb'] / original_info['size_mb']) * 100
        
        print(f"\nğŸ“‰ ê°ì†Œìœ¨:")
        print(f"   íŒŒë¼ë¯¸í„°: {param_reduction:.1f}% ê°ì†Œ")
        print(f"   ëª¨ë¸ í¬ê¸°: {size_reduction:.1f}% ê°ì†Œ")
        
        # 2. ì†ë„ ë²¤ì¹˜ë§ˆí¬
        print(f"\n2ï¸âƒ£ ì†ë„ ë²¤ì¹˜ë§ˆí¬ ({num_runs}íšŒ í‰ê· ):")
        
        print("â±ï¸  ì›ë³¸ ëª¨ë¸ ì†ë„ ì¸¡ì • ì¤‘...")
        original_speed = self.benchmark_speed(self.original_model, num_runs)
        
        print("â±ï¸  í”„ë£¨ë‹ ëª¨ë¸ ì†ë„ ì¸¡ì • ì¤‘...")
        pruned_speed = self.benchmark_speed(self.pruned_model, num_runs)
        
        print(f"ğŸ”„ ì›ë³¸ ëª¨ë¸:")
        print(f"   ì¶”ë¡  ì‹œê°„: {original_speed['avg_time_ms']:.2f}ms")
        print(f"   FPS: {original_speed['fps']:.1f}")
        
        print(f"ğŸ”„ í”„ë£¨ë‹ ëª¨ë¸:")
        print(f"   ì¶”ë¡  ì‹œê°„: {pruned_speed['avg_time_ms']:.2f}ms") 
        print(f"   FPS: {pruned_speed['fps']:.1f}")
        
        # ì†ë„ í–¥ìƒ ê³„ì‚°
        speed_improvement = pruned_speed['fps'] / original_speed['fps']
        time_reduction = (1 - pruned_speed['avg_time_ms'] / original_speed['avg_time_ms']) * 100
        
        print(f"\nâš¡ ì†ë„ í–¥ìƒ:")
        print(f"   FPS í–¥ìƒ: {speed_improvement:.2f}ë°°")
        print(f"   ì‹œê°„ ë‹¨ì¶•: {time_reduction:.1f}%")
        
        # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        print(f"\n3ï¸âƒ£ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        
        original_memory = self.benchmark_memory(self.original_model)
        pruned_memory = self.benchmark_memory(self.pruned_model)
        
        memory_key = 'gpu_memory_mb' if torch.cuda.is_available() else 'cpu_memory_mb'
        memory_type = 'GPU' if torch.cuda.is_available() else 'CPU'
        
        print(f"ğŸ’¾ ì›ë³¸ ëª¨ë¸ ({memory_type}): {original_memory[memory_key]:.1f} MB")
        print(f"ğŸ’¾ í”„ë£¨ë‹ ëª¨ë¸ ({memory_type}): {pruned_memory[memory_key]:.1f} MB")
        
        memory_reduction = (1 - pruned_memory[memory_key] / original_memory[memory_key]) * 100
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½: {memory_reduction:.1f}%")
        
        # 4. ì •í™•ë„ ë¹„êµ (ì˜µì…˜)
        if data_path:
            accuracy_results, _ = self.validate_accuracy(data_path)
            if accuracy_results:
                print(f"\n4ï¸âƒ£ ì •í™•ë„ ë¹„êµ:")
                print(f"ğŸ“ˆ ì›ë³¸ ëª¨ë¸:")
                print(f"   mAP50: {accuracy_results['original_map50']:.3f}")
                print(f"   mAP50-95: {accuracy_results['original_map']:.3f}")
                
                print(f"ğŸ“ˆ í”„ë£¨ë‹ ëª¨ë¸:")
                print(f"   mAP50: {accuracy_results['pruned_map50']:.3f}")
                print(f"   mAP50-95: {accuracy_results['pruned_map']:.3f}")
                
                # ì •í™•ë„ ë³€í™”
                map50_change = accuracy_results['pruned_map50'] - accuracy_results['original_map50']
                map_change = accuracy_results['pruned_map'] - accuracy_results['original_map']
                
                print(f"ğŸ“Š ì •í™•ë„ ë³€í™”:")
                print(f"   mAP50: {map50_change:+.3f}")
                print(f"   mAP50-95: {map_change:+.3f}")
        
        # 5. ì¢…í•© ìš”ì•½
        print(f"\nğŸ¯ ì¢…í•© ìš”ì•½:")
        print("=" * 30)
        print(f"âš¡ ì†ë„ í–¥ìƒ: {speed_improvement:.2f}ë°°")
        print(f"ğŸ“‰ íŒŒë¼ë¯¸í„° ê°ì†Œ: {param_reduction:.1f}%")
        print(f"ğŸ’¾ í¬ê¸° ê°ì†Œ: {size_reduction:.1f}%")
        print(f"ğŸ§  ë©”ëª¨ë¦¬ ì ˆì•½: {memory_reduction:.1f}%")
        
        # íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
        efficiency_score = (speed_improvement * (param_reduction/100) * (size_reduction/100)) * 100
        print(f"ğŸ† íš¨ìœ¨ì„± ì ìˆ˜: {efficiency_score:.1f}/100")
        
        # ìë™ ê·¸ë˜í”„ ìƒì„±
        print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        self.create_benchmark_graphs(
            original_info, pruned_info, 
            original_speed, pruned_speed,
            original_memory, pruned_memory,
            accuracy_results
        )
        
        print(f"\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")


def main():
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    ORIGINAL_MODEL = r"C:\Users\KDT34\Desktop\Group6\original_model.pt"  # ì›ë³¸ ëª¨ë¸
    PRUNED_MODEL = r"C:\Users\KDT34\Desktop\Group6\pruning_model.pt"  # í”„ë£¨ë‹ ëª¨ë¸
    
    # ê²€ì¦ ë°ì´í„° ì„¤ì • - YAML íŒŒì¼ ì§ì ‘ ì‚¬ìš©
    DATA_YAML = r"C:\Users\KDT34\Desktop\Group6\temp_validation\dataset.yaml"  # ë³€í™˜ëœ YAML íŒŒì¼
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = PruningBenchmark(ORIGINAL_MODEL, PRUNED_MODEL)
    
    # YAML íŒŒì¼ë¡œ ì •í™•ë„ ë¹„êµ
    benchmark.run_benchmark(data_path=DATA_YAML, num_runs=50)


if __name__ == "__main__":
    main()