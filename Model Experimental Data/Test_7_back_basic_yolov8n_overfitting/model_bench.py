"""
YOLO ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ (ìˆ˜ì •ë¨)
í”„ë£¨ë‹ëœ ëª¨ë¸ë“¤ê³¼ ì›ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµ

ê¸°ëŠ¥:
1. JSON ë¼ë²¨ì„ YOLO í˜•ì‹ìœ¼ë¡œ ìë™ ë³€í™˜
2. ì •í™•ë„, ì†ë„, íš¨ìœ¨ì„±, ì¢…í•© íš¨ìœ¨ì„± ë¹„êµ
3. ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ ë²¤ì¹˜ë§ˆí¬
4. ìƒì„¸í•œ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±
"""
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import os
import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from ultralytics import YOLO
import time
import shutil
from pathlib import Path
import tempfile
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class YOLOBenchmark:
    def __init__(self, data_dir, classes_file, num_eval_images=100):
        """
        Args:
            data_dir: JSON+ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„° í´ë” ê²½ë¡œ
            classes_file: classes.txt íŒŒì¼ ê²½ë¡œ
            num_eval_images: í‰ê°€ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸: 100ì¥)
        """
        self.data_dir = data_dir
        self.classes_file = classes_file
        self.num_eval_images = num_eval_images
        self.temp_dir = None
        self.models = {}
        self.results = {}
        
        # í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
        with open(classes_file, 'r') as f:
            self.classes = [line.strip() for line in f.readlines()]
        
        print(f"ğŸ¯ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •:")
        print(f"   ë°ì´í„° í´ë”: {data_dir}")
        print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(self.classes)}")
        print(f"   í‰ê°€ ì´ë¯¸ì§€ ìˆ˜: {num_eval_images}")
        print(f"   í•´ìƒë„: 320x180")
        print(f"   ë°°ì¹˜ í¬ê¸°: 1")
        print(f"   í™˜ê²½: CPU")
    
    def prepare_test_data(self):
        """JSON+ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì„ì‹œ ë°ì´í„°ì…‹ ìƒì„±"""
        print("\nğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.temp_dir = tempfile.mkdtemp(prefix="yolo_benchmark_")
        images_dir = os.path.join(self.temp_dir, "images")
        labels_dir = os.path.join(self.temp_dir, "labels")
        os.makedirs(images_dir, exist_ok=True)
        os.makedirs(labels_dir, exist_ok=True)
        
        # JSONê³¼ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        all_files = os.listdir(self.data_dir)
        json_files = [f for f in all_files if f.endswith('.json')]
        image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        # íŒŒì¼ ìŒ ë§¤ì¹­
        paired_files = []
        for json_file in json_files:
            base_name = os.path.splitext(json_file)[0]
            for img_file in image_files:
                if base_name == os.path.splitext(img_file)[0]:
                    paired_files.append((json_file, img_file))
                    break
        
        print(f"   ì°¾ì€ íŒŒì¼ ìŒ: {len(paired_files)}ê°œ")
        
        # í‰ê°€ ì´ë¯¸ì§€ ìˆ˜ë§Œí¼ ìƒ˜í”Œë§
        if len(paired_files) > self.num_eval_images:
            import random
            random.shuffle(paired_files)
            paired_files = paired_files[:self.num_eval_images]
            print(f"   ìƒ˜í”Œë§: {len(paired_files)}ê°œ ì‚¬ìš©")
        
        # ë³€í™˜ ë° ë³µì‚¬
        converted_count = 0
        for json_file, img_file in paired_files:
            json_path = os.path.join(self.data_dir, json_file)
            img_path = os.path.join(self.data_dir, img_file)
            
            # ì´ë¯¸ì§€ ë³µì‚¬
            base_name = os.path.splitext(img_file)[0]
            new_img_path = os.path.join(images_dir, f"{base_name}.jpg")
            shutil.copy(img_path, new_img_path)
            
            # JSONì„ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            yolo_annotations = self._convert_json_to_yolo(json_path, img_path)
            
            # ë¼ë²¨ íŒŒì¼ ì €ì¥
            label_path = os.path.join(labels_dir, f"{base_name}.txt")
            with open(label_path, 'w') as f:
                f.write('\n'.join(yolo_annotations))
            
            converted_count += 1
        
        # YAML íŒŒì¼ ìƒì„±
        yaml_path = os.path.join(self.temp_dir, "dataset.yaml")
        self._create_yaml(yaml_path)
        
        print(f"   ë³€í™˜ ì™„ë£Œ: {converted_count}ê°œ íŒŒì¼")
        print(f"   ì„ì‹œ ë°ì´í„°ì…‹: {self.temp_dir}")
        
        return yaml_path
    
    def _convert_json_to_yolo(self, json_path, img_path):
        """JSON ë¼ë²¨ì„ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        img = Image.open(img_path)
        img_width, img_height = img.size
        
        # JSON íŒŒì‹±
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        yolo_annotations = []
        shapes = data.get("shapes", [])
        
        for shape in shapes:
            label = shape.get("label", "")
            points = shape.get("points", [])
            shape_type = shape.get("shape_type", "")
            
            if label in self.classes and (shape_type == "polygon" or shape_type == "rectangle"):
                class_id = self.classes.index(label)
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                x_coords = [p[0] for p in points]
                y_coords = [p[1] for p in points]
                
                x_min, x_max = min(x_coords), max(x_coords)
                y_min, y_max = min(y_coords), max(y_coords)
                
                # YOLO í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
                x_center = (x_min + x_max) / (2 * img_width)
                y_center = (y_min + y_max) / (2 * img_height)
                width = (x_max - x_min) / img_width
                height = (y_max - y_min) / img_height
                
                yolo_annotation = f"{class_id} {x_center} {y_center} {width} {height}"
                yolo_annotations.append(yolo_annotation)
        
        return yolo_annotations
    
    def _create_yaml(self, yaml_path):
        """YOLO ë°ì´í„°ì…‹ YAML íŒŒì¼ ìƒì„±"""
        yaml_content = f"""
path: {self.temp_dir}
train: images
val: images

nc: {len(self.classes)}
names: {self.classes}
"""
        with open(yaml_path, 'w') as f:
            f.write(yaml_content)
    
    def add_model(self, model_path, model_name=None):
        """ë²¤ì¹˜ë§ˆí¬í•  ëª¨ë¸ ì¶”ê°€"""
        if model_name is None:
            model_name = os.path.splitext(os.path.basename(model_path))[0]
        
        print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ: {model_name}")
        try:
            model = YOLO(model_path)
            model_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            
            # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
            param_count = sum(p.numel() for p in model.model.parameters())
            
            self.models[model_name] = {
                'model': model,
                'path': model_path,
                'size_mb': model_size,
                'parameters': param_count
            }
            print(f"   í¬ê¸°: {model_size:.2f} MB")
            print(f"   íŒŒë¼ë¯¸í„°: {param_count:,}ê°œ")
            
        except Exception as e:
            print(f"   âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _calculate_accuracy_manual(self, model, yaml_path):
        """ì§ì ‘ ì¶”ë¡ ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚° (í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì—†ì´)"""
        # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë¡œë“œ
        images_dir = os.path.join(os.path.dirname(yaml_path), "images")
        labels_dir = os.path.join(os.path.dirname(yaml_path), "labels")
        
        img_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        all_predictions = []
        all_targets = []
        
        for img_file in img_files:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = os.path.join(images_dir, img_file)
            img = Image.open(img_path)
            
            # ì¶”ë¡  ì‹¤í–‰ (í•™ìŠµ ì—†ì´)
            results = model(img, verbose=False, device='cpu', conf=0.25, iou=0.45)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
            if len(results) > 0 and hasattr(results[0], 'boxes') and results[0].boxes is not None:
                boxes = results[0].boxes
                
                # ì•ˆì „í•˜ê²Œ í…ì„œ í™•ì¸
                if hasattr(boxes, 'xyxy') and boxes.xyxy is not None and len(boxes.xyxy) > 0:
                    pred_boxes = boxes.xyxy.cpu().numpy()
                    pred_confs = boxes.conf.cpu().numpy() if hasattr(boxes, 'conf') and boxes.conf is not None else np.array([])
                    pred_classes = boxes.cls.cpu().numpy() if hasattr(boxes, 'cls') and boxes.cls is not None else np.array([])
                    
                    # ì •ê·œí™” (ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë‚˜ëˆ„ê¸°)
                    if pred_boxes.shape[0] > 0:
                        img_w, img_h = img.size
                        pred_boxes[:, [0, 2]] /= img_w  # x ì¢Œí‘œë“¤
                        pred_boxes[:, [1, 3]] /= img_h  # y ì¢Œí‘œë“¤
                    
                    for i in range(pred_boxes.shape[0]):
                        all_predictions.append({
                            'bbox': pred_boxes[i],
                            'conf': float(pred_confs[i]) if i < len(pred_confs) else 1.0,
                            'class': int(pred_classes[i]) if i < len(pred_classes) else 0,
                            'image': img_file
                        })
            
            # ì‹¤ì œ ë¼ë²¨ ë¡œë“œ
            label_file = os.path.splitext(img_file)[0] + '.txt'
            label_path = os.path.join(labels_dir, label_file)
            
            if os.path.exists(label_path):
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                
                img_w, img_h = img.size
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        x_center, y_center, width, height = map(float, parts[1:5])
                        
                        # YOLO í˜•ì‹ì„ xyxyë¡œ ë³€í™˜
                        x1 = x_center - width/2
                        y1 = y_center - height/2
                        x2 = x_center + width/2
                        y2 = y_center + height/2
                        
                        all_targets.append({
                            'bbox': np.array([x1, y1, x2, y2]),
                            'class': class_id,
                            'image': img_file
                        })
        
        # ê°„ë‹¨í•œ mAP ê³„ì‚°
        if len(all_predictions) == 0 or len(all_targets) == 0:
            return 0.0, 0.0, 0.0, 0.0
        
        print(f"   ì˜ˆì¸¡: {len(all_predictions)}ê°œ, ì‹¤ì œ: {len(all_targets)}ê°œ")
        
        # IoU ì„ê³„ê°’ë³„ ì •í™•ë„ ê³„ì‚°
        total_tp = 0
        total_fp = 0
        matched_targets = set()  # ë§¤ì¹­ëœ íƒ€ê²Ÿ ì¶”ì 
        
        for pred in all_predictions:
            best_iou = 0
            best_target_idx = None
            
            # ê°™ì€ ì´ë¯¸ì§€ì˜ ê°™ì€ í´ë˜ìŠ¤ íƒ€ê²Ÿë“¤ê³¼ ë¹„êµ
            for idx, target in enumerate(all_targets):
                if (target['image'] == pred['image'] and 
                    target['class'] == pred['class'] and
                    idx not in matched_targets):
                    
                    # IoU ê³„ì‚°
                    iou = self._calculate_iou(pred['bbox'], target['bbox'])
                    if iou > best_iou:
                        best_iou = iou
                        best_target_idx = idx
            
            # IoU > 0.5ì´ë©´ True Positive
            if best_iou > 0.5 and best_target_idx is not None:
                total_tp += 1
                matched_targets.add(best_target_idx)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
            else:
                total_fp += 1
        
        total_fn = len(all_targets) - len(matched_targets)  # ë§¤ì¹­ë˜ì§€ ì•Šì€ íƒ€ê²Ÿë“¤
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0
        recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0
        map50 = (precision + recall) / 2 if (precision + recall) > 0 else 0.0  # ê°„ë‹¨í•œ ê·¼ì‚¬
        map50_95 = map50 * 0.8  # ê·¼ì‚¬ê°’
        
        return map50, map50_95, precision, recall
    
    def _calculate_iou(self, box1, box2):
        """ë‘ ë°•ìŠ¤ ê°„ì˜ IoU ê³„ì‚°"""
        # êµì§‘í•© ì˜ì—­ ê³„ì‚°
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        # ê° ë°•ìŠ¤ì˜ ë©´ì 
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        
        # í•©ì§‘í•© ë©´ì 
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def benchmark_model(self, model_name, yaml_path):
        """ê°œë³„ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ§ª {model_name} ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
        
        model_info = self.models[model_name]
        model = model_info['model']
        
        # ì •í™•ë„ í‰ê°€ - ì§ì ‘ ì¶”ë¡ ìœ¼ë¡œ ê³„ì‚°
        print("   ì •í™•ë„ ì¸¡ì • ì¤‘...")
        try:
            map50, map50_95, precision, recall = self._calculate_accuracy_manual(model, yaml_path)
            
        except Exception as e:
            print(f"   âŒ ì •í™•ë„ ì¸¡ì • ì‹¤íŒ¨: {e}")
            map50 = map50_95 = precision = recall = 0.0
        
        # ì†ë„ ì¸¡ì •
        print("   ì†ë„ ì¸¡ì • ì¤‘...")
        try:
            # ì›Œë°ì—…
            dummy_img = np.random.randint(0, 255, (180, 320, 3), dtype=np.uint8)
            for _ in range(5):
                _ = model(dummy_img, verbose=False, device='cpu')
            
            # ì‹¤ì œ ì†ë„ ì¸¡ì •
            times = []
            images_dir = os.path.join(os.path.dirname(yaml_path), "images")
            img_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            
            for i, img_file in enumerate(img_files[:50]):  # ìµœëŒ€ 50ì¥ìœ¼ë¡œ ì†ë„ ì¸¡ì •
                img_path = os.path.join(images_dir, img_file)
                img = Image.open(img_path)
                
                start_time = time.time()
                _ = model(img, verbose=False, device='cpu')
                end_time = time.time()
                
                times.append(end_time - start_time)
            
            avg_time = np.mean(times) * 1000  # ms
            fps = 1000 / avg_time
            
        except Exception as e:
            print(f"   âŒ ì†ë„ ì¸¡ì • ì‹¤íŒ¨: {e}")
            avg_time = fps = 0.0
        
        # ê²°ê³¼ ì €ì¥
        self.results[model_name] = {
            'model_size_mb': model_info['size_mb'],
            'parameters': model_info['parameters'],
            'map50': map50,
            'map50_95': map50_95,
            'precision': precision,
            'recall': recall,
            'avg_time_ms': avg_time,
            'fps': fps,
            'efficiency_map_mb': map50 / model_info['size_mb'] if model_info['size_mb'] > 0 else 0,
            'efficiency_map_ms': map50 / avg_time if avg_time > 0 else 0,
            'efficiency_score': (map50 * fps) / model_info['size_mb'] if model_info['size_mb'] > 0 else 0
        }
        
        print(f"   mAP50: {map50:.3f}")
        print(f"   ì†ë„: {fps:.1f} FPS ({avg_time:.1f}ms)")
        print(f"   íš¨ìœ¨ì„±: {self.results[model_name]['efficiency_score']:.2f}")
    
    def run_benchmark(self, model_paths, model_names=None):
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ YOLO ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 50)
        
        # ëª¨ë¸ ë¡œë“œ
        if model_names is None:
            model_names = [None] * len(model_paths)
        
        for model_path, model_name in zip(model_paths, model_names):
            self.add_model(model_path, model_name)
        
        if not self.models:
            print("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        yaml_path = self.prepare_test_data()
        
        # ê° ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
        for model_name in self.models.keys():
            self.benchmark_model(model_name, yaml_path)
        
        # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
        self._print_results()
        self._create_comparison_chart()
        
        # ì •ë¦¬
        if self.temp_dir:
            shutil.rmtree(self.temp_dir)
            print(f"\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
    
    def _print_results(self):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(self.results).T
        
        print("\nğŸ¯ ì •í™•ë„ ì§€í‘œ:")
        print("-" * 60)
        for model_name in df.index:
            print(f"{model_name:20} | mAP50: {df.loc[model_name, 'map50']:.3f} | mAP50-95: {df.loc[model_name, 'map50_95']:.3f}")
        
        print("\nâš¡ ì†ë„ ì§€í‘œ:")
        print("-" * 60)
        for model_name in df.index:
            print(f"{model_name:20} | {df.loc[model_name, 'fps']:.1f} FPS | {df.loc[model_name, 'avg_time_ms']:.1f}ms")
        
        print("\nğŸ’¾ íš¨ìœ¨ì„± ì§€í‘œ:")
        print("-" * 60)
        for model_name in df.index:
            print(f"{model_name:20} | í¬ê¸°: {df.loc[model_name, 'model_size_mb']:.1f}MB | íŒŒë¼ë¯¸í„°: {df.loc[model_name, 'parameters']:,}ê°œ")
        
        print("\nğŸ† ì¢…í•© íš¨ìœ¨ì„± (mAPÃ—FPS/í¬ê¸°):")
        print("-" * 60)
        # íš¨ìœ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
        sorted_models = df.sort_values('efficiency_score', ascending=False)
        for i, (model_name, row) in enumerate(sorted_models.iterrows()):
            rank = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else f"{i+1}ìœ„"
            print(f"{rank} {model_name:15} | ì ìˆ˜: {row['efficiency_score']:.2f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤
        print("\nğŸŒŸ ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥:")
        print("-" * 40)
        print(f"ğŸ“ˆ ìµœê³  ì •í™•ë„: {df['map50'].idxmax()} (mAP50: {df['map50'].max():.3f})")
        print(f"âš¡ ìµœê³  ì†ë„: {df['fps'].idxmax()} ({df['fps'].max():.1f} FPS)")
        print(f"ğŸ’¾ ìµœì†Œ í¬ê¸°: {df['model_size_mb'].idxmin()} ({df['model_size_mb'].min():.1f} MB)")
        print(f"ğŸ† ìµœê³  íš¨ìœ¨ì„±: {df['efficiency_score'].idxmax()} (ì ìˆ˜: {df['efficiency_score'].max():.2f})")
    
    def _create_comparison_chart(self):
        """ë¹„êµ ì°¨íŠ¸ ìƒì„± ë° ì €ì¥"""
        try:
            import matplotlib
            matplotlib.use('Agg')  # GUI ì—†ëŠ” ë°±ì—”ë“œ ì‚¬ìš©
            import matplotlib.pyplot as plt
            
            # ì˜ì–´ í°íŠ¸ ì„¤ì •
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
            
            df = pd.DataFrame(self.results).T
            
            if len(df) == 0:
                print("ğŸ“Š ê²°ê³¼ ë°ì´í„°ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"ğŸ“Š ì°¨íŠ¸ ìƒì„± ì‹œì‘... (í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()})")
            
            # 1. ì¢…í•© ë¹„êµ ì°¨íŠ¸ (2x2)
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
            
            # 1-1. ì •í™•ë„ vs ì†ë„
            ax1.scatter(df['fps'], df['map50'], s=150, alpha=0.7, c='blue')
            for i, model in enumerate(df.index):
                ax1.annotate(model, (df.iloc[i]['fps'], df.iloc[i]['map50']), 
                           xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')
            ax1.set_xlabel('FPS (Speed)', fontsize=12)
            ax1.set_ylabel('mAP50 (Accuracy)', fontsize=12)
            ax1.set_title('Accuracy vs Speed Comparison', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3)
            
            # 1-2. ëª¨ë¸ í¬ê¸° vs ì •í™•ë„
            ax2.scatter(df['model_size_mb'], df['map50'], s=150, alpha=0.7, color='orange')
            for i, model in enumerate(df.index):
                ax2.annotate(model, (df.iloc[i]['model_size_mb'], df.iloc[i]['map50']), 
                           xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')
            ax2.set_xlabel('Model Size (MB)', fontsize=12)
            ax2.set_ylabel('mAP50 (Accuracy)', fontsize=12)
            ax2.set_title('Model Size vs Accuracy Comparison', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3)
            
            # 1-3. ì¢…í•© íš¨ìœ¨ì„± ë°”ì°¨íŠ¸
            sorted_df = df.sort_values('efficiency_score', ascending=True)
            bars = ax3.barh(range(len(sorted_df)), sorted_df['efficiency_score'])
            ax3.set_yticks(range(len(sorted_df)))
            ax3.set_yticklabels(sorted_df.index, fontsize=10)
            ax3.set_xlabel('Efficiency Score (mAPÃ—FPS/Size)', fontsize=12)
            ax3.set_title('Overall Efficiency Comparison', fontsize=14, fontweight='bold')
            
            # ë§‰ëŒ€ ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜
            colors = plt.cm.viridis(np.linspace(0, 1, len(bars)))
            for bar, color in zip(bars, colors):
                bar.set_color(color)
            
            # 1-4. ìƒì„¸ ì„±ëŠ¥ ë°”ì°¨íŠ¸
            models = df.index.tolist()
            x = np.arange(len(models))
            width = 0.25
            
            ax4.bar(x - width, df['map50'], width, label='mAP50', alpha=0.8)
            ax4.bar(x, df['fps']/100, width, label='FPS/100', alpha=0.8)  # ìŠ¤ì¼€ì¼ ì¡°ì •
            ax4.bar(x + width, (1/df['model_size_mb'])*10, width, label='1/Size*10', alpha=0.8)  # ì—­ìˆ˜ë¡œ ë³€í™˜
            
            ax4.set_xlabel('Model', fontsize=12)
            ax4.set_ylabel('Normalized Score', fontsize=12)
            ax4.set_title('Detailed Performance Comparison', fontsize=14, fontweight='bold')
            ax4.set_xticks(x)
            ax4.set_xticklabels(models, fontsize=10)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ì €ì¥ ì‹œë„
            try:
                chart_path = os.path.join(os.getcwd(), 'yolo_benchmark_comparison.png')
                plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                print(f"âœ… ì¢…í•© ë¹„êµ ì°¨íŠ¸ ì €ì¥ ì™„ë£Œ: {chart_path}")
            except Exception as save_error:
                print(f"âŒ ì°¨íŠ¸ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                # ëŒ€ì²´ ê²½ë¡œë¡œ ì‹œë„
                alt_path = 'yolo_benchmark_comparison.png'
                plt.savefig(alt_path, dpi=300, bbox_inches='tight')
                print(f"âœ… ëŒ€ì²´ ê²½ë¡œë¡œ ì €ì¥: {alt_path}")
            
            plt.close()
            
            # 2. ê°œë³„ ì§€í‘œ ì°¨íŠ¸ë“¤
            self._create_individual_charts(df)
            
        except Exception as e:
            print(f"âŒ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def _create_individual_charts(self, df):
        """ê°œë³„ ì§€í‘œë³„ ìƒì„¸ ì°¨íŠ¸ ìƒì„±"""
        try:
            # 2-1. ì •í™•ë„ ì§€í‘œ ì°¨íŠ¸
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            models = df.index.tolist()
            x = np.arange(len(models))
            width = 0.35
            
            # mAP50 vs mAP50-95
            ax1.bar(x - width/2, df['map50'], width, label='mAP50', alpha=0.8, color='skyblue')
            ax1.bar(x + width/2, df['map50_95'], width, label='mAP50-95', alpha=0.8, color='lightcoral')
            ax1.set_xlabel('Model', fontsize=12)
            ax1.set_ylabel('Accuracy', fontsize=12)
            ax1.set_title('Accuracy Metrics Comparison', fontsize=14, fontweight='bold')
            ax1.set_xticks(x)
            ax1.set_xticklabels(models, fontsize=10)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # Precision vs Recall
            ax2.bar(x - width/2, df['precision'], width, label='Precision', alpha=0.8, color='lightgreen')
            ax2.bar(x + width/2, df['recall'], width, label='Recall', alpha=0.8, color='orange')
            ax2.set_xlabel('Model', fontsize=12)
            ax2.set_ylabel('Score', fontsize=12)
            ax2.set_title('Precision vs Recall Comparison', fontsize=14, fontweight='bold')
            ax2.set_xticks(x)
            ax2.set_xticklabels(models, fontsize=10)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('yolo_accuracy_metrics.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š ì •í™•ë„ ì§€í‘œ ì°¨íŠ¸ ì €ì¥: yolo_accuracy_metrics.png")
            plt.close()
            
            # 2-2. ì†ë„ ë° íš¨ìœ¨ì„± ì°¨íŠ¸
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # ì†ë„ ë¹„êµ
            bars1 = ax1.bar(models, df['fps'], alpha=0.8, color='purple')
            ax1.set_xlabel('Model', fontsize=12)
            ax1.set_ylabel('FPS', fontsize=12)
            ax1.set_title('Inference Speed Comparison', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3)
            
            # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
            for bar, fps in zip(bars1, df['fps']):
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                        f'{fps:.1f}', ha='center', va='bottom', fontweight='bold')
            
            # ëª¨ë¸ í¬ê¸° ë¹„êµ
            bars2 = ax2.bar(models, df['model_size_mb'], alpha=0.8, color='brown')
            ax2.set_xlabel('Model', fontsize=12)
            ax2.set_ylabel('Size (MB)', fontsize=12)
            ax2.set_title('Model Size Comparison', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3)
            
            # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
            for bar, size in zip(bars2, df['model_size_mb']):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                        f'{size:.1f}MB', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            plt.savefig('yolo_speed_size_metrics.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š ì†ë„/í¬ê¸° ì§€í‘œ ì°¨íŠ¸ ì €ì¥: yolo_speed_size_metrics.png")
            plt.close()
            
            # 2-3. íš¨ìœ¨ì„± ë ˆì´ë” ì°¨íŠ¸
            if len(df) > 1:  # 2ê°œ ì´ìƒ ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ
                self._create_radar_chart(df)
            
            # 2-4. ì¢…í•© ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ì´ë¯¸ì§€
            self._create_summary_table(df)
            
        except Exception as e:
            print(f"ê°œë³„ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _create_radar_chart(self, df):
        """ë ˆì´ë” ì°¨íŠ¸ ìƒì„±"""
        try:
            from math import pi
            
            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
            
            # ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)
            metrics = ['map50', 'fps', 'efficiency_score']
            df_norm = df[metrics].copy()
            
            for col in metrics:
                if df_norm[col].max() > 0:
                    df_norm[col] = df_norm[col] / df_norm[col].max()
            
            # í¬ê¸°ëŠ” ì—­ìˆœ (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if df['model_size_mb'].max() > df['model_size_mb'].min():
                df_norm['size_norm'] = 1 - ((df['model_size_mb'] - df['model_size_mb'].min()) / 
                                          (df['model_size_mb'].max() - df['model_size_mb'].min()))
            else:
                df_norm['size_norm'] = 1.0
            
            # ê°ë„ ì„¤ì •
            categories = ['Accuracy', 'Speed', 'Efficiency', 'Lightness']
            N = len(categories)
            angles = [n / float(N) * 2 * pi for n in range(N)]
            angles += angles[:1]  # ë‹«íŒ ë„í˜• ë§Œë“¤ê¸°
            
            # ê° ëª¨ë¸ë³„ë¡œ ê·¸ë¦¬ê¸°
            colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']
            for i, (model_name, row) in enumerate(df_norm.iterrows()):
                values = [row['map50'], row['fps'], row['efficiency_score'], row['size_norm']]
                values += values[:1]
                
                color = colors[i % len(colors)]
                ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=color)
                ax.fill(angles, values, alpha=0.1, color=color)
            
            # ì¶• ì„¤ì •
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(categories, fontsize=12)
            ax.set_ylim(0, 1)
            ax.set_title('Overall Performance Radar Chart', fontsize=16, fontweight='bold', pad=20)
            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
            ax.grid(True)
            
            plt.tight_layout()
            plt.savefig('yolo_radar_chart.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š ë ˆì´ë” ì°¨íŠ¸ ì €ì¥: yolo_radar_chart.png")
            plt.close()
            
        except Exception as e:
            print(f"ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _create_summary_table(self, df):
        """ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            fig, ax = plt.subplots(figsize=(14, 8))
            ax.axis('tight')
            ax.axis('off')
            
            # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
            table_data = []
            headers = ['Model', 'mAP50', 'mAP50-95', 'FPS', 'Size(MB)', 'Parameters', 'Efficiency']
            
            for model_name, row in df.iterrows():
                table_data.append([
                    model_name,
                    f"{row['map50']:.3f}",
                    f"{row['map50_95']:.3f}",
                    f"{row['fps']:.1f}",
                    f"{row['model_size_mb']:.1f}",
                    f"{int(row['parameters']):,}",
                    f"{row['efficiency_score']:.2f}"
                ])
            
            # í…Œì´ë¸” ìƒì„±
            table = ax.table(cellText=table_data, colLabels=headers, 
                           cellLoc='center', loc='center')
            
            # í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§
            table.auto_set_font_size(False)
            table.set_fontsize(12)
            table.scale(1.2, 2)
            
            # í—¤ë” ìŠ¤íƒ€ì¼
            for i in range(len(headers)):
                table[(0, i)].set_facecolor('#4CAF50')
                table[(0, i)].set_text_props(weight='bold', color='white')
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ (êµëŒ€ë¡œ ìƒ‰ìƒ)
            for i in range(1, len(table_data) + 1):
                for j in range(len(headers)):
                    if i % 2 == 0:
                        table[(i, j)].set_facecolor('#f0f0f0')
                    else:
                        table[(i, j)].set_facecolor('white')
            
            plt.title('YOLO Model Performance Comparison Summary', fontsize=16, fontweight='bold', pad=20)
            plt.savefig('yolo_summary_table.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š ìš”ì•½ í…Œì´ë¸” ì €ì¥: yolo_summary_table.png")
            plt.close()
            
        except Exception as e:
            print(f"ìš”ì•½ í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    # ì„¤ì •
    DATA_DIR = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106"  # ë°ì´í„° í´ë” (JSON+ì´ë¯¸ì§€)
    CLASSES_FILE = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\classes.txt"  # í´ë˜ìŠ¤ íŒŒì¼
    NUM_EVAL_IMAGES = 100  # í‰ê°€ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜
    
    # ê·¸ë˜í”„ ì €ì¥ í´ë” ì„¤ì • (ì›í•˜ëŠ” ê²½ìš°)
    CHART_OUTPUT_DIR = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\8.Pruning"  # ê·¸ë˜í”„ ì €ì¥ í´ë”
    
    # ë¹„êµí•  ëª¨ë¸ë“¤ (ê²½ë¡œ ë¦¬ìŠ¤íŠ¸)
    model_paths = [
        r"C:\Users\KDT-13\Desktop\A100\yolov8_continued.pt",  # ì›ë³¸ ëª¨ë¸
        r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\8.Pruning\ver0\model\pruning_model.pt"  # í”„ë£¨ë‹ ëª¨ë¸ 1
        #r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\8.Pruning\ver2(ê¸°ì¡´í•™ìŠµì½”ë“œë¡œí•´ì„œì˜ëª»ë¨_over_train)\runs\detect\train\weights\best.pt",  # ì¶”ê°€ ëª¨ë¸ë“¤...
        #r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\8.Pruning\ver3(ìƒˆ train code retrain)\retrained_pruned_model.pt",
        #r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\8.Pruning\ver4(ìƒˆ train code over train\retrained_pruned_model.pt"
    ]
    
    # ëª¨ë¸ ì´ë¦„ë“¤ (ì„ íƒì‚¬í•­, Noneì´ë©´ íŒŒì¼ëª… ì‚¬ìš©)
    model_names = [
        "0",
        "1"
        #"2",
        #"3",
        #"4"
    ]
    
    # ì‹¤í–‰ ì „ ê²½ë¡œ í™•ì¸
    print("ğŸ” ê²½ë¡œ í™•ì¸ ì¤‘...")
    
    # ë°ì´í„° í´ë” í™•ì¸
    if not os.path.exists(DATA_DIR):
        print(f"âŒ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {DATA_DIR}")
        return
    
    # í´ë˜ìŠ¤ íŒŒì¼ í™•ì¸
    if not os.path.exists(CLASSES_FILE):
        print(f"âŒ í´ë˜ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {CLASSES_FILE}")
        return
    
    # ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
    for i, model_path in enumerate(model_paths):
        if not os.path.exists(model_path):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_names[i]} - {model_path}")
            return
        else:
            print(f"âœ… {model_names[i]}: {model_path}")
    
    # ê·¸ë˜í”„ ì €ì¥ í´ë” ìƒì„±
    os.makedirs(CHART_OUTPUT_DIR, exist_ok=True)
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ê·¸ë˜í”„ ì €ì¥ í´ë”ë¡œ ë³€ê²½
    original_dir = os.getcwd()
    os.chdir(CHART_OUTPUT_DIR)
    
    print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥ ìœ„ì¹˜: {CHART_OUTPUT_DIR}")
    
    try:
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        benchmark = YOLOBenchmark(
            data_dir=DATA_DIR,
            classes_file=CLASSES_FILE, 
            num_eval_images=NUM_EVAL_IMAGES
        )
        
        benchmark.run_benchmark(model_paths, model_names)
        
    except Exception as e:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # ì›ë˜ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ë³µì›
        os.chdir(original_dir)

if __name__ == "__main__":
    main()