# 📊 YOLOv8 세그멘테이션 모델 성능 분석 (model_seg_ver3)

<div style="text-align: center; font-style: italic; margin-bottom: 20px;">
산업 안전 모니터링을 위한 고성능 객체 인식 시스템
</div>

---

## 📈 model_seg_ver3와 seg_ver1의 주요 차이점

### 🔹 모델 개선사항
- **✨ 세그멘테이션 모델 구조 최적화**: 두 모델 모두 세그멘테이션 기반이지만, ver3는 향상된 레이어 구조와 최적화된 매개변수를 사용
- **✨ 향상된 경계 인식**: 더 개선된 세그멘테이션 알고리즘으로 객체의 정확한 외곽선 인식 성능 향상
- **✨ 다중 카메라 통합 방식 개선**: cam1, cam2 데이터의 효율적인 통합 처리 방식 적용

### 🔹 성능 향상
- **🚀 전체 mAP@0.5**: 0.821 → 0.983/0.984 (크게 향상)
- **🚀 forklift-vertical**: 0.359 → 0.995 (극적인 향상)
- **🚀 person**: 0.955 → 0.969/0.977 (소폭 향상)
- **🚀 새로운 클래스 'object'** 추가 및 높은 성능(0.995) 달성

---

## 📋 주요 성능 요약

YOLOv8 세그멘테이션 모델(model_seg_ver3)은 전체 mAP@0.5가 **0.983-0.984**로 이전 모델 버전에 비해 상당한 성능 향상을 보여주고 있습니다. 모든 객체 클래스에서 0.9 이상의 정밀도(Precision)와 재현율(Recall)을 달성했으며, 대부분의 클래스는 0.995에 가까운 거의 완벽한 점수를 기록했습니다. 이 모델은 높은 신뢰도 임계값에서도 안정적인 성능을 보여주어 산업 안전 모니터링 애플리케이션에 매우 적합합니다.

---

## 📊 클래스별 성능 지표

| 클래스 | mAP@0.5 | 정밀도(Precision) | 재현율(Recall) | F1 점수 |
|:--------:|:---------:|:-------------------:|:--------------:|:---------:|
| 🏭 **forklift-vertical** | 0.995 | 1.00 | 1.00 | 1.00 |
| 🏭 **forklift-left** | 0.962 | 0.90 | 0.94 | 0.92 |
| 🏭 **forklift-horizontal** | 0.984 | 0.97 | 0.98 | 0.97 |
| 📷 **forklift-vertical(cam2)** | 0.995 | 1.00 | 1.00 | 1.00 |
| 📷 **forklift-left(cam2)** | 0.995 | 0.67 | 1.00 | 0.80 |
| 📷 **forklift-horizontal(cam2)** | 0.995 | 1.00 | 1.00 | 1.00 |
| 👤 **person** | 0.942-0.951 | 0.94 | 0.93 | 0.93 |
| 📦 **object** | 0.995 | 1.00 | 0.96 | 0.98 |
| **📊 전체(all classes)** | **0.983-0.984** | **1.00** | **0.99** | **0.95-0.96** |

---

## 🧩 혼동 행렬(Confusion Matrix) 분석

혼동 행렬을 분석한 결과, 대부분의 클래스가 매우 높은 정확도로 예측되었습니다:

- **👤 person**: 660개의 인스턴스가 정확하게 감지되어 94% 정확도를 보였으며, 약 6%는 배경(background)으로 분류되었습니다.
- **🏭 forklift-horizontal**: 약 97%의 정확도로 식별되었으며, 3%만이 다른 클래스로 오분류되었습니다.
- **📷 forklift-left(cam2)**: 67%의 정확도를 보였으나, 데이터 샘플 수가 적어 향후 개선의 여지가 있습니다.
- **📦 object**: 매우 높은 정확도(100%)로 식별되었습니다.

이전 버전에서 특히 문제가 되었던 **forklift-vertical** 클래스의 경우 100% 정확도로 큰 개선을 보였습니다.

---

## 📉 신뢰도 분석

- 모델은 신뢰도 약 **0.233**에서 **0.95-0.96**의 최적 F1 점수를 달성했습니다.
- 대부분의 클래스는 신뢰도 0.9 이상에서도 재현율 0.9 이상을 유지했습니다.
- 정밀도 곡선(Precision-Confidence Curve)에서 모든 클래스가 신뢰도 0.2 이상에서 정밀도 0.8 이상을 보여 매우 우수한 성능을 나타냈습니다.

---

## 📈 Precision-Recall 곡선 분석

- 모든 클래스가 넓은 범위의 재현율(0.0-0.9)에서 **1.0에 가까운 정밀도**를 유지했습니다.
- 특히 'forklift-vertical', 'forklift-vertical(cam2)', 'object' 클래스는 **0.995의 mAP**로 최고 성능을 보였습니다.
- 'person' 클래스는 이전 버전보다 개선되었으며, 넓은 재현율 범위에서 높은 정밀도를 유지했습니다.

---

## 📝 종합 평가

### ✅ 강점:
- 모든 클래스에서 mAP@0.5가 0.95 이상으로 매우 우수한 성능을 보였습니다.
- 특히 이전 모델에서 문제가 되었던 'forklift-vertical' 클래스의 극적인 성능 향상이 있었습니다.
- 전체 mAP@0.5는 0.983-0.984로 최고 수준을 달성했습니다.
- 세그멘테이션 모델의 최적화로 객체 경계를 더 정확하게 인식할 수 있게 되었습니다.

### ⚠️ 개선점:
- 'forklift-left(cam2)' 클래스는 67%의 정밀도를 보여 추가 데이터 수집이나 모델 튜닝을 통한 개선이 필요합니다.
- 'person' 클래스의 배경 오분류(6%)를 더 줄일 수 있는 방향으로 개선이 필요합니다.

### 💡 활용 권장사항:
- 신뢰도 임계값 0.233 부근으로 설정하여 최적 F1 점수를 확보하는 것이 좋습니다.
- 세그멘테이션 기반 모델은 더 정확한 객체 경계 식별이 가능하여 정밀한 위치 감지가 필요한 산업 환경에 매우 적합합니다.
- 여러 카메라(cam1, cam2)의 데이터 통합으로 다양한 각도에서의 객체 인식 성능이 향상되었습니다.

### 🎯 결론:
세그멘테이션 모델(model_seg_ver3)은 이전 버전과 비교하여 모든 측면에서 성능이 현저히 향상되었습니다. 특히 forklift-vertical 클래스의 정확도 향상과 전체 mAP의 상승(0.821→0.983)은 개선된 세그멘테이션 기술과 모델 최적화의 효과를 명확하게 보여줍니다. 이 모델은 실시간 산업 환경 모니터링, 안전 시스템, 자동화 작업 등에 매우 적합하며 높은 신뢰성을 제공합니다.