"""
ONNX ëª¨ë¸ ì–‘ìí™” ì‹œìŠ¤í…œ (ë²„ì „ í˜¸í™˜ì„± ìˆ˜ì •)
í”„ë£¨ë‹ëœ YOLO ëª¨ë¸ì„ INT8ë¡œ ì–‘ìí™”í•˜ì—¬ í¬ê¸° ë° ì†ë„ ìµœì í™”

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:
pip install onnxruntime onnx onnxruntime-tools
"""

import os
import numpy as np
import cv2
import onnx
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, QuantType
from onnxruntime.quantization import quantize_static, CalibrationDataReader
import time
import glob
from pathlib import Path
import shutil

class YOLOCalibrationDataReader(CalibrationDataReader):
    """YOLO ëª¨ë¸ìš© Calibration ë°ì´í„° ë¦¬ë”"""
    
    def __init__(self, calibration_data, input_name):
        self.data = calibration_data
        self.input_name = input_name
        self.current_index = 0
    
    def get_next(self):
        if self.current_index < len(self.data):
            input_data = {self.input_name: self.data[self.current_index]}
            self.current_index += 1
            return input_data
        else:
            return None
    
    def rewind(self):
        self.current_index = 0

class ONNXQuantizer:
    def __init__(self, original_model_path, output_dir="quantized_models"):
        """
        ONNX ëª¨ë¸ ì–‘ìí™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            original_model_path: ì›ë³¸ ONNX ëª¨ë¸ ê²½ë¡œ
            output_dir: ì–‘ìí™”ëœ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.original_model_path = original_model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ì…ë ¥ ì´ë¦„ í™•ì¸
        session = ort.InferenceSession(original_model_path)
        self.input_name = session.get_inputs()[0].name
        
        # ëª¨ë¸ ì •ë³´ í™•ì¸
        self.verify_original_model()
        
        print(f"ğŸš€ ONNX ì–‘ìí™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ì›ë³¸ ëª¨ë¸: {original_model_path}")
        print(f"   ì…ë ¥ ì´ë¦„: {self.input_name}")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    def verify_original_model(self):
        """ì›ë³¸ ëª¨ë¸ ê²€ì¦"""
        if not os.path.exists(self.original_model_path):
            raise FileNotFoundError(f"ì›ë³¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.original_model_path}")
        
        # ëª¨ë¸ í¬ê¸° í™•ì¸
        size_mb = os.path.getsize(self.original_model_path) / (1024 * 1024)
        print(f"ğŸ“Š ì›ë³¸ ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
        
        # ONNX ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
        try:
            model = onnx.load(self.original_model_path)
            onnx.checker.check_model(model)
            print("âœ… ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
        except Exception as e:
            raise RuntimeError(f"ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def dynamic_quantization(self):
        """
        ë™ì  ì–‘ìí™” ìˆ˜í–‰ (INT8) - ë²„ì „ í˜¸í™˜ì„± ê°œì„ 
        Calibration ë°ì´í„° ë¶ˆí•„ìš”, ë¹ ë¥´ê³  ê°„ë‹¨
        """
        print(f"\nğŸ”„ ë™ì  ì–‘ìí™” ì‹œì‘ (INT8)")
        print("=" * 50)
        
        output_path = self.output_dir / "model_dynamic_int8.onnx"
        
        try:
            start_time = time.perf_counter()
            
            # ìµœì†Œí•œì˜ íŒŒë¼ë¯¸í„°ë¡œ ë™ì  ì–‘ìí™” ìˆ˜í–‰
            quantize_dynamic(
                model_input=str(self.original_model_path),
                model_output=str(output_path),
                weight_type=QuantType.QInt8
            )
            
            elapsed_time = time.perf_counter() - start_time
            
            # ê²°ê³¼ í™•ì¸
            if output_path.exists():
                original_size = os.path.getsize(self.original_model_path) / (1024 * 1024)
                quantized_size = os.path.getsize(output_path) / (1024 * 1024)
                compression_ratio = original_size / quantized_size
                
                print(f"âœ… ë™ì  ì–‘ìí™” ì™„ë£Œ!")
                print(f"   ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"   ì›ë³¸ í¬ê¸°: {original_size:.2f} MB")
                print(f"   ì–‘ìí™” í›„: {quantized_size:.2f} MB")
                print(f"   ì••ì¶• ë¹„ìœ¨: {compression_ratio:.2f}ë°°")
                print(f"   í¬ê¸° ê°ì†Œ: {(1-quantized_size/original_size)*100:.1f}%")
                print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
                
                return str(output_path)
            else:
                raise RuntimeError("ì–‘ìí™”ëœ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ë™ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
            return None
    
    def create_calibration_dataset(self, image_dir, num_images=100, input_size=(320, 192)):
        """
        Calibration ë°ì´í„°ì…‹ ìƒì„± (ì •ì  ì–‘ìí™”ìš©)
        
        Args:
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            num_images: ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜
            input_size: ëª¨ë¸ ì…ë ¥ í¬ê¸° (width, height)
        """
        print(f"\nğŸ“ Calibration ë°ì´í„°ì…‹ ìƒì„±")
        print(f"   ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {image_dir}")
        print(f"   ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜: {num_images}")
        print(f"   ì…ë ¥ í¬ê¸°: {input_size}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        image_files = []
        
        for ext in image_extensions:
            pattern = os.path.join(image_dir, "**", ext)
            image_files.extend(glob.glob(pattern, recursive=True))
        
        if len(image_files) == 0:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        # í•„ìš”í•œ ìˆ˜ë§Œí¼ ì„ íƒ
        selected_images = image_files[:min(num_images, len(image_files))]
        print(f"   ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        print(f"   ì„ íƒëœ ì´ë¯¸ì§€: {len(selected_images)}ê°œ")
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒì„±
        calibration_data = []
        input_width, input_height = input_size
        
        print(f"   ì „ì²˜ë¦¬ ì¤‘...")
        for i, img_path in enumerate(selected_images):
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ (detecting_ver3.pyì™€ ë™ì¼)
                img = cv2.imread(img_path)
                if img is None:
                    continue
                
                # BGR â†’ RGB
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                original_h, original_w = img_rgb.shape[:2]
                
                # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                scale = min(input_width / original_w, input_height / original_h)
                new_w, new_h = int(original_w * scale), int(original_h * scale)
                resized = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
                
                # íŒ¨ë”©
                top_pad = (input_height - new_h) // 2
                bottom_pad = input_height - new_h - top_pad
                left_pad = (input_width - new_w) // 2
                right_pad = input_width - new_w - left_pad
                
                padded = cv2.copyMakeBorder(
                    resized, top_pad, bottom_pad, left_pad, right_pad,
                    cv2.BORDER_CONSTANT, value=(114, 114, 114)
                )
                
                # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
                tensor = padded.astype(np.float32) / 255.0
                tensor = np.transpose(tensor, (2, 0, 1))  # HWC â†’ CHW
                tensor = np.expand_dims(tensor, axis=0)   # ë°°ì¹˜ ì°¨ì›
                
                calibration_data.append(tensor)
                
                if (i + 1) % 20 == 0:
                    print(f"      ì§„í–‰ë¥ : {i+1}/{len(selected_images)}")
                    
            except Exception as e:
                print(f"      ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ({img_path}): {e}")
                continue
        
        print(f"   âœ… Calibration ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(calibration_data)}ê°œ")
        return calibration_data
    
    def static_quantization(self, image_dir, num_images=100, input_size=(320, 192)):
        """
        ì •ì  ì–‘ìí™” ìˆ˜í–‰ (INT8) - ì„ì‹œ íŒŒì¼ ì²˜ë¦¬ ê°œì„ 
        Calibration ë°ì´í„° í•„ìš”, ë” ì •í™•í•œ ì–‘ìí™”
        """
        print(f"\nğŸ”„ ì •ì  ì–‘ìí™” ì‹œì‘ (INT8)")
        print("=" * 50)
        
        output_path = self.output_dir / "model_static_int8.onnx"
        
        try:
            # Calibration ë°ì´í„° ìƒì„±
            calibration_data = self.create_calibration_dataset(
                image_dir, num_images, input_size
            )
            
            if len(calibration_data) == 0:
                raise RuntimeError("Calibration ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # Calibration ë°ì´í„° ë¦¬ë” ìƒì„±
            data_reader = YOLOCalibrationDataReader(calibration_data, self.input_name)
            
            print(f"   ì •ì  ì–‘ìí™” ìˆ˜í–‰ ì¤‘...")
            start_time = time.perf_counter()
            
            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ (ì•ˆì „í•œ ì´ë¦„ìœ¼ë¡œ)
            temp_model_path = self.output_dir / "temp_model_for_quantization.onnx"
            shutil.copy2(self.original_model_path, temp_model_path)
            
            # ìµœì†Œí•œì˜ íŒŒë¼ë¯¸í„°ë¡œ ì •ì  ì–‘ìí™” ìˆ˜í–‰
            quantize_static(
                model_input=str(temp_model_path),
                model_output=str(output_path),
                calibration_data_reader=data_reader
            )
            
            # ì„ì‹œ íŒŒì¼ ì œê±°
            if temp_model_path.exists():
                temp_model_path.unlink()
            
            elapsed_time = time.perf_counter() - start_time
            
            # ê²°ê³¼ í™•ì¸
            if output_path.exists():
                original_size = os.path.getsize(self.original_model_path) / (1024 * 1024)
                quantized_size = os.path.getsize(output_path) / (1024 * 1024)
                compression_ratio = original_size / quantized_size
                
                print(f"âœ… ì •ì  ì–‘ìí™” ì™„ë£Œ!")
                print(f"   ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"   ì‚¬ìš©ëœ ì´ë¯¸ì§€: {len(calibration_data)}ê°œ")
                print(f"   ì›ë³¸ í¬ê¸°: {original_size:.2f} MB")
                print(f"   ì–‘ìí™” í›„: {quantized_size:.2f} MB")
                print(f"   ì••ì¶• ë¹„ìœ¨: {compression_ratio:.2f}ë°°")
                print(f"   í¬ê¸° ê°ì†Œ: {(1-quantized_size/original_size)*100:.1f}%")
                print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
                
                return str(output_path)
            else:
                raise RuntimeError("ì–‘ìí™”ëœ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ì •ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
            return None
    
    def benchmark_models(self, test_image_path, num_runs=50):
        """
        ì›ë³¸ vs ì–‘ìí™” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        """
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("=" * 50)
        
        results = {}
        
        # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ë“¤
        models_to_test = [
            ("ì›ë³¸", self.original_model_path),
        ]
        
        # ì–‘ìí™”ëœ ëª¨ë¸ë“¤ ì¶”ê°€
        dynamic_path = self.output_dir / "model_dynamic_int8.onnx"
        if dynamic_path.exists():
            models_to_test.append(("ë™ì  INT8", str(dynamic_path)))
        
        static_path = self.output_dir / "model_static_int8.onnx"
        if static_path.exists():
            models_to_test.append(("ì •ì  INT8", str(static_path)))
        
        # ê° ëª¨ë¸ í…ŒìŠ¤íŠ¸
        for model_name, model_path in models_to_test:
            print(f"\nğŸ” {model_name} ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
            
            try:
                # ì„¸ì…˜ ìƒì„±
                session = ort.InferenceSession(model_path)
                input_name = session.get_inputs()[0].name
                output_name = session.get_outputs()[0].name
                
                # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                img = cv2.imread(test_image_path)
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                original_h, original_w = img_rgb.shape[:2]
                
                # ì „ì²˜ë¦¬ (detecting_ver3.pyì™€ ë™ì¼)
                scale = min(320 / original_w, 192 / original_h)
                new_w, new_h = int(original_w * scale), int(original_h * scale)
                resized = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
                
                top_pad = (192 - new_h) // 2
                bottom_pad = 192 - new_h - top_pad
                left_pad = (320 - new_w) // 2
                right_pad = 320 - new_w - left_pad
                
                padded = cv2.copyMakeBorder(
                    resized, top_pad, bottom_pad, left_pad, right_pad,
                    cv2.BORDER_CONSTANT, value=(114, 114, 114)
                )
                
                tensor = padded.astype(np.float32) / 255.0
                tensor = np.transpose(tensor, (2, 0, 1))
                tensor = np.expand_dims(tensor, axis=0)
                
                # ì›Œë°ì—…
                for _ in range(5):
                    _ = session.run([output_name], {input_name: tensor})
                
                # ë²¤ì¹˜ë§ˆí¬
                start_time = time.perf_counter()
                for _ in range(num_runs):
                    output = session.run([output_name], {input_name: tensor})
                end_time = time.perf_counter()
                
                avg_time = (end_time - start_time) / num_runs * 1000
                fps = 1000 / avg_time
                
                # ëª¨ë¸ í¬ê¸°
                size_mb = os.path.getsize(model_path) / (1024 * 1024)
                
                results[model_name] = {
                    'time_ms': avg_time,
                    'fps': fps,
                    'size_mb': size_mb,
                    'output': output[0]
                }
                
                print(f"   â±ï¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
                print(f"   ğŸš€ FPS: {fps:.1f}")
                print(f"   ğŸ’¾ ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
                
            except Exception as e:
                print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results[model_name] = None
        
        # ë¹„êµ ê²°ê³¼ ì¶œë ¥
        self.print_comparison(results)
        return results
    
    def print_comparison(self, results):
        """ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("=" * 70)
        
        valid_results = {k: v for k, v in results.items() if v is not None}
        
        if len(valid_results) < 2:
            print("ë¹„êµí•  ëª¨ë¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # ê¸°ì¤€ ëª¨ë¸ (ì›ë³¸)
        baseline = valid_results.get("ì›ë³¸")
        if baseline is None:
            baseline = list(valid_results.values())[0]
            baseline_name = list(valid_results.keys())[0]
        else:
            baseline_name = "ì›ë³¸"
        
        print(f"ê¸°ì¤€ ëª¨ë¸: {baseline_name}")
        print("-" * 70)
        print(f"{'ëª¨ë¸':<12} {'í¬ê¸°(MB)':<10} {'ì‹œê°„(ms)':<10} {'FPS':<8} {'ì†ë„ í–¥ìƒ':<10} {'í¬ê¸° ê°ì†Œ'}")
        print("-" * 70)
        
        for name, result in valid_results.items():
            if result is None:
                continue
            
            speed_improvement = baseline['time_ms'] / result['time_ms']
            size_reduction = (1 - result['size_mb'] / baseline['size_mb']) * 100
            
            print(f"{name:<12} {result['size_mb']:<10.2f} {result['time_ms']:<10.2f} "
                  f"{result['fps']:<8.1f} {speed_improvement:<10.2f}x {size_reduction:<6.1f}%")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    # ========================================
    # ğŸ”§ ì„¤ì • ìˆ˜ì •
    # ========================================
    
    ORIGINAL_MODEL_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\6.ONNX\To_ONNX_ver6(í”„ë£¨ë‹ëª¨ë¸_Test7)\yolov8_custom_fixed_test7_pruned.onnx"
    OUTPUT_DIR = "quantized_models"
    
    # Calibration ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ì •ì  ì–‘ìí™”ìš©)
    CALIBRATION_IMAGE_DIR = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106"
    NUM_CALIBRATION_IMAGES = 100  # ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì„±ëŠ¥ ë¹„êµìš©)
    TEST_IMAGE_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106\frame_000000.jpg"
    
    # ëª¨ë¸ ì…ë ¥ í¬ê¸°
    INPUT_SIZE = (320, 192)  # (width, height)
    
    # ========================================
    
    print("ğŸš€ ONNX ëª¨ë¸ ì–‘ìí™” ì‹œì‘")
    print("=" * 60)
    
    try:
        # ì–‘ìí™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        quantizer = ONNXQuantizer(ORIGINAL_MODEL_PATH, OUTPUT_DIR)
        
        # 1ë‹¨ê³„: ë™ì  ì–‘ìí™” (ë¹ ë¥´ê³  ê°„ë‹¨)
        print(f"\n1ï¸âƒ£ ë™ì  ì–‘ìí™” ìˆ˜í–‰")
        dynamic_model = quantizer.dynamic_quantization()
        
        if dynamic_model:
            print(f"âœ… ë™ì  ì–‘ìí™” ì„±ê³µ: {dynamic_model}")
        else:
            print(f"âŒ ë™ì  ì–‘ìí™” ì‹¤íŒ¨")
        
        # 2ë‹¨ê³„: ì •ì  ì–‘ìí™” (ë” ì •í™•, calibration í•„ìš”)
        print(f"\n2ï¸âƒ£ ì •ì  ì–‘ìí™” ìˆ˜í–‰")
        
        if os.path.exists(CALIBRATION_IMAGE_DIR):
            static_model = quantizer.static_quantization(
                image_dir=CALIBRATION_IMAGE_DIR,
                num_images=NUM_CALIBRATION_IMAGES,
                input_size=INPUT_SIZE
            )
            
            if static_model:
                print(f"âœ… ì •ì  ì–‘ìí™” ì„±ê³µ: {static_model}")
            else:
                print(f"âŒ ì •ì  ì–‘ìí™” ì‹¤íŒ¨")
        else:
            print(f"âŒ Calibration ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CALIBRATION_IMAGE_DIR}")
            print(f"   ì •ì  ì–‘ìí™”ë¥¼ ê±´ë„ˆë›°ê³  ë™ì  ì–‘ìí™”ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
        # 3ë‹¨ê³„: ì„±ëŠ¥ ë¹„êµ
        print(f"\n3ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        
        if os.path.exists(TEST_IMAGE_PATH):
            results = quantizer.benchmark_models(TEST_IMAGE_PATH, num_runs=50)
            
            if results:
                print(f"\nğŸ‰ ì–‘ìí™” ì™„ë£Œ!")
                print(f"ğŸ“‚ ìƒì„±ëœ ëª¨ë¸ë“¤:")
                
                # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸
                output_dir = Path(OUTPUT_DIR)
                for model_file in output_dir.glob("*.onnx"):
                    size_mb = os.path.getsize(model_file) / (1024 * 1024)
                    print(f"   {model_file.name}: {size_mb:.2f} MB")
                
                print(f"\nğŸ’¡ ì‚¬ìš© ê¶Œì¥ì‚¬í•­:")
                print(f"   - ì†ë„ ìš°ì„ : ë™ì  ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©")
                print(f"   - ì •í™•ë„ ìš°ì„ : ì •ì  ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©")
                print(f"   - detecting_ver3.pyì—ì„œ ëª¨ë¸ ê²½ë¡œë§Œ ë³€ê²½í•˜ì—¬ í…ŒìŠ¤íŠ¸")
        else:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_IMAGE_PATH}")
            print(f"   ì„±ëŠ¥ ë¹„êµë¥¼ ê±´ë„ˆë›°ê³  ì–‘ìí™”ë§Œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ì–‘ìí™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nğŸ ì–‘ìí™” í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")


if __name__ == "__main__":
    main()