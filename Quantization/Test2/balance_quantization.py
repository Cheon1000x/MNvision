"""
ONNX ëª¨ë¸ ëŒ€ì¹­ ì–‘ìí™” ì‹œìŠ¤í…œ (TensorRT í˜¸í™˜)
í”„ë£¨ë‹ëœ YOLO ëª¨ë¸ì„ ëŒ€ì¹­ INT8ë¡œ ì–‘ìí™”í•˜ì—¬ TensorRT í˜¸í™˜ì„± í™•ë³´

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:
pip install onnxruntime onnx onnxruntime-tools
"""

import os
import numpy as np
import cv2
import onnx
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, QuantType, QuantFormat
from onnxruntime.quantization import quantize_static, CalibrationDataReader
import time
import glob
from pathlib import Path
import shutil

class YOLOCalibrationDataReader(CalibrationDataReader):
    """YOLO ëª¨ë¸ìš© Calibration ë°ì´í„° ë¦¬ë”"""
    
    def __init__(self, calibration_data, input_name):
        self.data = calibration_data
        self.input_name = input_name
        self.current_index = 0
    
    def get_next(self):
        if self.current_index < len(self.data):
            input_data = {self.input_name: self.data[self.current_index]}
            self.current_index += 1
            return input_data
        else:
            return None
    
    def rewind(self):
        self.current_index = 0

class SymmetricONNXQuantizer:
    def __init__(self, original_model_path, output_dir="quantized_models_symmetric"):
        """
        ëŒ€ì¹­ ì–‘ìí™” ONNX ëª¨ë¸ ìƒì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            original_model_path: ì›ë³¸ ONNX ëª¨ë¸ ê²½ë¡œ
            output_dir: ì–‘ìí™”ëœ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.original_model_path = original_model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ì…ë ¥ ì´ë¦„ í™•ì¸
        session = ort.InferenceSession(original_model_path)
        self.input_name = session.get_inputs()[0].name
        
        # ëª¨ë¸ ì •ë³´ í™•ì¸
        self.verify_original_model()
        
        print(f"ğŸš€ ëŒ€ì¹­ ì–‘ìí™” ONNX ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ì›ë³¸ ëª¨ë¸: {original_model_path}")
        print(f"   ì…ë ¥ ì´ë¦„: {self.input_name}")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    def verify_original_model(self):
        """ì›ë³¸ ëª¨ë¸ ê²€ì¦"""
        if not os.path.exists(self.original_model_path):
            raise FileNotFoundError(f"ì›ë³¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.original_model_path}")
        
        # ëª¨ë¸ í¬ê¸° í™•ì¸
        size_mb = os.path.getsize(self.original_model_path) / (1024 * 1024)
        print(f"ğŸ“Š ì›ë³¸ ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
        
        # ONNX ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
        try:
            model = onnx.load(self.original_model_path)
            onnx.checker.check_model(model)
            print("âœ… ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
        except Exception as e:
            raise RuntimeError(f"ì›ë³¸ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def symmetric_dynamic_quantization(self):
        """
        ëŒ€ì¹­ ë™ì  ì–‘ìí™” ìˆ˜í–‰ (INT8) - TensorRT í˜¸í™˜
        """
        print(f"\nğŸ”„ ëŒ€ì¹­ ë™ì  ì–‘ìí™” ì‹œì‘ (INT8)")
        print("=" * 50)
        
        output_path = self.output_dir / "model_dynamic_symmetric_int8.onnx"
        
        try:
            start_time = time.perf_counter()
            
            # ëŒ€ì¹­ ì–‘ìí™”ë¡œ ë™ì  ì–‘ìí™” ìˆ˜í–‰ (ë²„ì „ í˜¸í™˜ì„± ê°œì„ )
            quantize_dynamic(
                model_input=str(self.original_model_path),
                model_output=str(output_path),
                weight_type=QuantType.QInt8,
                reduce_range=False   # ëŒ€ì¹­ ì–‘ìí™” ê°•ì œ
            )
            
            elapsed_time = time.perf_counter() - start_time
            
            # ê²°ê³¼ í™•ì¸
            if output_path.exists():
                original_size = os.path.getsize(self.original_model_path) / (1024 * 1024)
                quantized_size = os.path.getsize(output_path) / (1024 * 1024)
                compression_ratio = original_size / quantized_size
                
                print(f"âœ… ëŒ€ì¹­ ë™ì  ì–‘ìí™” ì™„ë£Œ!")
                print(f"   ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"   ì›ë³¸ í¬ê¸°: {original_size:.2f} MB")
                print(f"   ì–‘ìí™” í›„: {quantized_size:.2f} MB")
                print(f"   ì••ì¶• ë¹„ìœ¨: {compression_ratio:.2f}ë°°")
                print(f"   í¬ê¸° ê°ì†Œ: {(1-quantized_size/original_size)*100:.1f}%")
                print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
                
                return str(output_path)
            else:
                raise RuntimeError("ì–‘ìí™”ëœ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ëŒ€ì¹­ ë™ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
            return None
    
    def create_calibration_dataset(self, image_dir, num_images=100, input_size=(320, 192)):
        """
        Calibration ë°ì´í„°ì…‹ ìƒì„± (ì •ì  ì–‘ìí™”ìš©)
        
        Args:
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            num_images: ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜
            input_size: ëª¨ë¸ ì…ë ¥ í¬ê¸° (width, height)
        """
        print(f"\nğŸ“ Calibration ë°ì´í„°ì…‹ ìƒì„±")
        print(f"   ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {image_dir}")
        print(f"   ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜: {num_images}")
        print(f"   ì…ë ¥ í¬ê¸°: {input_size}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        image_files = []
        
        for ext in image_extensions:
            pattern = os.path.join(image_dir, "**", ext)
            image_files.extend(glob.glob(pattern, recursive=True))
        
        if len(image_files) == 0:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        # í•„ìš”í•œ ìˆ˜ë§Œí¼ ì„ íƒ
        selected_images = image_files[:min(num_images, len(image_files))]
        print(f"   ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        print(f"   ì„ íƒëœ ì´ë¯¸ì§€: {len(selected_images)}ê°œ")
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒì„±
        calibration_data = []
        input_width, input_height = input_size
        
        print(f"   ì „ì²˜ë¦¬ ì¤‘...")
        for i, img_path in enumerate(selected_images):
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ (detecting_ver3.pyì™€ ë™ì¼)
                img = cv2.imread(img_path)
                if img is None:
                    continue
                
                # BGR â†’ RGB
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                original_h, original_w = img_rgb.shape[:2]
                
                # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                scale = min(input_width / original_w, input_height / original_h)
                new_w, new_h = int(original_w * scale), int(original_h * scale)
                resized = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
                
                # íŒ¨ë”©
                top_pad = (input_height - new_h) // 2
                bottom_pad = input_height - new_h - top_pad
                left_pad = (input_width - new_w) // 2
                right_pad = input_width - new_w - left_pad
                
                padded = cv2.copyMakeBorder(
                    resized, top_pad, bottom_pad, left_pad, right_pad,
                    cv2.BORDER_CONSTANT, value=(114, 114, 114)
                )
                
                # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
                tensor = padded.astype(np.float32) / 255.0
                tensor = np.transpose(tensor, (2, 0, 1))  # HWC â†’ CHW
                tensor = np.expand_dims(tensor, axis=0)   # ë°°ì¹˜ ì°¨ì›
                
                calibration_data.append(tensor)
                
                if (i + 1) % 20 == 0:
                    print(f"      ì§„í–‰ë¥ : {i+1}/{len(selected_images)}")
                    
            except Exception as e:
                print(f"      ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ({img_path}): {e}")
                continue
        
        print(f"   âœ… Calibration ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(calibration_data)}ê°œ")
        return calibration_data
    
    def symmetric_static_quantization(self, image_dir, num_images=100, input_size=(320, 192)):
        """
        ëŒ€ì¹­ ì •ì  ì–‘ìí™” ìˆ˜í–‰ (INT8) - TensorRT í˜¸í™˜
        """
        print(f"\nğŸ”„ ëŒ€ì¹­ ì •ì  ì–‘ìí™” ì‹œì‘ (INT8)")
        print("=" * 50)
        
        output_path = self.output_dir / "model_static_symmetric_int8.onnx"
        
        try:
            # Calibration ë°ì´í„° ìƒì„±
            calibration_data = self.create_calibration_dataset(
                image_dir, num_images, input_size
            )
            
            if len(calibration_data) == 0:
                raise RuntimeError("Calibration ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # Calibration ë°ì´í„° ë¦¬ë” ìƒì„±
            data_reader = YOLOCalibrationDataReader(calibration_data, self.input_name)
            
            print(f"   ëŒ€ì¹­ ì •ì  ì–‘ìí™” ìˆ˜í–‰ ì¤‘...")
            start_time = time.perf_counter()
            
            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ (ì•ˆì „í•œ ì´ë¦„ìœ¼ë¡œ)
            temp_model_path = self.output_dir / "temp_model_for_symmetric_quantization.onnx"
            shutil.copy2(self.original_model_path, temp_model_path)
            
            # ğŸ¯ ëŒ€ì¹­ ì–‘ìí™” ì„¤ì •ìœ¼ë¡œ ì •ì  ì–‘ìí™” ìˆ˜í–‰ (ë²„ì „ í˜¸í™˜ì„± ê°œì„ )
            quantize_static(
                model_input=str(temp_model_path),
                model_output=str(output_path),
                calibration_data_reader=data_reader,
                quant_format=QuantFormat.QOperator,  # QOperator í˜•ì‹ ì‚¬ìš©
                activation_type=QuantType.QInt8,     # í™œì„±í™” INT8
                weight_type=QuantType.QInt8,         # ê°€ì¤‘ì¹˜ INT8
                reduce_range=False                   # ğŸ”‘ ëŒ€ì¹­ ì–‘ìí™” ê°•ì œ (zero_point = 0)
            )
            
            # ì„ì‹œ íŒŒì¼ ì œê±°
            if temp_model_path.exists():
                temp_model_path.unlink()
            
            elapsed_time = time.perf_counter() - start_time
            
            # ê²°ê³¼ í™•ì¸
            if output_path.exists():
                original_size = os.path.getsize(self.original_model_path) / (1024 * 1024)
                quantized_size = os.path.getsize(output_path) / (1024 * 1024)
                compression_ratio = original_size / quantized_size
                
                print(f"âœ… ëŒ€ì¹­ ì •ì  ì–‘ìí™” ì™„ë£Œ!")
                print(f"   ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"   ì‚¬ìš©ëœ ì´ë¯¸ì§€: {len(calibration_data)}ê°œ")
                print(f"   ì›ë³¸ í¬ê¸°: {original_size:.2f} MB")
                print(f"   ì–‘ìí™” í›„: {quantized_size:.2f} MB")
                print(f"   ì••ì¶• ë¹„ìœ¨: {compression_ratio:.2f}ë°°")
                print(f"   í¬ê¸° ê°ì†Œ: {(1-quantized_size/original_size)*100:.1f}%")
                print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
                
                return str(output_path)
            else:
                raise RuntimeError("ì–‘ìí™”ëœ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ëŒ€ì¹­ ì •ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
            return None
    
    def verify_symmetric_quantization(self, quantized_model_path):
        """
        ëŒ€ì¹­ ì–‘ìí™”ê°€ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ ê²€ì¦
        """
        print(f"\nğŸ” ëŒ€ì¹­ ì–‘ìí™” ê²€ì¦")
        print("=" * 50)
        
        try:
            # ONNX ëª¨ë¸ ë¡œë“œ
            model = onnx.load(quantized_model_path)
            
            # QuantizeLinear ë…¸ë“œë“¤ ì°¾ê¸°
            quantize_nodes = []
            for node in model.graph.node:
                if node.op_type == "QuantizeLinear":
                    quantize_nodes.append(node)
            
            print(f"   ë°œê²¬ëœ QuantizeLinear ë…¸ë“œ: {len(quantize_nodes)}ê°œ")
            
            # Zero point ê²€ì‚¬
            symmetric_count = 0
            asymmetric_count = 0
            
            for node in quantize_nodes:
                # Zero point ì…ë ¥ í™•ì¸ (ë³´í†µ ì„¸ ë²ˆì§¸ ì…ë ¥)
                if len(node.input) >= 3:
                    zero_point_name = node.input[2]
                    
                    # ì´ˆê¸°í™” ê°’ ì°¾ê¸°
                    for initializer in model.graph.initializer:
                        if initializer.name == zero_point_name:
                            # NumPy ë°°ì—´ë¡œ ë³€í™˜
                            zero_point_data = onnx.numpy_helper.to_array(initializer)
                            
                            # ëª¨ë“  ê°’ì´ 0ì¸ì§€ í™•ì¸
                            if np.all(zero_point_data == 0):
                                symmetric_count += 1
                            else:
                                asymmetric_count += 1
                            break
            
            print(f"   ëŒ€ì¹­ ì–‘ìí™” ë…¸ë“œ: {symmetric_count}ê°œ")
            print(f"   ë¹„ëŒ€ì¹­ ì–‘ìí™” ë…¸ë“œ: {asymmetric_count}ê°œ")
            
            if asymmetric_count == 0:
                print(f"   âœ… ì™„ì „í•œ ëŒ€ì¹­ ì–‘ìí™” í™•ì¸! TensorRT í˜¸í™˜ ê°€ëŠ¥")
                return True
            else:
                print(f"   âš ï¸ ì¼ë¶€ ë¹„ëŒ€ì¹­ ì–‘ìí™” ë°œê²¬. TensorRT í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥")
                return False
                
        except Exception as e:
            print(f"   âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def benchmark_models(self, test_image_path, num_runs=50):
        """
        ì›ë³¸ vs ëŒ€ì¹­ ì–‘ìí™” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        """
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("=" * 50)
        
        results = {}
        
        # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ë“¤
        models_to_test = [
            ("ì›ë³¸", self.original_model_path),
        ]
        
        # ì–‘ìí™”ëœ ëª¨ë¸ë“¤ ì¶”ê°€
        dynamic_path = self.output_dir / "model_dynamic_symmetric_int8.onnx"
        if dynamic_path.exists():
            models_to_test.append(("ë™ì  ëŒ€ì¹­ INT8", str(dynamic_path)))
        
        static_path = self.output_dir / "model_static_symmetric_int8.onnx"
        if static_path.exists():
            models_to_test.append(("ì •ì  ëŒ€ì¹­ INT8", str(static_path)))
        
        # ê° ëª¨ë¸ í…ŒìŠ¤íŠ¸
        for model_name, model_path in models_to_test:
            print(f"\nğŸ” {model_name} ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
            
            try:
                # ì„¸ì…˜ ìƒì„±
                session = ort.InferenceSession(model_path)
                input_name = session.get_inputs()[0].name
                output_name = session.get_outputs()[0].name
                
                # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                img = cv2.imread(test_image_path)
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                original_h, original_w = img_rgb.shape[:2]
                
                # ì „ì²˜ë¦¬ (detecting_ver3.pyì™€ ë™ì¼)
                scale = min(320 / original_w, 192 / original_h)
                new_w, new_h = int(original_w * scale), int(original_h * scale)
                resized = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
                
                top_pad = (192 - new_h) // 2
                bottom_pad = 192 - new_h - top_pad
                left_pad = (320 - new_w) // 2
                right_pad = 320 - new_w - left_pad
                
                padded = cv2.copyMakeBorder(
                    resized, top_pad, bottom_pad, left_pad, right_pad,
                    cv2.BORDER_CONSTANT, value=(114, 114, 114)
                )
                
                tensor = padded.astype(np.float32) / 255.0
                tensor = np.transpose(tensor, (2, 0, 1))
                tensor = np.expand_dims(tensor, axis=0)
                
                # ì›Œë°ì—…
                for _ in range(5):
                    _ = session.run([output_name], {input_name: tensor})
                
                # ë²¤ì¹˜ë§ˆí¬
                start_time = time.perf_counter()
                for _ in range(num_runs):
                    output = session.run([output_name], {input_name: tensor})
                end_time = time.perf_counter()
                
                avg_time = (end_time - start_time) / num_runs * 1000
                fps = 1000 / avg_time
                
                # ëª¨ë¸ í¬ê¸°
                size_mb = os.path.getsize(model_path) / (1024 * 1024)
                
                results[model_name] = {
                    'time_ms': avg_time,
                    'fps': fps,
                    'size_mb': size_mb,
                    'output': output[0]
                }
                
                print(f"   â±ï¸ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
                print(f"   ğŸš€ FPS: {fps:.1f}")
                print(f"   ğŸ’¾ ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")
                
            except Exception as e:
                print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results[model_name] = None
        
        # ë¹„êµ ê²°ê³¼ ì¶œë ¥
        self.print_comparison(results)
        return results
    
    def print_comparison(self, results):
        """ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("=" * 70)
        
        valid_results = {k: v for k, v in results.items() if v is not None}
        
        if len(valid_results) < 2:
            print("ë¹„êµí•  ëª¨ë¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # ê¸°ì¤€ ëª¨ë¸ (ì›ë³¸)
        baseline = valid_results.get("ì›ë³¸")
        if baseline is None:
            baseline = list(valid_results.values())[0]
            baseline_name = list(valid_results.keys())[0]
        else:
            baseline_name = "ì›ë³¸"
        
        print(f"ê¸°ì¤€ ëª¨ë¸: {baseline_name}")
        print("-" * 70)
        print(f"{'ëª¨ë¸':<15} {'í¬ê¸°(MB)':<10} {'ì‹œê°„(ms)':<10} {'FPS':<8} {'ì†ë„ í–¥ìƒ':<10} {'í¬ê¸° ê°ì†Œ'}")
        print("-" * 70)
        
        for name, result in valid_results.items():
            if result is None:
                continue
            
            speed_improvement = baseline['time_ms'] / result['time_ms']
            size_reduction = (1 - result['size_mb'] / baseline['size_mb']) * 100
            
            print(f"{name:<15} {result['size_mb']:<10.2f} {result['time_ms']:<10.2f} "
                  f"{result['fps']:<8.1f} {speed_improvement:<10.2f}x {size_reduction:<6.1f}%")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    # ========================================
    # ğŸ”§ ì„¤ì • ìˆ˜ì •
    # ========================================
    
    ORIGINAL_MODEL_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\9.Quantization\Test1\yolov8_custom_fixed_test7_pruned.onnx"
    OUTPUT_DIR = "quantized_models_symmetric"
    
    # Calibration ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ì •ì  ì–‘ìí™”ìš©)
    CALIBRATION_IMAGE_DIR = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106"
    NUM_CALIBRATION_IMAGES = 100  # ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì„±ëŠ¥ ë¹„êµìš©)
    TEST_IMAGE_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106\frame_000000.jpg"
    
    # ëª¨ë¸ ì…ë ¥ í¬ê¸°
    INPUT_SIZE = (320, 192)  # (width, height)
    
    # ========================================
    
    print("ğŸš€ ëŒ€ì¹­ ì–‘ìí™” ONNX ëª¨ë¸ ìƒì„± ì‹œì‘")
    print("=" * 60)
    
    try:
        # ì–‘ìí™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        quantizer = SymmetricONNXQuantizer(ORIGINAL_MODEL_PATH, OUTPUT_DIR)
        
        # 1ë‹¨ê³„: ëŒ€ì¹­ ë™ì  ì–‘ìí™” (ë¹ ë¥´ê³  ê°„ë‹¨)
        print(f"\n1ï¸âƒ£ ëŒ€ì¹­ ë™ì  ì–‘ìí™” ìˆ˜í–‰")
        dynamic_model = quantizer.symmetric_dynamic_quantization()
        
        if dynamic_model:
            print(f"âœ… ëŒ€ì¹­ ë™ì  ì–‘ìí™” ì„±ê³µ: {dynamic_model}")
            # ëŒ€ì¹­ ì–‘ìí™” ê²€ì¦
            quantizer.verify_symmetric_quantization(dynamic_model)
        else:
            print(f"âŒ ëŒ€ì¹­ ë™ì  ì–‘ìí™” ì‹¤íŒ¨")
        
        # 2ë‹¨ê³„: ëŒ€ì¹­ ì •ì  ì–‘ìí™” (ë” ì •í™•)
        print(f"\n2ï¸âƒ£ ëŒ€ì¹­ ì •ì  ì–‘ìí™” ìˆ˜í–‰")
        
        if os.path.exists(CALIBRATION_IMAGE_DIR):
            static_model = quantizer.symmetric_static_quantization(
                image_dir=CALIBRATION_IMAGE_DIR,
                num_images=NUM_CALIBRATION_IMAGES,
                input_size=INPUT_SIZE
            )
            
            if static_model:
                print(f"âœ… ëŒ€ì¹­ ì •ì  ì–‘ìí™” ì„±ê³µ: {static_model}")
                # ëŒ€ì¹­ ì–‘ìí™” ê²€ì¦
                quantizer.verify_symmetric_quantization(static_model)
            else:
                print(f"âŒ ëŒ€ì¹­ ì •ì  ì–‘ìí™” ì‹¤íŒ¨")
        else:
            print(f"âŒ Calibration ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CALIBRATION_IMAGE_DIR}")
            print(f"   ì •ì  ì–‘ìí™”ë¥¼ ê±´ë„ˆë›°ê³  ë™ì  ì–‘ìí™”ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
        # 3ë‹¨ê³„: ì„±ëŠ¥ ë¹„êµ
        print(f"\n3ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        
        if os.path.exists(TEST_IMAGE_PATH):
            results = quantizer.benchmark_models(TEST_IMAGE_PATH, num_runs=50)
            
            if results:
                print(f"\nğŸ‰ ëŒ€ì¹­ ì–‘ìí™” ì™„ë£Œ!")
                print(f"ğŸ“‚ ìƒì„±ëœ ëª¨ë¸ë“¤:")
                
                # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸
                output_dir = Path(OUTPUT_DIR)
                for model_file in output_dir.glob("*.onnx"):
                    size_mb = os.path.getsize(model_file) / (1024 * 1024)
                    print(f"   {model_file.name}: {size_mb:.2f} MB")
                
                print(f"\nğŸ’¡ TensorRT ë³€í™˜ ê¶Œì¥ì‚¬í•­:")
                print(f"   - ëŒ€ì¹­ ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ TensorRT í˜¸í™˜ì„± í™•ë³´")
                print(f"   - build_engine.pyì—ì„œ ëŒ€ì¹­ ì–‘ìí™” ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©")
                print(f"   - zero_point = 0 í™•ì¸ìœ¼ë¡œ ì˜¤ë¥˜ í•´ê²°")
        else:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_IMAGE_PATH}")
            print(f"   ì„±ëŠ¥ ë¹„êµë¥¼ ê±´ë„ˆë›°ê³  ì–‘ìí™”ë§Œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ëŒ€ì¹­ ì–‘ìí™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nğŸ ëŒ€ì¹­ ì–‘ìí™” í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")


if __name__ == "__main__":
    main()