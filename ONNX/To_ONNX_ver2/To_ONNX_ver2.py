def safe_segment_to_onnx(model_path, output_path="model_seg.onnx", img_size=640):
    """ì•ˆì „í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ONNX ë³€í™˜ (ìˆœí™˜ì°¸ì¡° ë¬¸ì œ í•´ê²°)"""
    import os
    from ultralytics import YOLO
    import torch
    
    try:
        print("--- ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ONNX ë³€í™˜ ì‹œì‘ ---")
        
        # 1. ëª¨ë¸ ë¡œë“œ (task ëª…ì‹œ)
        print(f"ëª¨ë¸ ë¡œë”©: {model_path}")
        model = YOLO(model_path, task='segment')
        
        # 2. ëª¨ë¸ ì •ë³´ í™•ì¸
        print(f"ëª¨ë¸ íƒ€ì…: {model.task}")
        print(f"ëª¨ë¸ ì´ë¦„: {type(model.model).__name__}")
        print(f"í´ë˜ìŠ¤ ìˆ˜: {len(model.names) if hasattr(model, 'names') else 'Unknown'}")
        
        # 3. ìˆœí™˜ì°¸ì¡° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì•ˆì „í•œ ë°©ë²•ë“¤
        print("ëª¨ë¸ êµ¬ì¡° ì•ˆì „ ì²˜ë¦¬ ì¤‘...")
        
        # ë°©ë²• 1: detect ì†ì„± ë¬¸ì œ ìš°íšŒ - ì§ì ‘ ë³€í™˜ ì‹œë„
        conversion_methods = [
            ("ê¸°ë³¸ ë³€í™˜", lambda: basic_conversion(model, img_size)),
            ("torch.jit ìš°íšŒ", lambda: jit_trace_conversion(model, img_size)),
            ("ì§ì ‘ export", lambda: direct_export_conversion(model, img_size)),
            ("ì•ˆì „ ëª¨ë“œ", lambda: safe_mode_conversion(model, img_size))
        ]
        
        for method_name, conversion_func in conversion_methods:
            print(f"\n--- {method_name} ì‹œë„ ---")
            try:
                success = conversion_func()
                if success:
                    # ë³€í™˜ëœ íŒŒì¼ í™•ì¸
                    possible_paths = [
                        output_path,
                        model_path.replace('.pt', '.onnx'),
                        os.path.join(os.path.dirname(model_path), 'best.onnx'),
                        'yolov8_seg_onnx_ver1.onnx'
                    ]
                    
                    for path in possible_paths:
                        if os.path.exists(path):
                            if path != output_path:
                                import shutil
                                shutil.move(path, output_path)
                            
                            print(f"âœ… {method_name} ì„±ê³µ: {output_path}")
                            
                            # ê²€ì¦
                            if verify_onnx_model(output_path):
                                return output_path
                            else:
                                print("âš ï¸ ê²€ì¦ ì‹¤íŒ¨, ë‹¤ìŒ ë°©ë²• ì‹œë„")
                                break
                
            except Exception as e:
                print(f"âŒ {method_name} ì‹¤íŒ¨: {e}")
                continue
        
        print("âŒ ëª¨ë“  ë³€í™˜ ë°©ë²• ì‹¤íŒ¨")
        return None
                
    except Exception as e:
        print(f"ONNX ë³€í™˜ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def basic_conversion(model, img_size):
    """ê¸°ë³¸ ë³€í™˜ ë°©ë²•"""
    try:
        success = model.export(
            format="onnx",
            imgsz=img_size,
            opset=12,
            simplify=False,
            dynamic=False,
            half=False,
            verbose=True
        )
        return success
    except:
        return False

def jit_trace_conversion(model, img_size):
    """torch.jit.traceë¥¼ ì´ìš©í•œ ë³€í™˜"""
    try:
        # ëª¨ë¸ì„ ì§ì ‘ traceí•˜ì—¬ ë³€í™˜
        model.model.eval()
        
        # ë”ë¯¸ ì…ë ¥ ìƒì„±
        dummy_input = torch.randn(1, 3, img_size, img_size)
        
        # JIT trace (ìˆœí™˜ì°¸ì¡° ë¬¸ì œ ìš°íšŒ)
        with torch.no_grad():
            traced_model = torch.jit.trace(model.model, dummy_input, strict=False)
        
        # ONNXë¡œ ë³€í™˜
        torch.onnx.export(
            traced_model,
            dummy_input,
            "temp_traced.onnx",
            export_params=True,
            opset_version=12,
            do_constant_folding=True,
            input_names=['images'],
            output_names=['output0', 'output1'],
            verbose=True
        )
        
        return os.path.exists("temp_traced.onnx")
    except Exception as e:
        print(f"JIT trace ë³€í™˜ ì˜¤ë¥˜: {e}")
        return False

def direct_export_conversion(model, img_size):
    """ì§ì ‘ export (detect ì†ì„± ë¬´ì‹œ)"""
    try:
        # detect ì†ì„± ë¬¸ì œë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì œê±°
        head = model.model.model[-1]
        
        # ê¸°ì¡´ detect ì†ì„± ë°±ì—… (ìˆë‹¤ë©´)
        original_detect = getattr(head, 'detect', None)
        
        # detect ì†ì„± ì„ì‹œ ì œê±°
        if hasattr(head, 'detect'):
            delattr(head, 'detect')
        
        try:
            # ë³€í™˜ ì‹œë„
            success = model.export(
                format="onnx",
                imgsz=img_size,
                opset=11,  # ë” ë‚®ì€ ë²„ì „
                simplify=False,
                dynamic=False,
                half=False
            )
        finally:
            # detect ì†ì„± ë³µì› (í•„ìš”ì‹œ)
            if original_detect is not None:
                head.detect = original_detect
        
        return success
    except Exception as e:
        print(f"ì§ì ‘ export ì˜¤ë¥˜: {e}")
        return False

def safe_mode_conversion(model, img_size):
    """ì•ˆì „ ëª¨ë“œ ë³€í™˜ (ìµœì†Œ ì„¤ì •)"""
    try:
        # ê°€ì¥ ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ë³€í™˜
        success = model.export(
            format="onnx",
            imgsz=img_size,
            opset=9,     # ê°€ì¥ ë‚®ì€ ë²„ì „
            simplify=False,
            dynamic=False,
            half=False,
            int8=False,
            verbose=False  # ë¡œê·¸ ìµœì†Œí™”
        )
        return success
    except Exception as e:
        print(f"ì•ˆì „ ëª¨ë“œ ë³€í™˜ ì˜¤ë¥˜: {e}")
        return False

def verify_onnx_model(onnx_path):
    """ë³€í™˜ëœ ONNX ëª¨ë¸ ê²€ì¦"""
    try:
        import onnxruntime as ort
        import numpy as np
        
        print(f"ONNX ëª¨ë¸ ê²€ì¦ ì¤‘: {onnx_path}")
        
        # ONNX ëª¨ë¸ ë¡œë“œ
        session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
        
        # ì…ì¶œë ¥ ì •ë³´ í™•ì¸
        inputs = session.get_inputs()
        outputs = session.get_outputs()
        
        print("ì…ë ¥ ì •ë³´:")
        for inp in inputs:
            print(f"  - {inp.name}: {inp.shape}")
        
        print("ì¶œë ¥ ì •ë³´:")
        for out in outputs:
            print(f"  - {out.name}: {out.shape}")
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
        input_shape = inputs[0].shape
        # ë™ì  ì°¨ì› ì²˜ë¦¬
        processed_shape = []
        for dim in input_shape:
            if isinstance(dim, str) or dim is None:
                processed_shape.append(1)
            else:
                processed_shape.append(dim)
        
        dummy_input = np.random.randn(*processed_shape).astype(np.float32)
        
        print("ë”ë¯¸ ë°ì´í„°ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘...")
        result_outputs = session.run(None, {inputs[0].name: dummy_input})
        
        print(f"âœ… ì¶”ë¡  ì„±ê³µ! ì¶œë ¥ ê°œìˆ˜: {len(result_outputs)}")
        for i, output in enumerate(result_outputs):
            print(f"  ì¶œë ¥ {i}: í˜•íƒœ={output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ONNX ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

# ì¶”ê°€: ê°•ì œ ë³€í™˜ ë°©ë²• (ìµœí›„ì˜ ìˆ˜ë‹¨)
def force_conversion_last_resort(model_path, output_path="model_seg.onnx", img_size=640):
    """ìµœí›„ì˜ ìˆ˜ë‹¨: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì§ì ‘ ë³€í™˜"""
    try:
        import torch
        from ultralytics.nn.tasks import SegmentationModel
        
        print("--- ê°•ì œ ë³€í™˜ ì‹œë„ (ìµœí›„ì˜ ìˆ˜ë‹¨) ---")
        
        # 1. ì²´í¬í¬ì¸íŠ¸ ì§ì ‘ ë¡œë“œ
        ckpt = torch.load(model_path, map_location='cpu')
        
        # 2. ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        if 'model' in ckpt:
            # ëª¨ë¸ ì„¤ì • ì¶”ì¶œ
            cfg = ckpt['model'].yaml if hasattr(ckpt['model'], 'yaml') else None
            nc = ckpt['model'].nc if hasattr(ckpt['model'], 'nc') else 11
            
            # ê¸°ë³¸ YOLOv8n-seg ì‚¬ìš©
            from ultralytics import YOLO
            base_model = YOLO('yolov8n-seg.pt')
            model = base_model.model
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ (í˜¸í™˜ë˜ëŠ” ê²ƒë§Œ)
            try:
                model.load_state_dict(ckpt['model'], strict=False)
                print("âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            except:
                print("âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¼ë¶€ ì‹¤íŒ¨, ê³„ì† ì§„í–‰")
            
            model.eval()
            
            # 3. torch.onnx.exportë¡œ ì§ì ‘ ë³€í™˜
            dummy_input = torch.randn(1, 3, img_size, img_size)
            
            torch.onnx.export(
                model,
                dummy_input,
                output_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['images'],
                output_names=['output0', 'output1']
            )
            
            if os.path.exists(output_path):
                print(f"âœ… ê°•ì œ ë³€í™˜ ì„±ê³µ: {output_path}")
                return output_path
            
        return None
        
    except Exception as e:
        print(f"âŒ ê°•ì œ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    model_path = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\4.Model Experimental Data\Test_7_onnx\yolov8_seg_onnx_ver1.pt"
    output_path = "model_seg_fixed.onnx"
    
    # 1ì°¨ ì‹œë„: ì•ˆì „í•œ ë³€í™˜
    result = safe_segment_to_onnx(model_path, output_path, img_size=640)
    
    if not result:
        print("\nğŸš¨ 1ì°¨ ì‹œë„ ì‹¤íŒ¨, ê°•ì œ ë³€í™˜ ì‹œë„...")
        # 2ì°¨ ì‹œë„: ê°•ì œ ë³€í™˜
        result = force_conversion_last_resort(model_path, output_path, img_size=640)
    
    if result:
        print(f"\nğŸ‰ ìµœì¢… ë³€í™˜ ì„±ê³µ!")
        print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {result}")
    else:
        print(f"\nğŸ’¥ ëª¨ë“  ë³€í™˜ ë°©ë²• ì‹¤íŒ¨!")
        print("ğŸ”§ ë‹¤ë¥¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")