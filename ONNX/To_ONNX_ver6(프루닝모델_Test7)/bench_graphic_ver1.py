#!/usr/bin/env python3
"""
PT ëª¨ë¸ vs ONNX ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (ê³ ê¸‰ ì‹œê°í™” ë²„ì „)
ì •í™•ë„, ì†ë„, íƒì§€ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•˜ê³  ìƒì„¸í•œ ì‹œê°í™” ì œê³µ
"""

import cv2
import numpy as np
import onnxruntime as ort
import time
import os
from ultralytics import YOLO
from pathlib import Path
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from datetime import datetime
import json
from collections import defaultdict

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

class PTModel:
    """ì›ë³¸ PyTorch ëª¨ë¸ ë˜í¼"""
    def __init__(self, model_path, conf_threshold=0.3):
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        self.class_names = list(self.model.names.values())
        
    def predict(self, image_path):
        start_time = time.perf_counter()
        results = self.model(image_path, conf=self.conf_threshold, verbose=False)[0]
        inference_time = (time.perf_counter() - start_time) * 1000
        
        boxes = []
        scores = []
        labels = []
        
        if results.boxes is not None and len(results.boxes) > 0:
            for box in results.boxes:
                conf = box.conf.item()
                cls_id = int(box.cls.item())
                xyxy = box.xyxy[0].tolist()
                
                boxes.append(xyxy)
                scores.append(conf)
                labels.append(cls_id)
        
        return np.array(boxes), np.array(scores), np.array(labels), inference_time

class ONNXModel:
    """ONNX ëª¨ë¸ ë˜í¼"""
    def __init__(self, model_path, input_size=(320, 192), conf_threshold=0.3, iou_threshold=0.1):
        self.session = ort.InferenceSession(model_path)
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        self.input_width, self.input_height = input_size
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # í´ë˜ìŠ¤ ì´ë¦„ (í”„ë¡œì íŠ¸ì— ë§ê²Œ ìˆ˜ì •)
        self.class_names = [
            'forklift-right',       # 0
            'forklift-left',        # 1  
            'forklift-horizontal',  # 2
            'person',               # 3
            'forklift-vertical',    # 4
            'object',               # 5
            ''                      # 6
        ]

    def preprocess(self, image):
        original_h, original_w = image.shape[:2]
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
        scale = min(self.input_width / original_w, self.input_height / original_h)
        new_w, new_h = int(original_w * scale), int(original_h * scale)
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # íŒ¨ë”© ì¶”ê°€
        top_pad = (self.input_height - new_h) // 2
        bottom_pad = self.input_height - new_h - top_pad
        left_pad = (self.input_width - new_w) // 2
        right_pad = self.input_width - new_w - left_pad

        padded_image = cv2.copyMakeBorder(
            resized_image, top_pad, bottom_pad, left_pad, right_pad,
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )

        # ì •ê·œí™” ë° ì°¨ì› ë³€í™˜
        input_tensor = padded_image.astype(np.float32) / 255.0
        input_tensor = np.transpose(input_tensor, (2, 0, 1))
        input_tensor = np.expand_dims(input_tensor, axis=0)

        return input_tensor, scale, (top_pad, left_pad)

    def postprocess(self, output, original_width, original_height, scale, padding):
        pred = output.squeeze(0)
        
        # YOLO ì¶œë ¥ íŒŒì‹±
        boxes_raw = pred[0:4, :].T
        objectness_raw = pred[4, :]
        class_scores_raw = pred[5:11, :].T

        # ì‹œê·¸ëª¨ì´ë“œ ì ìš©
        objectness = self.sigmoid(objectness_raw)
        class_scores = self.sigmoid(class_scores_raw)

        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        scores = objectness[:, np.newaxis] * class_scores
        scores_max = np.max(scores, axis=1)
        labels = np.argmax(scores, axis=1)

        # ì„ê³„ê°’ í•„í„°ë§
        keep_mask = scores_max > self.conf_threshold
        if keep_mask.sum() == 0:
            return np.array([]), np.array([]), np.array([])

        boxes_filtered = boxes_raw[keep_mask]
        scores_filtered = scores_max[keep_mask]
        labels_filtered = labels[keep_mask]

        # ì¤‘ì‹¬ì  â†’ ì¢Œìƒë‹¨/ìš°í•˜ë‹¨ ë³€í™˜
        boxes_xyxy = np.copy(boxes_filtered)
        boxes_xyxy[:, 0] = boxes_filtered[:, 0] - boxes_filtered[:, 2] / 2
        boxes_xyxy[:, 1] = boxes_filtered[:, 1] - boxes_filtered[:, 3] / 2
        boxes_xyxy[:, 2] = boxes_filtered[:, 0] + boxes_filtered[:, 2] / 2
        boxes_xyxy[:, 3] = boxes_filtered[:, 1] + boxes_filtered[:, 3] / 2
        
        # NMS
        boxes_for_nms = np.array([[x1, y1, x2-x1, y2-y1] for x1, y1, x2, y2 in boxes_xyxy])
        indices = cv2.dnn.NMSBoxes(
            boxes_for_nms.tolist(), scores_filtered.tolist(), 
            self.conf_threshold, self.iou_threshold
        )
        
        if len(indices) == 0:
            return np.array([]), np.array([]), np.array([])
        
        indices = indices.flatten()
        boxes_final = boxes_xyxy[indices]
        scores_final = scores_filtered[indices]
        labels_final = labels_filtered[indices]

        # íŒ¨ë”© ë° ìŠ¤ì¼€ì¼ë§ ì—­ë³€í™˜
        top_pad, left_pad = padding
        boxes_final[:, 0] -= left_pad
        boxes_final[:, 1] -= top_pad
        boxes_final[:, 2] -= left_pad
        boxes_final[:, 3] -= top_pad
        boxes_final /= scale

        # í´ë¦¬í•‘
        boxes_final[:, 0] = np.clip(boxes_final[:, 0], 0, original_width)
        boxes_final[:, 1] = np.clip(boxes_final[:, 1], 0, original_height)
        boxes_final[:, 2] = np.clip(boxes_final[:, 2], 0, original_width)
        boxes_final[:, 3] = np.clip(boxes_final[:, 3], 0, original_height)

        return boxes_final, scores_final, labels_final

    def sigmoid(self, x):
        x = np.clip(x, -500, 500)
        return 1 / (1 + np.exp(-x))

    def predict(self, image_path):
        # ì´ë¯¸ì§€ ë¡œë“œ
        original_image_bgr = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image_bgr, cv2.COLOR_BGR2RGB)
        original_height, original_width = original_image.shape[:2]

        # ì „ì²˜ë¦¬
        input_tensor, scale, padding = self.preprocess(original_image)

        # ONNX ì¶”ë¡ 
        start_time = time.perf_counter()
        outputs = self.session.run([self.output_name], {self.input_name: input_tensor})
        inference_time = (time.perf_counter() - start_time) * 1000
        
        # í›„ì²˜ë¦¬
        boxes, scores, labels = self.postprocess(
            outputs[0], original_width, original_height, scale, padding
        )
        
        return boxes, scores, labels, inference_time

class EnhancedBenchmarkComparator:
    """ê³ ê¸‰ ì‹œê°í™” ê¸°ëŠ¥ì´ í¬í•¨ëœ ë²¤ì¹˜ë§ˆí¬ ë¹„êµê¸°"""
    
    def __init__(self, pt_model_path, onnx_model_path, conf_threshold=0.3):
        print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.pt_model = PTModel(pt_model_path, conf_threshold)
        self.onnx_model = ONNXModel(onnx_model_path, conf_threshold=conf_threshold)
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.results_dir = f"benchmark_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # í´ë˜ìŠ¤ë³„ í†µê³„
        self.class_stats = defaultdict(lambda: {'pt_count': 0, 'onnx_count': 0, 'matched': 0})
        
        print(f"âœ… PT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(self.pt_model.class_names)}ê°œ í´ë˜ìŠ¤")
        print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(self.onnx_model.class_names)}ê°œ í´ë˜ìŠ¤")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ í´ë”: {self.results_dir}")
        
    def calculate_iou(self, box1, box2):
        """ë‘ ë°•ìŠ¤ ê°„ì˜ IoU ê³„ì‚°"""
        x1_max = max(box1[0], box2[0])
        y1_max = max(box1[1], box2[1])
        x2_min = min(box1[2], box2[2])
        y2_min = min(box1[3], box2[3])
        
        if x2_min <= x1_max or y2_min <= y1_max:
            return 0.0
        
        intersection = (x2_min - x1_max) * (y2_min - y1_max)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def match_detections(self, pt_boxes, pt_labels, onnx_boxes, onnx_labels, iou_threshold=0.5):
        """PTì™€ ONNX íƒì§€ ê²°ê³¼ ë§¤ì¹­"""
        matches = []
        unmatched_pt = list(range(len(pt_boxes)))
        unmatched_onnx = list(range(len(onnx_boxes)))
        
        for i, pt_box in enumerate(pt_boxes):
            best_iou = 0
            best_match = -1
            
            for j, onnx_box in enumerate(onnx_boxes):
                if j in unmatched_onnx:
                    iou = self.calculate_iou(pt_box, onnx_box)
                    if iou > best_iou and iou > iou_threshold:
                        best_iou = iou
                        best_match = j
            
            if best_match != -1:
                # í´ë˜ìŠ¤ IDë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
                pt_class = int(pt_labels[i])
                onnx_class = int(onnx_labels[best_match])
                class_match = pt_class == onnx_class
                
                # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
                # print(f"PT class: {pt_class}, ONNX class: {onnx_class}, Match: {class_match}")
                
                matches.append({
                    'pt_idx': i,
                    'onnx_idx': best_match,
                    'iou': float(best_iou),
                    'class_match': class_match,
                    'pt_class': pt_class,
                    'onnx_class': onnx_class
                })
                unmatched_pt.remove(i)
                unmatched_onnx.remove(best_match)
        
        return matches, unmatched_pt, unmatched_onnx

    def update_class_stats(self, pt_labels, onnx_labels, matches):
        """í´ë˜ìŠ¤ë³„ í†µê³„ ì—…ë°ì´íŠ¸"""
        # PT íƒì§€ ì¹´ìš´íŠ¸
        for label in pt_labels:
            self.class_stats[label]['pt_count'] += 1
        
        # ONNX íƒì§€ ì¹´ìš´íŠ¸
        for label in onnx_labels:
            self.class_stats[label]['onnx_count'] += 1
        
        # ë§¤ì¹­ ì¹´ìš´íŠ¸
        for match in matches:
            if match['class_match']:
                self.class_stats[match['pt_class']]['matched'] += 1

    def create_detection_visualization(self, image_path, pt_boxes, pt_labels, pt_scores, 
                                     onnx_boxes, onnx_labels, onnx_scores, matches):
        """íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        fig, axes = plt.subplots(1, 3, figsize=(20, 7))
        
        # PT ê²°ê³¼
        axes[0].imshow(image)
        axes[0].set_title(f'PT Model ({len(pt_boxes)} detections)', fontsize=14, fontweight='bold')
        axes[0].axis('off')
        
        for i, (box, label, score) in enumerate(zip(pt_boxes, pt_labels, pt_scores)):
            rect = plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], 
                               fill=False, color='red', linewidth=2)
            axes[0].add_patch(rect)
            class_name = self.pt_model.class_names[label] if label < len(self.pt_model.class_names) else f"class_{label}"
            axes[0].text(box[0], box[1]-5, f'{class_name}: {score:.2f}', 
                        color='red', fontsize=8, fontweight='bold')
        
        # ONNX ê²°ê³¼
        axes[1].imshow(image)
        axes[1].set_title(f'ONNX Model ({len(onnx_boxes)} detections)', fontsize=14, fontweight='bold')
        axes[1].axis('off')
        
        for i, (box, label, score) in enumerate(zip(onnx_boxes, onnx_labels, onnx_scores)):
            rect = plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], 
                               fill=False, color='blue', linewidth=2)
            axes[1].add_patch(rect)
            class_name = self.onnx_model.class_names[label] if label < len(self.onnx_model.class_names) else f"class_{label}"
            axes[1].text(box[0], box[1]-5, f'{class_name}: {score:.2f}', 
                        color='blue', fontsize=8, fontweight='bold')
        
        # ë§¤ì¹­ ê²°ê³¼
        axes[2].imshow(image)
        axes[2].set_title(f'Matched Results ({len(matches)} matches)', fontsize=14, fontweight='bold')
        axes[2].axis('off')
        
        # ë§¤ì¹­ëœ íƒì§€ë“¤
        for match in matches:
            pt_box = pt_boxes[match['pt_idx']]
            onnx_box = onnx_boxes[match['onnx_idx']]
            
            color = 'green' if match['class_match'] else 'orange'
            
            # PT ë°•ìŠ¤ (ì‹¤ì„ )
            rect_pt = plt.Rectangle((pt_box[0], pt_box[1]), pt_box[2]-pt_box[0], pt_box[3]-pt_box[1], 
                                  fill=False, color=color, linewidth=2, linestyle='-')
            axes[2].add_patch(rect_pt)
            
            # ONNX ë°•ìŠ¤ (ì ì„ )
            rect_onnx = plt.Rectangle((onnx_box[0], onnx_box[1]), onnx_box[2]-onnx_box[0], onnx_box[3]-onnx_box[1], 
                                    fill=False, color=color, linewidth=2, linestyle='--')
            axes[2].add_patch(rect_onnx)
            
            # IoU í‘œì‹œ
            center_x = (pt_box[0] + pt_box[2]) / 2
            center_y = (pt_box[1] + pt_box[3]) / 2
            axes[2].text(center_x, center_y, f'IoU: {match["iou"]:.2f}', 
                        color=color, fontsize=8, fontweight='bold', 
                        bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.8))
        
        plt.tight_layout()
        
        # ì €ì¥
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        save_path = os.path.join(self.results_dir, f'detection_{base_name}.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return save_path

    def benchmark_single_image(self, image_path, save_visualization=True, debug_classes=False):
        """ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ“¸ ì´ë¯¸ì§€ ì²˜ë¦¬: {os.path.basename(image_path)}")
        
        # PT ëª¨ë¸ ì˜ˆì¸¡
        pt_boxes, pt_scores, pt_labels, pt_time = self.pt_model.predict(image_path)
        
        # ONNX ëª¨ë¸ ì˜ˆì¸¡
        onnx_boxes, onnx_scores, onnx_labels, onnx_time = self.onnx_model.predict(image_path)
        
        # í´ë˜ìŠ¤ ì •ë³´ ë””ë²„ê¹… ì¶œë ¥
        if debug_classes and (len(pt_labels) > 0 or len(onnx_labels) > 0):
            print(f"   ë””ë²„ê·¸ - PT í´ë˜ìŠ¤: {pt_labels.tolist() if len(pt_labels) > 0 else 'None'}")
            print(f"   ë””ë²„ê·¸ - ONNX í´ë˜ìŠ¤: {onnx_labels.tolist() if len(onnx_labels) > 0 else 'None'}")
            
            # í´ë˜ìŠ¤ ì´ë¦„ë„ ì¶œë ¥
            if len(pt_labels) > 0:
                pt_class_names = [self.pt_model.class_names[int(label)] if int(label) < len(self.pt_model.class_names) else f"unknown_{label}" for label in pt_labels]
                print(f"   ë””ë²„ê·¸ - PT í´ë˜ìŠ¤ëª…: {pt_class_names}")
            
            if len(onnx_labels) > 0:
                onnx_class_names = [self.onnx_model.class_names[int(label)] if int(label) < len(self.onnx_model.class_names) else f"unknown_{label}" for label in onnx_labels]
                print(f"   ë””ë²„ê·¸ - ONNX í´ë˜ìŠ¤ëª…: {onnx_class_names}")
        
        # ê²°ê³¼ ë§¤ì¹­
        matches, unmatched_pt, unmatched_onnx = self.match_detections(
            pt_boxes, pt_labels, onnx_boxes, onnx_labels
        )
        
        # ë§¤ì¹­ ê²°ê³¼ ë””ë²„ê¹…
        if debug_classes and matches:
            print(f"   ë””ë²„ê·¸ - ë§¤ì¹­ ê²°ê³¼:")
            for i, match in enumerate(matches):
                pt_class_name = self.pt_model.class_names[match['pt_class']] if match['pt_class'] < len(self.pt_model.class_names) else f"unknown_{match['pt_class']}"
                onnx_class_name = self.onnx_model.class_names[match['onnx_class']] if match['onnx_class'] < len(self.onnx_model.class_names) else f"unknown_{match['onnx_class']}"
                print(f"     ë§¤ì¹­ {i+1}: PT({match['pt_class']}:{pt_class_name}) vs ONNX({match['onnx_class']}:{onnx_class_name}) = {match['class_match']}")
        
        # í´ë˜ìŠ¤ë³„ í†µê³„ ì—…ë°ì´íŠ¸
        self.update_class_stats(pt_labels, onnx_labels, matches)
        
        # ì‹œê°í™” ìƒì„±
        viz_path = None
        if save_visualization and (len(pt_boxes) > 0 or len(onnx_boxes) > 0):
            viz_path = self.create_detection_visualization(
                image_path, pt_boxes, pt_labels, pt_scores,
                onnx_boxes, onnx_labels, onnx_scores, matches
            )
        
        # í†µê³„ ê³„ì‚°
        total_pt = len(pt_boxes)
        total_onnx = len(onnx_boxes)
        matched_count = len(matches)
        class_match_count = sum(1 for m in matches if m['class_match'])
        
        results = {
            'image': os.path.basename(image_path),
            'image_path': image_path,
            'pt_detections': total_pt,
            'onnx_detections': total_onnx,
            'matched_detections': matched_count,
            'class_accuracy': class_match_count / matched_count if matched_count > 0 else 0,
            'pt_inference_time': pt_time,
            'onnx_inference_time': onnx_time,
            'speed_improvement': pt_time / onnx_time if onnx_time > 0 else 0,
            'unmatched_pt': len(unmatched_pt),
            'unmatched_onnx': len(unmatched_onnx),
            'avg_iou': np.mean([m['iou'] for m in matches]) if matches else 0,
            'visualization_path': viz_path,
            'matches': matches
        }
        
        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        print(f"   PT íƒì§€: {total_pt}ê°œ, ONNX íƒì§€: {total_onnx}ê°œ")
        print(f"   ë§¤ì¹­: {matched_count}ê°œ, í´ë˜ìŠ¤ ì •í™•ë„: {results['class_accuracy']:.1%}")
        print(f"   í‰ê·  IoU: {results['avg_iou']:.3f}")
        print(f"   ì†ë„: PT {pt_time:.1f}ms vs ONNX {onnx_time:.1f}ms ({results['speed_improvement']:.1f}x)")
        if viz_path:
            print(f"   ì‹œê°í™” ì €ì¥: {os.path.basename(viz_path)}")
        
        return results

    def create_comprehensive_visualizations(self, all_results):
        """ì¢…í•©ì ì¸ ì‹œê°í™” ìƒì„±"""
        df = pd.DataFrame(all_results)
        
        # 1. ì „ì²´ ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ
        self.create_performance_dashboard(df)
        
        # 2. í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
        self.create_class_analysis(df)
        
        # 3. ì‹œê°„ë³„ ì„±ëŠ¥ ì¶”ì´
        self.create_time_analysis(df)
        
        # 4. ìƒì„¸ í†µê³„ ë¦¬í¬íŠ¸
        self.create_detailed_report(df)
        
        # 5. IoU ë¶„í¬ ë¶„ì„
        self.create_iou_analysis(df)

    def create_performance_dashboard(self, df):
        """ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ"""
        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        
        # 1. ì „ì²´ íƒì§€ ìˆ˜ ë¹„êµ
        ax1 = fig.add_subplot(gs[0, 0])
        total_pt = df['pt_detections'].sum()
        total_onnx = df['onnx_detections'].sum()
        bars = ax1.bar(['PT Model', 'ONNX Model'], [total_pt, total_onnx], 
                      color=['#FF6B6B', '#4ECDC4'])
        ax1.set_title('Total Detections', fontweight='bold')
        ax1.set_ylabel('Number of Detections')
        for bar, value in zip(bars, [total_pt, total_onnx]):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                    str(value), ha='center', va='bottom', fontweight='bold')
        
        # 2. í‰ê·  ì¶”ë¡  ì‹œê°„ ë¹„êµ
        ax2 = fig.add_subplot(gs[0, 1])
        avg_pt_time = df['pt_inference_time'].mean()
        avg_onnx_time = df['onnx_inference_time'].mean()
        bars = ax2.bar(['PT Model', 'ONNX Model'], [avg_pt_time, avg_onnx_time], 
                      color=['#FF6B6B', '#4ECDC4'])
        ax2.set_title('Average Inference Time', fontweight='bold')
        ax2.set_ylabel('Time (ms)')
        for bar, value in zip(bars, [avg_pt_time, avg_onnx_time]):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                    f'{value:.1f}ms', ha='center', va='bottom', fontweight='bold')
        
        # 3. ì†ë„ í–¥ìƒ ë¶„í¬
        ax3 = fig.add_subplot(gs[0, 2])
        speed_improvements = df['speed_improvement'].values
        ax3.hist(speed_improvements, bins=15, color='skyblue', alpha=0.7, edgecolor='black')
        ax3.axvline(speed_improvements.mean(), color='red', linestyle='--', 
                   label=f'Mean: {speed_improvements.mean():.1f}x')
        ax3.set_title('Speed Improvement Distribution', fontweight='bold')
        ax3.set_xlabel('Speed Improvement (x)')
        ax3.set_ylabel('Frequency')
        ax3.legend()
        
        # 4. í´ë˜ìŠ¤ ì •í™•ë„ ë¶„í¬
        ax4 = fig.add_subplot(gs[0, 3])
        class_accuracies = df['class_accuracy'].values
        ax4.hist(class_accuracies, bins=10, color='lightgreen', alpha=0.7, edgecolor='black')
        ax4.axvline(class_accuracies.mean(), color='red', linestyle='--', 
                   label=f'Mean: {class_accuracies.mean():.2f}')
        ax4.set_title('Class Accuracy Distribution', fontweight='bold')
        ax4.set_xlabel('Class Accuracy')
        ax4.set_ylabel('Frequency')
        ax4.legend()
        
        # 5. ì´ë¯¸ì§€ë³„ íƒì§€ ìˆ˜ ë¹„êµ
        ax5 = fig.add_subplot(gs[1, :2])
        x = range(len(df))
        width = 0.35
        ax5.bar([i - width/2 for i in x], df['pt_detections'], width, 
               label='PT Model', color='#FF6B6B', alpha=0.8)
        ax5.bar([i + width/2 for i in x], df['onnx_detections'], width, 
               label='ONNX Model', color='#4ECDC4', alpha=0.8)
        ax5.set_title('Detections per Image', fontweight='bold')
        ax5.set_xlabel('Image Index')
        ax5.set_ylabel('Number of Detections')
        ax5.legend()
        ax5.grid(True, alpha=0.3)
        
        # 6. ì´ë¯¸ì§€ë³„ ì¶”ë¡  ì‹œê°„
        ax6 = fig.add_subplot(gs[1, 2:])
        ax6.plot(x, df['pt_inference_time'], 'o-', label='PT Model', 
                color='#FF6B6B', linewidth=2, markersize=6)
        ax6.plot(x, df['onnx_inference_time'], 's-', label='ONNX Model', 
                color='#4ECDC4', linewidth=2, markersize=6)
        ax6.set_title('Inference Time per Image', fontweight='bold')
        ax6.set_xlabel('Image Index')
        ax6.set_ylabel('Time (ms)')
        ax6.legend()
        ax6.grid(True, alpha=0.3)
        
        # 7. ë§¤ì¹­ ì„±ëŠ¥ ìš”ì•½
        ax7 = fig.add_subplot(gs[2, :2])
        categories = ['Total PT', 'Total ONNX', 'Matched', 'Unmatched PT', 'Unmatched ONNX']
        values = [
            df['pt_detections'].sum(),
            df['onnx_detections'].sum(),
            df['matched_detections'].sum(),
            df['unmatched_pt'].sum(),
            df['unmatched_onnx'].sum()
        ]
        colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#FFB4B4', '#B4E4E1']
        bars = ax7.bar(categories, values, color=colors)
        ax7.set_title('Detection Matching Summary', fontweight='bold')
        ax7.set_ylabel('Count')
        for bar, value in zip(bars, values):
            ax7.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                    str(value), ha='center', va='bottom', fontweight='bold')
        
        # 8. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½
        ax8 = fig.add_subplot(gs[2, 2:])
        metrics = ['Avg Speed\nImprovement', 'Avg Class\nAccuracy', 'Avg IoU', 'Match Rate']
        values = [
            df['speed_improvement'].mean(),
            df['class_accuracy'].mean(),
            df['avg_iou'].mean(),
            df['matched_detections'].sum() / df['pt_detections'].sum() if df['pt_detections'].sum() > 0 else 0
        ]
        colors = ['gold', 'lightcoral', 'lightblue', 'lightgreen']
        bars = ax8.bar(metrics, values, color=colors)
        ax8.set_title('Performance Metrics Summary', fontweight='bold')
        for bar, value in zip(bars, values):
            ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.2f}', ha='center', va='bottom', fontweight='bold')
        
        plt.suptitle('PT vs ONNX Model Performance Dashboard', fontsize=20, fontweight='bold')
        
        # ì €ì¥
        save_path = os.path.join(self.results_dir, 'performance_dashboard.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì €ì¥: {save_path}")

    def create_class_analysis(self, df):
        """í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„"""
        if not self.class_stats:
            return
            
        # í´ë˜ìŠ¤ë³„ ë°ì´í„° ì¤€ë¹„
        class_data = []
        for class_id, stats in self.class_stats.items():
            class_name = (self.pt_model.class_names[class_id] 
                         if class_id < len(self.pt_model.class_names) 
                         else f"class_{class_id}")
            
            precision = stats['matched'] / stats['onnx_count'] if stats['onnx_count'] > 0 else 0
            recall = stats['matched'] / stats['pt_count'] if stats['pt_count'] > 0 else 0
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            class_data.append({
                'class_id': class_id,
                'class_name': class_name,
                'pt_count': stats['pt_count'],
                'onnx_count': stats['onnx_count'],
                'matched': stats['matched'],
                'precision': precision,
                'recall': recall,
                'f1_score': f1_score
            })
        
        class_df = pd.DataFrame(class_data)
        
        if len(class_df) == 0:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. í´ë˜ìŠ¤ë³„ íƒì§€ ìˆ˜ ë¹„êµ
        x = range(len(class_df))
        width = 0.35
        axes[0, 0].bar([i - width/2 for i in x], class_df['pt_count'], width, 
                      label='PT Model', color='#FF6B6B', alpha=0.8)
        axes[0, 0].bar([i + width/2 for i in x], class_df['onnx_count'], width, 
                      label='ONNX Model', color='#4ECDC4', alpha=0.8)
        axes[0, 0].set_title('Detections by Class', fontweight='bold')
        axes[0, 0].set_xlabel('Class')
        axes[0, 0].set_ylabel('Number of Detections')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(class_df['class_name'], rotation=45, ha='right')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. í´ë˜ìŠ¤ë³„ ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜
        x = range(len(class_df))
        width = 0.25
        axes[0, 1].bar([i - width for i in x], class_df['precision'], width, 
                      label='Precision', color='lightcoral', alpha=0.8)
        axes[0, 1].bar(x, class_df['recall'], width, 
                      label='Recall', color='lightblue', alpha=0.8)
        axes[0, 1].bar([i + width for i in x], class_df['f1_score'], width, 
                      label='F1 Score', color='lightgreen', alpha=0.8)
        axes[0, 1].set_title('Performance Metrics by Class', fontweight='bold')
        axes[0, 1].set_xlabel('Class')
        axes[0, 1].set_ylabel('Score')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(class_df['class_name'], rotation=45, ha='right')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].set_ylim(0, 1)
        
        # 3. ë§¤ì¹­ ì„±ê³µë¥ 
        match_rates = class_df['matched'] / class_df['pt_count']
        match_rates = match_rates.fillna(0)
        bars = axes[1, 0].bar(range(len(class_df)), match_rates, 
                             color='gold', alpha=0.8)
        axes[1, 0].set_title('Match Rate by Class', fontweight='bold')
        axes[1, 0].set_xlabel('Class')
        axes[1, 0].set_ylabel('Match Rate')
        axes[1, 0].set_xticks(range(len(class_df)))
        axes[1, 0].set_xticklabels(class_df['class_name'], rotation=45, ha='right')
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].set_ylim(0, 1)
        
        # ê° ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar, rate in zip(bars, match_rates):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                           f'{rate:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. í´ë˜ìŠ¤ë³„ ìƒì„¸ í†µê³„ í…Œì´ë¸”
        axes[1, 1].axis('tight')
        axes[1, 1].axis('off')
        
        table_data = class_df[['class_name', 'pt_count', 'onnx_count', 'matched', 'f1_score']].round(3)
        table = axes[1, 1].table(cellText=table_data.values,
                               colLabels=['Class', 'PT', 'ONNX', 'Matched', 'F1'],
                               cellLoc='center',
                               loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        axes[1, 1].set_title('Detailed Statistics by Class', fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ì €ì¥
        save_path = os.path.join(self.results_dir, 'class_analysis.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“ˆ í´ë˜ìŠ¤ ë¶„ì„ ì €ì¥: {save_path}")

    def create_time_analysis(self, df):
        """ì‹œê°„ë³„ ì„±ëŠ¥ ì¶”ì´ ë¶„ì„"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 10))
        
        # 1. ëˆ„ì  ì¶”ë¡  ì‹œê°„
        cumulative_pt = df['pt_inference_time'].cumsum()
        cumulative_onnx = df['onnx_inference_time'].cumsum()
        
        axes[0, 0].plot(cumulative_pt, label='PT Model', color='#FF6B6B', linewidth=2)
        axes[0, 0].plot(cumulative_onnx, label='ONNX Model', color='#4ECDC4', linewidth=2)
        axes[0, 0].set_title('Cumulative Inference Time', fontweight='bold')
        axes[0, 0].set_xlabel('Image Index')
        axes[0, 0].set_ylabel('Cumulative Time (ms)')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì´ë™í‰ê·  (rolling average)
        window = min(5, len(df))
        rolling_pt = df['pt_inference_time'].rolling(window=window).mean()
        rolling_onnx = df['onnx_inference_time'].rolling(window=window).mean()
        
        axes[0, 1].plot(rolling_pt, label=f'PT Model ({window}-img avg)', 
                       color='#FF6B6B', linewidth=2)
        axes[0, 1].plot(rolling_onnx, label=f'ONNX Model ({window}-img avg)', 
                       color='#4ECDC4', linewidth=2)
        axes[0, 1].set_title('Rolling Average Inference Time', fontweight='bold')
        axes[0, 1].set_xlabel('Image Index')
        axes[0, 1].set_ylabel('Time (ms)')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ì†ë„ í–¥ìƒ ì¶”ì´
        axes[1, 0].plot(df['speed_improvement'], 'o-', color='purple', 
                       linewidth=2, markersize=6)
        axes[1, 0].axhline(y=df['speed_improvement'].mean(), color='red', 
                          linestyle='--', alpha=0.7, label='Average')
        axes[1, 0].set_title('Speed Improvement Trend', fontweight='bold')
        axes[1, 0].set_xlabel('Image Index')
        axes[1, 0].set_ylabel('Speed Improvement (x)')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ì •í™•ë„ ì¶”ì´
        axes[1, 1].plot(df['class_accuracy'], 's-', color='green', 
                       linewidth=2, markersize=6)
        axes[1, 1].axhline(y=df['class_accuracy'].mean(), color='red', 
                          linestyle='--', alpha=0.7, label='Average')
        axes[1, 1].set_title('Class Accuracy Trend', fontweight='bold')
        axes[1, 1].set_xlabel('Image Index')
        axes[1, 1].set_ylabel('Class Accuracy')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].set_ylim(0, 1)
        
        plt.tight_layout()
        
        # ì €ì¥
        save_path = os.path.join(self.results_dir, 'time_analysis.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"â±ï¸ ì‹œê°„ ë¶„ì„ ì €ì¥: {save_path}")

    def create_iou_analysis(self, df):
        """IoU ë¶„í¬ ë° ë¶„ì„"""
        # ëª¨ë“  ë§¤ì¹­ì—ì„œ IoU ê°’ ì¶”ì¶œ
        all_ious = []
        for _, row in df.iterrows():
            if row['matches']:
                all_ious.extend([match['iou'] for match in row['matches']])
        
        if not all_ious:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # 1. IoU íˆìŠ¤í† ê·¸ë¨
        axes[0, 0].hist(all_ious, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
        axes[0, 0].axvline(np.mean(all_ious), color='red', linestyle='--', 
                          label=f'Mean: {np.mean(all_ious):.3f}')
        axes[0, 0].axvline(np.median(all_ious), color='green', linestyle='--', 
                          label=f'Median: {np.median(all_ious):.3f}')
        axes[0, 0].set_title('IoU Distribution', fontweight='bold')
        axes[0, 0].set_xlabel('IoU')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. IoU ë°•ìŠ¤í”Œë¡¯
        axes[0, 1].boxplot(all_ious, patch_artist=True, 
                          boxprops=dict(facecolor='lightblue', alpha=0.7))
        axes[0, 1].set_title('IoU Box Plot', fontweight='bold')
        axes[0, 1].set_ylabel('IoU')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ì´ë¯¸ì§€ë³„ í‰ê·  IoU
        avg_ious_per_image = df['avg_iou'].values
        axes[1, 0].plot(avg_ious_per_image, 'o-', color='orange', linewidth=2, markersize=6)
        axes[1, 0].axhline(y=np.mean(avg_ious_per_image), color='red', linestyle='--', 
                          alpha=0.7, label='Overall Average')
        axes[1, 0].set_title('Average IoU per Image', fontweight='bold')
        axes[1, 0].set_xlabel('Image Index')
        axes[1, 0].set_ylabel('Average IoU')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. IoU vs í´ë˜ìŠ¤ ì •í™•ë„ ìƒê´€ê´€ê³„
        valid_indices = (df['avg_iou'] > 0) & (df['class_accuracy'] >= 0)
        if valid_indices.sum() > 0:
            x_vals = df.loc[valid_indices, 'avg_iou']
            y_vals = df.loc[valid_indices, 'class_accuracy']
            
            axes[1, 1].scatter(x_vals, y_vals, alpha=0.6, color='purple', s=50)
            
            # ì¶”ì„¸ì„  ì¶”ê°€
            if len(x_vals) > 1:
                z = np.polyfit(x_vals, y_vals, 1)
                p = np.poly1d(z)
                axes[1, 1].plot(x_vals, p(x_vals), "r--", alpha=0.8, linewidth=2)
                
                # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                correlation = np.corrcoef(x_vals, y_vals)[0, 1]
                axes[1, 1].text(0.05, 0.95, f'Correlation: {correlation:.3f}', 
                               transform=axes[1, 1].transAxes, fontweight='bold',
                               bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))
            
            axes[1, 1].set_title('IoU vs Class Accuracy', fontweight='bold')
            axes[1, 1].set_xlabel('Average IoU')
            axes[1, 1].set_ylabel('Class Accuracy')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ì €ì¥
        save_path = os.path.join(self.results_dir, 'iou_analysis.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ¯ IoU ë¶„ì„ ì €ì¥: {save_path}")

    def create_detailed_report(self, df):
        """ìƒì„¸ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_path = os.path.join(self.results_dir, 'detailed_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("PT vs ONNX ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìƒì„¸ ë¦¬í¬íŠ¸\n")
            f.write("=" * 80 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(df)}ê°œ\n\n")
            
            # ì „ì²´ ìš”ì•½
            f.write("ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½\n")
            f.write("-" * 40 + "\n")
            f.write(f"ì´ PT íƒì§€: {df['pt_detections'].sum()}ê°œ\n")
            f.write(f"ì´ ONNX íƒì§€: {df['onnx_detections'].sum()}ê°œ\n")
            f.write(f"ì´ ë§¤ì¹­: {df['matched_detections'].sum()}ê°œ\n")
            f.write(f"ì „ì²´ ë§¤ì¹­ë¥ : {df['matched_detections'].sum() / df['pt_detections'].sum() * 100:.1f}%\n")
            f.write(f"í‰ê·  í´ë˜ìŠ¤ ì •í™•ë„: {df['class_accuracy'].mean() * 100:.1f}%\n")
            f.write(f"í‰ê·  IoU: {df['avg_iou'].mean():.3f}\n\n")
            
            # ì†ë„ ì„±ëŠ¥
            f.write("âš¡ ì†ë„ ì„±ëŠ¥\n")
            f.write("-" * 40 + "\n")
            f.write(f"í‰ê·  PT ì¶”ë¡  ì‹œê°„: {df['pt_inference_time'].mean():.1f}ms\n")
            f.write(f"í‰ê·  ONNX ì¶”ë¡  ì‹œê°„: {df['onnx_inference_time'].mean():.1f}ms\n")
            f.write(f"í‰ê·  ì†ë„ í–¥ìƒ: {df['speed_improvement'].mean():.1f}x\n")
            f.write(f"ìµœëŒ€ ì†ë„ í–¥ìƒ: {df['speed_improvement'].max():.1f}x\n")
            f.write(f"ìµœì†Œ ì†ë„ í–¥ìƒ: {df['speed_improvement'].min():.1f}x\n\n")
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
            if self.class_stats:
                f.write("ğŸ¯ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n")
                f.write("-" * 40 + "\n")
                for class_id, stats in self.class_stats.items():
                    class_name = (self.pt_model.class_names[class_id] 
                                 if class_id < len(self.pt_model.class_names) 
                                 else f"class_{class_id}")
                    
                    precision = stats['matched'] / stats['onnx_count'] if stats['onnx_count'] > 0 else 0
                    recall = stats['matched'] / stats['pt_count'] if stats['pt_count'] > 0 else 0
                    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
                    
                    f.write(f"\ní´ë˜ìŠ¤: {class_name}\n")
                    f.write(f"  PT íƒì§€: {stats['pt_count']}ê°œ\n")
                    f.write(f"  ONNX íƒì§€: {stats['onnx_count']}ê°œ\n")
                    f.write(f"  ë§¤ì¹­: {stats['matched']}ê°œ\n")
                    f.write(f"  ì •ë°€ë„: {precision:.3f}\n")
                    f.write(f"  ì¬í˜„ìœ¨: {recall:.3f}\n")
                    f.write(f"  F1 ì ìˆ˜: {f1_score:.3f}\n")
            
            # ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼
            f.write("\nğŸ“¸ ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼\n")
            f.write("-" * 40 + "\n")
            for idx, row in df.iterrows():
                f.write(f"\n{idx+1}. {row['image']}\n")
                f.write(f"   PT íƒì§€: {row['pt_detections']}ê°œ\n")
                f.write(f"   ONNX íƒì§€: {row['onnx_detections']}ê°œ\n")
                f.write(f"   ë§¤ì¹­: {row['matched_detections']}ê°œ\n")
                f.write(f"   í´ë˜ìŠ¤ ì •í™•ë„: {row['class_accuracy']:.3f}\n")
                f.write(f"   í‰ê·  IoU: {row['avg_iou']:.3f}\n")
                f.write(f"   PT ì‹œê°„: {row['pt_inference_time']:.1f}ms\n")
                f.write(f"   ONNX ì‹œê°„: {row['onnx_inference_time']:.1f}ms\n")
                f.write(f"   ì†ë„ í–¥ìƒ: {row['speed_improvement']:.1f}x\n")
        
        print(f"ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

    def save_results_json(self, all_results):
        """ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥"""
        # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {str(k): convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        # ë§¤ì¹­ ì •ë³´ëŠ” ì§ë ¬í™”ë¥¼ ìœ„í•´ ì œê±°í•˜ê³  NumPy íƒ€ì… ë³€í™˜
        clean_results = []
        for result in all_results:
            clean_result = {}
            for k, v in result.items():
                if k != 'matches':  # matchesëŠ” ë³µì¡í•œ êµ¬ì¡°ì´ë¯€ë¡œ ì œì™¸
                    clean_result[str(k)] = convert_numpy_types(v)
            clean_results.append(clean_result)
        
        # í´ë˜ìŠ¤ í†µê³„ë„ NumPy íƒ€ì… ë³€í™˜
        converted_class_stats = {}
        for class_id, stats in self.class_stats.items():
            converted_class_stats[str(class_id)] = {
                str(k): convert_numpy_types(v) for k, v in stats.items()
            }
        
        # ìš”ì•½ í†µê³„ ê³„ì‚° ë° ë³€í™˜
        summary_stats = {
            'total_images': len(all_results),
            'total_pt_detections': sum(r['pt_detections'] for r in all_results),
            'total_onnx_detections': sum(r['onnx_detections'] for r in all_results),
            'total_matches': sum(r['matched_detections'] for r in all_results),
            'avg_speed_improvement': float(np.mean([r['speed_improvement'] for r in all_results])),
            'avg_class_accuracy': float(np.mean([r['class_accuracy'] for r in all_results])),
            'avg_iou': float(np.mean([r['avg_iou'] for r in all_results]))
        }
        
        json_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': summary_stats,
            'class_statistics': converted_class_stats,
            'detailed_results': clean_results
        }
        
        json_path = os.path.join(self.results_dir, 'benchmark_results.json')
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥: {json_path}")
        except Exception as e:
            print(f"âš ï¸ JSON ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°„ë‹¨í•œ ë²„ì „ìœ¼ë¡œ ì €ì¥
            try:
                simple_data = {
                    'timestamp': datetime.now().isoformat(),
                    'summary': {
                        'total_images': len(all_results),
                        'avg_speed_improvement': float(np.mean([r['speed_improvement'] for r in all_results])),
                        'avg_class_accuracy': float(np.mean([r['class_accuracy'] for r in all_results])),
                        'avg_iou': float(np.mean([r['avg_iou'] for r in all_results]))
                    },
                    'note': 'Simplified version due to serialization error'
                }
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(simple_data, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ ê°„ë‹¨í•œ JSON ê²°ê³¼ ì €ì¥: {json_path}")
            except Exception as e2:
                print(f"âŒ JSON ì €ì¥ ì™„ì „ ì‹¤íŒ¨: {e2}")

    def benchmark_multiple_images(self, image_paths, save_individual_viz=True):
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¢…í•© ë²¤ì¹˜ë§ˆí¬"""
        print("ğŸš€ ë‹¤ì¤‘ ì´ë¯¸ì§€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 60)
        
        all_results = []
        
        for i, image_path in enumerate(image_paths):
            if os.path.exists(image_path):
                print(f"\nì§„í–‰ë¥ : {i+1}/{len(image_paths)}")
                
                # ê°œë³„ ì‹œê°í™”ëŠ” ì²˜ìŒ 10ê°œ ì´ë¯¸ì§€ë§Œ ì €ì¥ (ìš©ëŸ‰ ì ˆì•½)
                save_viz = save_individual_viz and i < 10
                
                result = self.benchmark_single_image(image_path, save_visualization=save_viz)
                all_results.append(result)
            else:
                print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
        
        if not all_results:
            print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¢…í•© í†µê³„ ì¶œë ¥
        self.print_summary_stats(all_results)
        
        # ì¢…í•© ì‹œê°í™” ìƒì„±
        print(f"\nğŸ¨ ì¢…í•© ì‹œê°í™” ìƒì„± ì¤‘...")
        self.create_comprehensive_visualizations(all_results)
        
        # ê²°ê³¼ ì €ì¥
        self.save_results_json(all_results)
        
        print(f"\nâœ… ëª¨ë“  ê²°ê³¼ê°€ '{self.results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return all_results

    def print_summary_stats(self, results):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½ í†µê³„ ì¶œë ¥"""
        df = pd.DataFrame(results)
        
        print(f"\nğŸ“Š ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ({len(results)}ê°œ ì´ë¯¸ì§€)")
        print("=" * 60)
        
        print(f"ğŸ¯ íƒì§€ ì„±ëŠ¥:")
        print(f"   ì´ PT íƒì§€: {df['pt_detections'].sum()}ê°œ")
        print(f"   ì´ ONNX íƒì§€: {df['onnx_detections'].sum()}ê°œ")
        print(f"   ì´ ë§¤ì¹­: {df['matched_detections'].sum()}ê°œ")
        print(f"   ì „ì²´ ë§¤ì¹­ë¥ : {(df['matched_detections'].sum() / df['pt_detections'].sum() * 100):.1f}%")
        print(f"   í‰ê·  í´ë˜ìŠ¤ ì •í™•ë„: {df['class_accuracy'].mean():.1%}")
        print(f"   í‰ê·  IoU: {df['avg_iou'].mean():.3f}")
        
        print(f"\nâš¡ ì†ë„ ì„±ëŠ¥:")
        print(f"   í‰ê·  PT ì‹œê°„: {df['pt_inference_time'].mean():.1f}ms")
        print(f"   í‰ê·  ONNX ì‹œê°„: {df['onnx_inference_time'].mean():.1f}ms")
        print(f"   í‰ê·  ì†ë„ í–¥ìƒ: {df['speed_improvement'].mean():.1f}x")
        print(f"   ìµœëŒ€ ì†ë„ í–¥ìƒ: {df['speed_improvement'].max():.1f}x")
        
        print(f"\nğŸ“ˆ ìƒì„¸ í†µê³„:")
        print(f"   ë¯¸ë§¤ì¹­ PT: {df['unmatched_pt'].sum()}ê°œ")
        print(f"   ë¯¸ë§¤ì¹­ ONNX: {df['unmatched_onnx'].sum()}ê°œ")
        print(f"   ì†ë„ í–¥ìƒ í‘œì¤€í¸ì°¨: {df['speed_improvement'].std():.2f}")

def find_images_in_folder(folder_path):
    """í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë°˜í™˜"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
    image_files = []
    
    if not os.path.exists(folder_path):
        print(f"âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return []
    
    print(f"ğŸ“ í´ë” ìŠ¤ìº” ì¤‘: {folder_path}")
    
    # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ê²€ìƒ‰ (í•˜ìœ„ í´ë” í¬í•¨)
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            file_ext = Path(file).suffix.lower()
            if file_ext in image_extensions:
                full_path = os.path.join(root, file)
                image_files.append(full_path)
    
    print(f"âœ… ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
    
    # íŒŒì¼ëª…ìœ¼ë¡œ ì •ë ¬
    image_files.sort()
    
    # ì²˜ìŒ 10ê°œ íŒŒì¼ëª… ì¶œë ¥
    if image_files:
        print("ğŸ“‹ ë°œê²¬ëœ ì´ë¯¸ì§€ (ì²˜ìŒ 10ê°œ):")
        for i, img_path in enumerate(image_files[:10]):
            rel_path = os.path.relpath(img_path, folder_path)
            print(f"   {i+1}. {rel_path}")
        if len(image_files) > 10:
            print(f"   ... ì™¸ {len(image_files) - 10}ê°œ")
    
    return image_files

def get_user_inputs():
    """ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ëŠ” í•¨ìˆ˜"""
    
    print("ğŸ”§ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •")
    print("=" * 40)
    
    # PT ëª¨ë¸ ê²½ë¡œ
    print("\n1ï¸âƒ£ PT ëª¨ë¸ ê²½ë¡œ:")
    pt_default = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\6.ONNX\To_ONNX_ver3\yolov8_custom.pt"
    pt_path = input(f"PT ëª¨ë¸ ê²½ë¡œ [{pt_default}]: ").strip()
    if not pt_path:
        pt_path = pt_default
    
    # ONNX ëª¨ë¸ ê²½ë¡œ  
    print("\n2ï¸âƒ£ ONNX ëª¨ë¸ ê²½ë¡œ:")
    onnx_default = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\6.ONNX\To_ONNX_ver3\yolov8_custom_fixed.onnx"
    onnx_path = input(f"ONNX ëª¨ë¸ ê²½ë¡œ [{onnx_default}]: ").strip()
    if not onnx_path:
        onnx_path = onnx_default
    
    # ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
    print("\n3ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”:")
    print("í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼(.jpg, .png ë“±)ì´ ìë™ìœ¼ë¡œ ê²€ìƒ‰ë©ë‹ˆë‹¤.")
    folder_default = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1"
    folder_path = input(f"ì´ë¯¸ì§€ í´ë” ê²½ë¡œ [{folder_default}]: ").strip()
    if not folder_path:
        folder_path = folder_default
    
    # ì‹ ë¢°ë„ ì„ê³„ê°’
    print("\n4ï¸âƒ£ ì‹ ë¢°ë„ ì„ê³„ê°’:")
    conf_default = "0.3"
    conf_input = input(f"ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0) [{conf_default}]: ").strip()
    try:
        conf_threshold = float(conf_input) if conf_input else float(conf_default)
        if not 0.0 <= conf_threshold <= 1.0:
            raise ValueError
    except ValueError:
        print(f"âš ï¸ ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ {conf_default} ì‚¬ìš©")
        conf_threshold = float(conf_default)
    
    # ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
    print("\n5ï¸âƒ£ ìµœëŒ€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜:")
    max_default = "10"
    max_input = input(f"ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ (0=ì „ì²´) [{max_default}]: ").strip()
    try:
        max_images = int(max_input) if max_input else int(max_default)
        if max_images < 0:
            raise ValueError
    except ValueError:
        print(f"âš ï¸ ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ {max_default} ì‚¬ìš©")
        max_images = int(max_default)
    
    # ê°œë³„ ì´ë¯¸ì§€ ì‹œê°í™” ì €ì¥ ì—¬ë¶€
    print("\n6ï¸âƒ£ ê°œë³„ ì´ë¯¸ì§€ ì‹œê°í™”:")
    print("ê° ì´ë¯¸ì§€ì— ëŒ€í•œ íƒì§€ ê²°ê³¼ ë¹„êµ ì´ë¯¸ì§€ë¥¼ ì €ì¥í• ì§€ ì„ íƒí•©ë‹ˆë‹¤.")
    print("(ì£¼ì˜: ë§ì€ ì´ë¯¸ì§€ì˜ ê²½ìš° ì €ì¥ ê³µê°„ì„ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤)")
    viz_input = input("ê°œë³„ ì‹œê°í™” ì €ì¥ (y/n) [y]: ").strip().lower()
    save_individual_viz = viz_input != 'n'
    
    return pt_path, onnx_path, folder_path, conf_threshold, max_images, save_individual_viz

def create_summary_html_report(results_dir, summary_data=None):
    """HTML í˜•íƒœì˜ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    # ê¸°ë³¸ ë©”íŠ¸ë¦­ (JSON íŒŒì¼ì—ì„œ ë¡œë“œë  ìˆ˜ ìˆìŒ)
    default_metrics = {
        'avg_speed_improvement': 0.0,
        'avg_class_accuracy': 0.0,
        'avg_iou': 0.0,
        'match_rate': 0.0
    }
    
    if summary_data:
        default_metrics.update(summary_data)
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>PT vs ONNX ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼</title>
        <style>
            body {{
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                background-color: #f5f5f5;
            }}
            .header {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 30px;
                border-radius: 10px;
                text-align: center;
                margin-bottom: 30px;
            }}
            .card {{
                background: white;
                padding: 20px;
                margin: 20px 0;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }}
            .metric-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 20px;
                margin: 20px 0;
            }}
            .metric-card {{
                background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
                color: white;
                padding: 20px;
                border-radius: 10px;
                text-align: center;
            }}
            .metric-value {{
                font-size: 2em;
                font-weight: bold;
                margin: 10px 0;
            }}
            .image-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
                gap: 20px;
                margin: 20px 0;
            }}
            .image-card {{
                text-align: center;
            }}
            .image-card img {{
                max-width: 100%;
                height: auto;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
            }}
            th, td {{
                padding: 12px;
                text-align: left;
                border-bottom: 1px solid #ddd;
            }}
            th {{
                background-color: #4CAF50;
                color: white;
            }}
            tr:hover {{
                background-color: #f5f5f5;
            }}
            .footer {{
                text-align: center;
                margin-top: 40px;
                padding: 20px;
                color: #666;
            }}
            .alert {{
                background-color: #e7f3ff;
                border: 1px solid #b3d9ff;
                border-radius: 5px;
                padding: 15px;
                margin: 15px 0;
            }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>ğŸ”¬ PT vs ONNX ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬</h1>
            <p>ìƒì„± ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}</p>
        </div>
        
        <div class="card">
            <h2>ğŸ“Š ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ</h2>
            <div class="metric-grid">
                <div class="metric-card" style="background: linear-gradient(135deg, #FF6B6B 0%, #FF6B6BAA 100%);">
                    <div class="metric-value">{default_metrics['avg_speed_improvement']:.1f}x</div>
                    <div>í‰ê·  ì†ë„ í–¥ìƒ</div>
                </div>
                <div class="metric-card" style="background: linear-gradient(135deg, #4ECDC4 0%, #4ECDC4AA 100%);">
                    <div class="metric-value">{default_metrics['avg_class_accuracy']:.1%}</div>
                    <div>í‰ê·  í´ë˜ìŠ¤ ì •í™•ë„</div>
                </div>
                <div class="metric-card" style="background: linear-gradient(135deg, #45B7D1 0%, #45B7D1AA 100%);">
                    <div class="metric-value">{default_metrics['avg_iou']:.3f}</div>
                    <div>í‰ê·  IoU</div>
                </div>
                <div class="metric-card" style="background: linear-gradient(135deg, #96CEB4 0%, #96CEB4AA 100%);">
                    <div class="metric-value">{default_metrics['match_rate']:.1%}</div>
                    <div>ì „ì²´ ë§¤ì¹­ë¥ </div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ê·¸ë˜í”„</h2>
            <div class="alert">
                <strong>ğŸ’¡ ì°¸ê³ :</strong> ì•„ë˜ ê·¸ë˜í”„ë“¤ì„ í´ë¦­í•˜ë©´ ë” í° í¬ê¸°ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            </div>
            <div class="image-grid">
                <div class="image-card">
                    <h3>ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ</h3>
                    <a href="performance_dashboard.png" target="_blank">
                        <img src="performance_dashboard.png" alt="ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ">
                    </a>
                    <p>ì „ì²´ì ì¸ ì„±ëŠ¥ ë¹„êµì™€ ì£¼ìš” ë©”íŠ¸ë¦­ì„ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
                </div>
                <div class="image-card">
                    <h3>í´ë˜ìŠ¤ë³„ ë¶„ì„</h3>
                    <a href="class_analysis.png" target="_blank">
                        <img src="class_analysis.png" alt="í´ë˜ìŠ¤ë³„ ë¶„ì„">
                    </a>
                    <p>ê° í´ë˜ìŠ¤ë³„ ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.</p>
                </div>
                <div class="image-card">
                    <h3>ì‹œê°„ ì¶”ì´ ë¶„ì„</h3>
                    <a href="time_analysis.png" target="_blank">
                        <img src="time_analysis.png" alt="ì‹œê°„ ì¶”ì´ ë¶„ì„">
                    </a>
                    <p>ì‹œê°„ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ì™€ ì•ˆì •ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.</p>
                </div>
                <div class="image-card">
                    <h3>IoU ë¶„í¬ ë¶„ì„</h3>
                    <a href="iou_analysis.png" target="_blank">
                        <img src="iou_analysis.png" alt="IoU ë¶„í¬ ë¶„ì„">
                    </a>
                    <p>IoU ë¶„í¬ì™€ ì •í™•ë„ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.</p>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡</h2>
            <div class="alert">
                <strong>ğŸ“‹ íŒŒì¼ ì„¤ëª…:</strong>
                <ul>
                    <li><strong>benchmark_results.json</strong> - ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° (JSON í˜•ì‹)</li>
                    <li><strong>detailed_report.txt</strong> - ìƒì„¸í•œ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸</li>
                    <li><strong>performance_dashboard.png</strong> - ì¢…í•© ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ</li>
                    <li><strong>class_analysis.png</strong> - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„</li>
                    <li><strong>time_analysis.png</strong> - ì‹œê°„ ì¶”ì´ ë° ì•ˆì •ì„± ë¶„ì„</li>
                    <li><strong>iou_analysis.png</strong> - IoU ë¶„í¬ ë° ìƒê´€ê´€ê³„ ë¶„ì„</li>
                    <li><strong>detection_*.png</strong> - ê°œë³„ ì´ë¯¸ì§€ íƒì§€ ê²°ê³¼ ë¹„êµ</li>
                </ul>
            </div>
        </div>
        
        <div class="card">
            <h2>ğŸ¯ ê²°ê³¼ ìš”ì•½</h2>
            <table>
                <tr>
                    <th>í•­ëª©</th>
                    <th>PT ëª¨ë¸</th>
                    <th>ONNX ëª¨ë¸</th>
                    <th>ê°œì„ ë„</th>
                </tr>
                <tr>
                    <td>í‰ê·  ì¶”ë¡  ì‹œê°„</td>
                    <td id="pt-time">-</td>
                    <td id="onnx-time">-</td>
                    <td id="speed-improvement">-</td>
                </tr>
                <tr>
                    <td>í‰ê·  íƒì§€ ìˆ˜</td>
                    <td id="pt-detections">-</td>
                    <td id="onnx-detections">-</td>
                    <td id="detection-difference">-</td>
                </tr>
                <tr>
                    <td>ë§¤ì¹­ ì •í™•ë„</td>
                    <td colspan="2" id="match-accuracy">-</td>
                    <td>-</td>
                </tr>
            </table>
        </div>
        
        <div class="footer">
            <p>ğŸ”¬ ì´ ë¦¬í¬íŠ¸ëŠ” PTì™€ ONNX ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤.</p>
            <p>ğŸ“„ ìì„¸í•œ ë‚´ìš©ì€ <a href="detailed_report.txt">detailed_report.txt</a> íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.</p>
            <p>ğŸ’¾ ì›ì‹œ ë°ì´í„°ëŠ” <a href="benchmark_results.json">benchmark_results.json</a> íŒŒì¼ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
        </div>
        
        <script>
            // JSON ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë™ì ìœ¼ë¡œ í‘œì‹œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” fetch ì‚¬ìš©)
            function loadBenchmarkData() {{
                // ì‹¤ì œë¡œëŠ” benchmark_results.jsonì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œ
                // ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©
                document.getElementById('pt-time').textContent = '-';
                document.getElementById('onnx-time').textContent = '-';
                document.getElementById('speed-improvement').textContent = '{default_metrics["avg_speed_improvement"]:.1f}x';
                document.getElementById('pt-detections').textContent = '-';
                document.getElementById('onnx-detections').textContent = '-';
                document.getElementById('detection-difference').textContent = '-';
                document.getElementById('match-accuracy').textContent = '{default_metrics["avg_class_accuracy"]:.1%}';
            }}
            
            // í˜ì´ì§€ ë¡œë“œ ì‹œ ë°ì´í„° ë¡œë“œ
            window.onload = loadBenchmarkData;
        </script>
    </body>
    </html>
    """
    
    html_path = os.path.join(results_dir, 'benchmark_report.html')
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"ğŸŒ HTML ë¦¬í¬íŠ¸ ì €ì¥: {html_path}")
    return html_path

def main():
    """ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    
    print("ğŸ”¬ PT vs ONNX ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (ê³ ê¸‰ ì‹œê°í™” ë²„ì „)")
    print("=" * 70)
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    pt_path, onnx_path, folder_path, conf_threshold, max_images, save_individual_viz = get_user_inputs()
    
    print(f"\nğŸ“‹ ì„¤ì • í™•ì¸:")
    print(f"   PT ëª¨ë¸: {pt_path}")
    print(f"   ONNX ëª¨ë¸: {onnx_path}")
    print(f"   ì´ë¯¸ì§€ í´ë”: {folder_path}")
    print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’: {conf_threshold}")
    print(f"   ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜: {max_images if max_images > 0 else 'ì „ì²´'}")
    print(f"   ê°œë³„ ì‹œê°í™” ì €ì¥: {'ì˜ˆ' if save_individual_viz else 'ì•„ë‹ˆì˜¤'}")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(pt_path):
        print(f"âŒ PT ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pt_path}")
        return
    
    if not os.path.exists(onnx_path):
        print(f"âŒ ONNX ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {onnx_path}")
        return
    
    # ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰
    image_files = find_images_in_folder(folder_path)
    
    if not image_files:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
    if max_images > 0 and len(image_files) > max_images:
        image_files = image_files[:max_images]
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ {max_images}ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.")
    
    # ì‹¤í–‰ í™•ì¸
    print(f"\nğŸš€ {len(image_files)}ê°œ ì´ë¯¸ì§€ë¡œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    print(f"ğŸ’¾ ê²°ê³¼ëŠ” 'benchmark_results_YYYYMMDD_HHMMSS' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")
    confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n) [y]: ").strip().lower()
    if confirm and confirm != 'y':
        print("âŒ ë²¤ì¹˜ë§ˆí¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    print("\n" + "=" * 70)
    
    try:
        # ë²¤ì¹˜ë§ˆí¬ ê°ì²´ ìƒì„±
        comparator = EnhancedBenchmarkComparator(pt_path, onnx_path, conf_threshold)
        
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        results = comparator.benchmark_multiple_images(image_files, save_individual_viz)
        
        # ìš”ì•½ ë°ì´í„° ì¤€ë¹„
        df = pd.DataFrame(results)
        summary_data = {
            'avg_speed_improvement': df['speed_improvement'].mean(),
            'avg_class_accuracy': df['class_accuracy'].mean(),
            'avg_iou': df['avg_iou'].mean(),
            'match_rate': df['matched_detections'].sum() / df['pt_detections'].sum() if df['pt_detections'].sum() > 0 else 0
        }
        
        # HTML ë¦¬í¬íŠ¸ ìƒì„±
        html_path = create_summary_html_report(comparator.results_dir, summary_data)
        
        print(f"\nğŸ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ í´ë”: {comparator.results_dir}")
        print("\nğŸ“‹ ìƒì„±ëœ ì£¼ìš” íŒŒì¼:")
        print(f"   â€¢ benchmark_report.html - ì›¹ ë¸Œë¼ìš°ì €ìš© ì¢…í•© ë¦¬í¬íŠ¸")
        print(f"   â€¢ performance_dashboard.png - ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ")
        print(f"   â€¢ class_analysis.png - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„")
        print(f"   â€¢ time_analysis.png - ì‹œê°„ ì¶”ì´ ë¶„ì„")
        print(f"   â€¢ iou_analysis.png - IoU ë¶„í¬ ë¶„ì„")
        print(f"   â€¢ detailed_report.txt - ìƒì„¸ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸")
        print(f"   â€¢ benchmark_results.json - ì›ì‹œ ë°ì´í„° (JSON)")
        
        if save_individual_viz:
            detection_files = [f for f in os.listdir(comparator.results_dir) if f.startswith('detection_')]
            if detection_files:
                print(f"   â€¢ detection_*.png - ê°œë³„ ì´ë¯¸ì§€ íƒì§€ ê²°ê³¼ ({len(detection_files)}ê°œ)")
        
        print(f"\nğŸŒ ì›¹ ë¦¬í¬íŠ¸ í™•ì¸: {html_path}")
        print(f"   ë¸Œë¼ìš°ì €ì—ì„œ ìœ„ íŒŒì¼ì„ ì—´ì–´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ“Š ê°„ë‹¨ ìš”ì•½:")
        print(f"   â€¢ ì´ ì²˜ë¦¬ ì´ë¯¸ì§€: {len(results)}ê°œ")
        print(f"   â€¢ í‰ê·  ì†ë„ í–¥ìƒ: {summary_data['avg_speed_improvement']:.1f}x")
        print(f"   â€¢ í‰ê·  í´ë˜ìŠ¤ ì •í™•ë„: {summary_data['avg_class_accuracy']:.1%}")
        print(f"   â€¢ í‰ê·  IoU: {summary_data['avg_iou']:.3f}")
        print(f"   â€¢ ì „ì²´ ë§¤ì¹­ë¥ : {summary_data['match_rate']:.1%}")
        
        # ì¶”ê°€ ë¶„ì„ ì œì•ˆ
        print(f"\nğŸ’¡ ì¶”ê°€ ë¶„ì„ ì œì•ˆ:")
        if summary_data['avg_speed_improvement'] > 2.0:
            print(f"   âœ… ONNX ëª¨ë¸ì´ PT ëª¨ë¸ë³´ë‹¤ {summary_data['avg_speed_improvement']:.1f}ë°° ë¹ ë¦…ë‹ˆë‹¤!")
        if summary_data['avg_class_accuracy'] > 0.8:
            print(f"   âœ… ë†’ì€ í´ë˜ìŠ¤ ì •í™•ë„({summary_data['avg_class_accuracy']:.1%})ë¥¼ ë³´ì…ë‹ˆë‹¤!")
        if summary_data['avg_iou'] > 0.7:
            print(f"   âœ… ìš°ìˆ˜í•œ IoU ì ìˆ˜({summary_data['avg_iou']:.3f})ì…ë‹ˆë‹¤!")
        if summary_data['match_rate'] < 0.7:
            print(f"   âš ï¸ ë§¤ì¹­ë¥ ({summary_data['match_rate']:.1%})ì´ ë‚®ìŠµë‹ˆë‹¤. ì„ê³„ê°’ ì¡°ì •ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
    except Exception as e:
        print(f"\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return

def fix_openmp_issues():
    """OpenMP ê´€ë ¨ ë¬¸ì œë“¤ì„ ì‚¬ì „ì— í•´ê²°í•˜ëŠ” í•¨ìˆ˜"""
    import os
    import warnings
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    env_vars = {
        'KMP_DUPLICATE_LIB_OK': 'TRUE',
        'OMP_NUM_THREADS': '1',
        'OPENBLAS_NUM_THREADS': '1', 
        'MKL_NUM_THREADS': '1',
        'VECLIB_MAXIMUM_THREADS': '1',
        'NUMEXPR_NUM_THREADS': '1',
        'CUDA_LAUNCH_BLOCKING': '1'  # CUDA ë™ê¸°í™” (GPU ì‚¬ìš©ì‹œ)
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
    
    # ê²½ê³  ë©”ì‹œì§€ ì–µì œ
    warnings.filterwarnings('ignore', category=UserWarning)
    warnings.filterwarnings('ignore', category=FutureWarning)
    
    # PyTorch ì„¤ì •
    try:
        import torch
        torch.set_num_threads(1)
        if hasattr(torch, 'set_num_interop_threads'):
            torch.set_num_interop_threads(1)
        print("âœ… PyTorch ë©€í‹°ìŠ¤ë ˆë”© ì„¤ì • ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ PyTorch ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    
    # OpenCV ì„¤ì •
    try:
        import cv2
        cv2.setNumThreads(1)
        print("âœ… OpenCV ë©€í‹°ìŠ¤ë ˆë”© ì„¤ì • ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ OpenCV ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    
    # NumPy ì„¤ì •
    try:
        import numpy as np
        if hasattr(np, '__config__') and hasattr(np.__config__, 'show'):
            # NumPyì˜ BLAS ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ë³´ í™•ì¸ (ì„ íƒì‚¬í•­)
            pass
        print("âœ… NumPy ì„¤ì • í™•ì¸ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ NumPy ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    # OpenMP ë¬¸ì œ ì‚¬ì „ í•´ê²°
    print("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì • ìµœì í™” ì¤‘...")
    fix_openmp_issues()
    
    try:
        main()
    except KeyboardInterrupt:
        print("\nâŒ í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        
        # OpenMP ê´€ë ¨ ì˜¤ë¥˜ì¸ ê²½ìš° ì¶”ê°€ ì•ˆë‚´
        if "libiomp5md.dll" in str(e) or "OpenMP" in str(e):
            print("\nğŸ”§ OpenMP ì˜¤ë¥˜ í•´ê²° ë°©ë²•:")
            print("1. Anaconda ì‚¬ìš©ì‹œ: conda install intel-openmp")
            print("2. pip ì‚¬ìš©ì‹œ: pip uninstall intel-openmp && pip install intel-openmp")
            print("3. ì‹œìŠ¤í…œ ì¬ì‹œì‘ í›„ ë‹¤ì‹œ ì‹¤í–‰")
            print("4. ê°€ìƒí™˜ê²½ì„ ìƒˆë¡œ ë§Œë“¤ì–´ì„œ ì‹¤í–‰")
        
        import traceback
        traceback.print_exc()