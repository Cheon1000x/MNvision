import cv2
import numpy as np
import onnxruntime as ort
import time

class ONNXDetector:
    def __init__(self, onnx_model_path, input_size=(640, 384), conf_threshold=0.2, iou_threshold=0.3):
        """
        ìƒˆë¡œìš´ ONNX ê°ì²´ íƒì§€ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            onnx_model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            input_size: ëª¨ë¸ ì…ë ¥ í¬ê¸° (width, height)
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (ë‚®ì¶¤)
            iou_threshold: IoU ì„ê³„ê°’ (NMSìš©, ê°•í™”)
        """
        self.onnx_model_path = onnx_model_path
        self.session = ort.InferenceSession(onnx_model_path)
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        self.input_width, self.input_height = input_size
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold

        # ìˆ˜ì •ëœ 6ê°œ í´ë˜ìŠ¤ (ê³µë°± í´ë˜ìŠ¤ ì œê±°)
        self.class_names = [
            'forklift-right',    # 0
            'forklift-left',        # 1  
            'forklift-horizontal',       # 2
            'person',  # 3
            'forklift-vertical',               # 4
            'object',
            ''# 5
        ]
        
        print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {onnx_model_path}")
        print(f"   ì…ë ¥ ì´ë¦„: {self.input_name}")
        print(f"   ì¶œë ¥ ì´ë¦„: {self.output_name}")
        print(f"   ì…ë ¥ í¬ê¸°: {self.input_width}x{self.input_height}")
        print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(self.class_names)}")
        print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold}")
        print(f"   IoU ì„ê³„ê°’: {self.iou_threshold}")

    def preprocess(self, image):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ë¦¬ì‚¬ì´ì¦ˆ + íŒ¨ë”© + ì •ê·œí™”
        ìˆ˜ì •ëœ ì „ì²˜ë¦¬ - ONNX ëª¨ë¸ê³¼ ì •í™•íˆ ì¼ì¹˜
        """
        original_h, original_w = image.shape[:2]
        
        print(f"ğŸ” ì „ì²˜ë¦¬:")
        print(f"   ì›ë³¸ í¬ê¸°: {original_w}x{original_h}")
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
        scale = min(self.input_width / original_w, self.input_height / original_h)
        new_w, new_h = int(original_w * scale), int(original_h * scale)
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        print(f"   ë¦¬ì‚¬ì´ì¦ˆ: {new_w}x{new_h}, ìŠ¤ì¼€ì¼: {scale:.3f}")

        # íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ì •ë ¬)
        top_pad = (self.input_height - new_h) // 2
        bottom_pad = self.input_height - new_h - top_pad
        left_pad = (self.input_width - new_w) // 2
        right_pad = self.input_width - new_w - left_pad

        padded_image = cv2.copyMakeBorder(
            resized_image,
            top_pad, bottom_pad, left_pad, right_pad,
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )
        
        print(f"   íŒ¨ë”©: ìƒ{top_pad} í•˜{bottom_pad} ì¢Œ{left_pad} ìš°{right_pad}")
        print(f"   íŒ¨ë”© í›„: {padded_image.shape}")

        # ì •ê·œí™” ë° ì°¨ì› ë³€í™˜ (ìˆ˜ì •ë¨!)
        input_tensor = padded_image.astype(np.float32) / 255.0
        input_tensor = np.transpose(input_tensor, (2, 0, 1))    # HWC â†’ CHW (ìˆ˜ì •!)
        input_tensor = np.expand_dims(input_tensor, axis=0)     # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

        print(f"   ìµœì¢… í…ì„œ: {input_tensor.shape}")
        return input_tensor, scale, (top_pad, left_pad)

    def postprocess(self, output, original_width, original_height, scale, padding):
        """
        YOLO ì¶œë ¥ í›„ì²˜ë¦¬: í–¥ìƒëœ ë””ë²„ê¹… ë° ì²˜ë¦¬
        """
        pred = output.squeeze(0)  # (11, 5040) â†’ ë°°ì¹˜ ì°¨ì› ì œê±°
        
        print(f"ğŸ” í›„ì²˜ë¦¬:")
        print(f"   ì˜ˆì¸¡ ì¶œë ¥: {pred.shape}")
        
        # YOLO ì¶œë ¥ íŒŒì‹±
        boxes_raw = pred[0:4, :].T      # (5040, 4) - cx, cy, w, h
        objectness_raw = pred[4, :]     # (5040,) - ê°ì²´ì„± ì ìˆ˜ (raw)
        class_scores_raw = pred[5:11, :].T  # (5040, 6) - í´ë˜ìŠ¤ ì ìˆ˜ (raw)
        
        print(f"   ë°•ìŠ¤: {boxes_raw.shape}")
        print(f"   ê°ì²´ì„±(raw): {objectness_raw.shape}")
        print(f"   í´ë˜ìŠ¤(raw): {class_scores_raw.shape}")

        # ì‹œê·¸ëª¨ì´ë“œ ì ìš© (ì¤‘ìš”!)
        objectness = self.sigmoid(objectness_raw)
        class_scores = self.sigmoid(class_scores_raw)
        
        print(f"   ê°ì²´ì„± ë²”ìœ„: {objectness.min():.3f} ~ {objectness.max():.3f}")
        print(f"   í´ë˜ìŠ¤ ì ìˆ˜ ë²”ìœ„: {class_scores.min():.3f} ~ {class_scores.max():.3f}")

        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        scores = objectness[:, np.newaxis] * class_scores
        scores_max = np.max(scores, axis=1)
        labels = np.argmax(scores, axis=1)
        
        print(f"   ìµœì¢… ì ìˆ˜ ë²”ìœ„: {scores_max.min():.3f} ~ {scores_max.max():.3f}")
        print(f"   ìƒìœ„ 10ê°œ ì ìˆ˜: {np.sort(scores_max)[-10:]}")

        # ì„ê³„ê°’ í•„í„°ë§
        keep_mask = scores_max > self.conf_threshold
        print(f"   ì„ê³„ê°’ {self.conf_threshold} ì´ìƒ: {keep_mask.sum()}ê°œ")
        
        if keep_mask.sum() == 0:
            print("   âŒ ì„ê³„ê°’ í†µê³¼í•œ ê°ì²´ ì—†ìŒ")
            return np.array([]), np.array([]), np.array([])

        boxes_filtered = boxes_raw[keep_mask]
        scores_filtered = scores_max[keep_mask]
        labels_filtered = labels[keep_mask]

        # ì¤‘ì‹¬ì  í˜•ì‹ â†’ ì¢Œìƒë‹¨/ìš°í•˜ë‹¨ í˜•ì‹ ë³€í™˜
        boxes_xyxy = np.copy(boxes_filtered)
        boxes_xyxy[:, 0] = boxes_filtered[:, 0] - boxes_filtered[:, 2] / 2  # x1
        boxes_xyxy[:, 1] = boxes_filtered[:, 1] - boxes_filtered[:, 3] / 2  # y1
        boxes_xyxy[:, 2] = boxes_filtered[:, 0] + boxes_filtered[:, 2] / 2  # x2
        boxes_xyxy[:, 3] = boxes_filtered[:, 1] + boxes_filtered[:, 3] / 2  # y2
        
        # NMSìš© í˜•ì‹ ë³€í™˜ (x, y, w, h)
        boxes_for_nms = np.array([[x1, y1, x2-x1, y2-y1] for x1, y1, x2, y2 in boxes_xyxy])
        
        # NMS ì ìš© (ê°•í™”ëœ ì„¤ì •)
        indices = cv2.dnn.NMSBoxes(
            boxes_for_nms.tolist(), 
            scores_filtered.tolist(), 
            self.conf_threshold, 
            self.iou_threshold  # ë” ê°•í•œ NMS
        )
        
        if len(indices) == 0:
            print("   âŒ NMS í›„ ë‚¨ì€ ê°ì²´ ì—†ìŒ")
            return np.array([]), np.array([]), np.array([])
        
        indices = indices.flatten()
        
        boxes_final = boxes_xyxy[indices]
        scores_final = scores_filtered[indices]
        labels_final = labels_filtered[indices]

        print(f"   NMS í›„ ìµœì¢…: {len(boxes_final)}ê°œ")

        # íŒ¨ë”© ë° ìŠ¤ì¼€ì¼ë§ ì—­ë³€í™˜
        top_pad, left_pad = padding

        # íŒ¨ë”© ì œê±°
        boxes_final[:, 0] -= left_pad
        boxes_final[:, 1] -= top_pad
        boxes_final[:, 2] -= left_pad
        boxes_final[:, 3] -= top_pad

        # ìŠ¤ì¼€ì¼ë§ ì—­ë³€í™˜
        boxes_final /= scale

        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ í´ë¦¬í•‘
        boxes_final[:, 0] = np.clip(boxes_final[:, 0], 0, original_width)
        boxes_final[:, 1] = np.clip(boxes_final[:, 1], 0, original_height)
        boxes_final[:, 2] = np.clip(boxes_final[:, 2], 0, original_width)
        boxes_final[:, 3] = np.clip(boxes_final[:, 3], 0, original_height)

        # ìµœì†Œ í¬ê¸° ë³´ì¥
        boxes_final[:, 2] = np.maximum(boxes_final[:, 2], boxes_final[:, 0] + 1)
        boxes_final[:, 3] = np.maximum(boxes_final[:, 3], boxes_final[:, 1] + 1)

        return boxes_final, scores_final, labels_final

    def sigmoid(self, x):
        """ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ (overflow ë°©ì§€)"""
        x = np.clip(x, -500, 500)  # overflow ë°©ì§€
        return 1 / (1 + np.exp(-x))

    def predict(self, image_path):
        """
        ì´ë¯¸ì§€ì— ëŒ€í•œ ê°ì²´ íƒì§€ ìˆ˜í–‰
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        original_image_bgr = cv2.imread(image_path)
        if original_image_bgr is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return np.array([]), np.array([]), np.array([]), None

        # BGR â†’ RGB ë³€í™˜
        original_image = cv2.cvtColor(original_image_bgr, cv2.COLOR_BGR2RGB)
        original_height, original_width = original_image.shape[:2]

        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬: {image_path}")
        print(f"   ì›ë³¸ í¬ê¸°: {original_width}x{original_height}")

        # ì „ì²˜ë¦¬
        input_tensor, scale, padding = self.preprocess(original_image)

        # ONNX ì¶”ë¡ 
        print(f"ğŸ” ONNX ì¶”ë¡  ìˆ˜í–‰...")
        start_time = time.perf_counter()
        outputs = self.session.run([self.output_name], {self.input_name: input_tensor})
        inference_time = (time.perf_counter() - start_time) * 1000
        print(f"   ì¶”ë¡  ì‹œê°„: {inference_time:.2f}ms")
        
        # í›„ì²˜ë¦¬
        boxes, scores, labels = self.postprocess(
            outputs[0], original_width, original_height, scale, padding
        )
        
        return boxes, scores, labels, original_image_bgr

    def visualize(self, image_bgr, boxes, scores, labels, save_path=None):
        """
        íƒì§€ ê²°ê³¼ ì‹œê°í™” (í–¥ìƒëœ ë²„ì „)
        """
        display_image = image_bgr.copy()

        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì •ì˜
        colors = [
            (255, 0, 0),    # forklift-vertical - ë¹¨ê°•
            (0, 255, 0),    # forklift-left - ì´ˆë¡
            (0, 0, 255),    # forklift-right - íŒŒë‘
            (255, 255, 0),  # forklift-horizontal - ë…¸ë‘
            (255, 0, 255),  # person - ë§ˆì  íƒ€
            (0, 255, 255),  # object - ì‹œì•ˆ
        ]

        for i in range(len(boxes)):
            x1, y1, x2, y2 = map(int, boxes[i])
            label = labels[i]
            score = scores[i]
            
            class_name = self.class_names[label] if label < len(self.class_names) else f"Class {label}"
            color = colors[label] if label < len(colors) else (255, 255, 255)

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘êº¼ìš´ ì„ )
            cv2.rectangle(display_image, (x1, y1), (x2, y2), color, 3)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            text = f"{class_name}: {score:.3f}"
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            
            # í…ìŠ¤íŠ¸ ë°°ê²½
            cv2.rectangle(display_image, (x1, y1 - text_size[1] - 10), 
                         (x1 + text_size[0] + 10, y1), color, -1)
            
            # í…ìŠ¤íŠ¸
            cv2.putText(display_image, text, (x1 + 5, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # ê²°ê³¼ í‘œì‹œ ë˜ëŠ” ì €ì¥
        if save_path:
            cv2.imwrite(save_path, display_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {save_path}")
        else:
            cv2.imshow("ONNX Detection Result", display_image)
            print("Press any key to close...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        return display_image

def main():
    """
    ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    import time
    
    # ========================================
    # ğŸ”§ ìƒˆë¡œìš´ ONNX ëª¨ë¸ ì„¤ì •
    # ========================================
    
    ONNX_MODEL_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\9.Quantization\quantized_models\model_static_int8.onnx"
    TEST_IMAGE_PATH = r"C:\Users\KDT-13\Desktop\Group 6_\MNvision\2.Data\photo_cam1\20231214062106\frame_000001.jpg"
    
    # ëª¨ë¸ ì…ë ¥ í¬ê¸° (ONNX ëª¨ë¸ì— ë§ê²Œ)
    INPUT_SIZE = (320, 192)  # (width, height)
    
    # íƒì§€ ì„ê³„ê°’ (ë‚®ì¶°ì„œ ë” ë§ì€ í›„ë³´ í™•ì¸)
    CONF_THRESHOLD = 0.3     # ì‹ ë¢°ë„ ì„ê³„ê°’ (ë‚®ì¶¤)
    IOU_THRESHOLD = 0.1      # NMS IoU ì„ê³„ê°’ (ê°•í™”)
    
    # ========================================
    
    print("ğŸš€ ìƒˆë¡œìš´ ONNX ê°ì²´ íƒì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # íƒì§€ê¸° ì´ˆê¸°í™”
    detector = ONNXDetector(
        onnx_model_path=ONNX_MODEL_PATH,
        input_size=INPUT_SIZE,
        conf_threshold=CONF_THRESHOLD,
        iou_threshold=IOU_THRESHOLD
    )
    
    # ê°ì²´ íƒì§€ ìˆ˜í–‰
    print(f"\nğŸ” ì´ë¯¸ì§€ íƒì§€ ì‹œì‘:")
    boxes, scores, labels, original_image = detector.predict(TEST_IMAGE_PATH)
    
    # ê²°ê³¼ ì¶œë ¥
    if len(boxes) > 0:
        print(f"\nğŸ¯ íƒì§€ ê²°ê³¼: {len(boxes)}ê°œ ê°ì²´ ë°œê²¬")
        for i in range(len(boxes)):
            x1, y1, x2, y2 = boxes[i]
            class_name = detector.class_names[labels[i]]
            score = scores[i]
            print(f"   {i+1}. {class_name}: {score:.3f} - ë°•ìŠ¤: [{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}]")
        
        # ê²°ê³¼ ì‹œê°í™”
        detector.visualize(original_image, boxes, scores, labels)
    else:
        print("\nâŒ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë” ë‚®ì¶°ë³´ê¸° (0.1 or 0.05)")
        print("2. ì‹œê·¸ëª¨ì´ë“œ ì ìš©ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("3. ì›ë³¸ PT ëª¨ë¸ê³¼ ONNX ì¶œë ¥ ì§ì ‘ ë¹„êµ")

if __name__ == "__main__":
    main()